{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import datetime\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload all the data\n",
    "with open('../EDA/All_clean_data/EXPERIENCE_SAMPLING_R00_DND_NO_MISSING_DATA.pickle', 'rb') as file:\n",
    "    EXP = pickle.load(file)\n",
    "    \n",
    "with open('../EDA/All_clean_data/HR_R00_DND.pickle', 'rb') as file:\n",
    "    HR = pickle.load(file)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "with open('../EDA/All_clean_data/SLEEP_R00_DND.pickle', 'rb') as file:\n",
    "    SLEEP = pickle.load(file)\n",
    "    \n",
    "with open('../EDA/All_clean_data/SURVEY_R00_DND.pickle', 'rb') as file:\n",
    "    SURVEY = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../EDA/All_clean_data/STEPS_R00_DND.pickle', 'rb') as handle:\n",
    "    STEPS = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was an issue with the subject ID from HR. I modified that and I create a new pickle version of the DF. This was the code:\n",
    "\n",
    "`HR['ID'] = HR['ID'].replace(to_replace = '(DND1)' , value = 'DND', regex = True)\n",
    "with open('./All_clean_data/HR_R00_DND.pickle','wb') as file:\n",
    "    pickle.dump(HR,file)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>la_p</th>\n",
       "      <th>ha_p</th>\n",
       "      <th>ha_n</th>\n",
       "      <th>la_n</th>\n",
       "      <th>la</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>ha</th>\n",
       "      <th>start_survey</th>\n",
       "      <th>survey_no</th>\n",
       "      <th>experiment</th>\n",
       "      <th>DATE</th>\n",
       "      <th>Period_of_day</th>\n",
       "      <th>VALENCE</th>\n",
       "      <th>VALENCE_mean</th>\n",
       "      <th>Date_only_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-19 13:49:36</td>\n",
       "      <td>1</td>\n",
       "      <td>R00</td>\n",
       "      <td>0219</td>\n",
       "      <td>Evening</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-20 07:32:33</td>\n",
       "      <td>2</td>\n",
       "      <td>R00</td>\n",
       "      <td>0220</td>\n",
       "      <td>Morning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2016-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-20 15:39:23</td>\n",
       "      <td>3</td>\n",
       "      <td>R00</td>\n",
       "      <td>0220</td>\n",
       "      <td>Evening</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2016-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-20 21:13:34</td>\n",
       "      <td>4</td>\n",
       "      <td>R00</td>\n",
       "      <td>0220</td>\n",
       "      <td>Night</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2016-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-21 07:11:48</td>\n",
       "      <td>5</td>\n",
       "      <td>R00</td>\n",
       "      <td>0221</td>\n",
       "      <td>Morning</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3078</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-01 18:00:19</td>\n",
       "      <td>27</td>\n",
       "      <td>DND</td>\n",
       "      <td>0401</td>\n",
       "      <td>Night</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3079</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-01 23:42:54</td>\n",
       "      <td>28</td>\n",
       "      <td>DND</td>\n",
       "      <td>0401</td>\n",
       "      <td>Night</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>DND121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 16:47:21</td>\n",
       "      <td>29</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Evening</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2018-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3081</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 16:47:27</td>\n",
       "      <td>30</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Evening</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2018-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3082</td>\n",
       "      <td>DND121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 20:07:11</td>\n",
       "      <td>31</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Night</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2018-04-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2678 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  la_p  ha_p  ha_n  la_n   la    p    n   ha        start_survey  \\\n",
       "0       1047   2.0   3.0   1.0   1.0  2.0  4.0  1.0  1.0 2016-02-19 13:49:36   \n",
       "1       1047   2.0   1.0   1.0   2.0  3.0  3.0  1.0  1.0 2016-02-20 07:32:33   \n",
       "2       1047   3.0   3.0   1.0   1.0  3.0  5.0  1.0  1.0 2016-02-20 15:39:23   \n",
       "3       1047   4.0   3.0   1.0   1.0  2.0  4.0  1.0  1.0 2016-02-20 21:13:34   \n",
       "4       1047   4.0   1.0   1.0   2.0  4.0  2.0  1.0  1.0 2016-02-21 07:11:48   \n",
       "...      ...   ...   ...   ...   ...  ...  ...  ...  ...                 ...   \n",
       "3078  DND121   2.0   1.0   4.0   2.0  2.0  1.0  4.0  1.0 2018-04-01 18:00:19   \n",
       "3079  DND121   2.0   1.0   3.0   2.0  2.0  1.0  4.0  1.0 2018-04-01 23:42:54   \n",
       "3080  DND121   1.0   3.0   3.0   2.0  1.0  2.0  4.0  1.0 2018-04-02 16:47:21   \n",
       "3081  DND121   2.0   3.0   1.0   2.0  2.0  4.0  2.0  1.0 2018-04-02 16:47:27   \n",
       "3082  DND121   3.0   1.0   2.0   2.0  3.0  1.0  4.0  1.0 2018-04-02 20:07:11   \n",
       "\n",
       "      survey_no experiment  DATE Period_of_day  VALENCE  VALENCE_mean  \\\n",
       "0             1        R00  0219       Evening      6.0      2.000000   \n",
       "1             2        R00  0220       Morning      2.0      0.666667   \n",
       "2             3        R00  0220       Evening      8.0      2.666667   \n",
       "3             4        R00  0220         Night      8.0      2.666667   \n",
       "4             5        R00  0221       Morning      3.0      1.000000   \n",
       "...         ...        ...   ...           ...      ...           ...   \n",
       "3078         27        DND  0401         Night     -6.0     -2.000000   \n",
       "3079         28        DND  0401         Night     -5.0     -1.666667   \n",
       "3080         29        DND  0402       Evening     -3.0     -1.000000   \n",
       "3081         30        DND  0402       Evening      4.0      1.333333   \n",
       "3082         31        DND  0402         Night     -3.0     -1.000000   \n",
       "\n",
       "     Date_only_date  \n",
       "0        2016-02-19  \n",
       "1        2016-02-20  \n",
       "2        2016-02-20  \n",
       "3        2016-02-20  \n",
       "4        2016-02-21  \n",
       "...             ...  \n",
       "3078     2018-04-01  \n",
       "3079     2018-04-01  \n",
       "3080     2018-04-02  \n",
       "3081     2018-04-02  \n",
       "3082     2018-04-02  \n",
       "\n",
       "[2678 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey is a dictionary of datasets.\n",
    "## I am going to create a loop to merge all my tables into one big DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features that we are going to use in our model\n",
    "features = {'AVI' : ['Experiment',\n",
    "                     'HAN_actual', 'HAN_ideal', \n",
    "                     'HAP_actual', 'HAP_ideal',\n",
    "                     'HA_actual', 'HA_ideal',\n",
    "                     'LAN_actual', 'LAN_ideal',\n",
    "                     'LAP_actual', 'LAP_ideal',\n",
    "                     'LA_actual', 'LA_ideal',\n",
    "                     'N_actual', 'N_ideal',\n",
    "                     'P_actual', 'P_ideal',\n",
    "                     'Subject'],\n",
    "            'DEMOGRAPHICS' : ['Age',\n",
    "                             'Children',\n",
    "                             'Ethnicity',\n",
    "                             'Experiment',\n",
    "                             'Household_income',\n",
    "                             'Marital_Status',\n",
    "                             'Sex',\n",
    "                             'Subject'],\n",
    "            'MEDICAL_SCREENING' : ['BMI',\n",
    "                                    'Experiment',\n",
    "                                    'Height (cm)',\n",
    "                                    'Subject',\n",
    "                                    'Weight (kg)'],\n",
    "            'BISBAS' : ['BAS_D', 'BAS_FS', 'BAS_RR', 'BIS.5', 'Experiment', 'Subject'],\n",
    "            'BIS' : ['BIS_total', 'Experiment', 'Subject'],\n",
    "            'TPQ_NS' : ['Experiment', 'NS_total', 'Subject'],\n",
    "            'NEO_SF' : ['Conscientiousness_scaled', 'Experiment', 'Extraversion_scaled', 'Neuroticism_scaled', 'Subject'],\n",
    "            'SWLS' : ['Experiment', 'SWLS', 'Subject'],    \n",
    "            'FTP' : ['Experiment', 'FTP', 'Subject'],\n",
    "            'SBQ' : ['Experiment','SBQ','Subject']}\n",
    "features.keys() == SURVEY.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>HAN_actual</th>\n",
       "      <th>HAN_ideal</th>\n",
       "      <th>HAP_actual</th>\n",
       "      <th>HAP_ideal</th>\n",
       "      <th>HA_actual</th>\n",
       "      <th>HA_ideal</th>\n",
       "      <th>LAN_actual</th>\n",
       "      <th>LAN_ideal</th>\n",
       "      <th>LAP_actual</th>\n",
       "      <th>LAP_ideal</th>\n",
       "      <th>LA_actual</th>\n",
       "      <th>LA_ideal</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>N_ideal</th>\n",
       "      <th>P_actual</th>\n",
       "      <th>P_ideal</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>R00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>DND</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>DND118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>DND</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>DND119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>DND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>DND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiment  HAN_actual  HAN_ideal  HAP_actual  HAP_ideal  HA_actual  \\\n",
       "1          R00    2.000000   1.000000         3.6        4.0   2.000000   \n",
       "3          R00    1.333333   1.666667         2.8        4.4   2.666667   \n",
       "7          R00    1.666667   1.000000         2.2        3.2   2.000000   \n",
       "8          R00    1.333333   1.666667         3.8        3.8   2.333333   \n",
       "13         R00    1.666667   1.333333         3.4        3.8   2.333333   \n",
       "..         ...         ...        ...         ...        ...        ...   \n",
       "117        DND    5.000000   3.000000        12.0       17.0   7.000000   \n",
       "118        DND    3.000000   3.000000        12.0       15.0   8.000000   \n",
       "119        DND         NaN        NaN         NaN        NaN        NaN   \n",
       "120        DND    6.000000   3.000000        16.0       18.0   7.000000   \n",
       "121        DND         NaN        NaN         NaN        NaN        NaN   \n",
       "\n",
       "      HA_ideal  LAN_actual  LAN_ideal  LAP_actual  LAP_ideal  LA_actual  \\\n",
       "1     3.333333    2.000000        1.0         3.8        4.8        2.4   \n",
       "3     3.333333    2.333333        2.0         2.2        4.0        2.0   \n",
       "7     2.000000    2.000000        1.0         2.2        4.0        2.0   \n",
       "8     2.666667    2.000000        2.0         3.0        3.4        2.4   \n",
       "13    2.333333    1.666667        1.0         3.8        4.2        1.4   \n",
       "..         ...         ...        ...         ...        ...        ...   \n",
       "117   8.000000    6.000000        3.0        13.0       16.0        5.0   \n",
       "118  10.000000    6.000000        5.0        18.0       18.0        8.0   \n",
       "119        NaN         NaN        NaN         NaN        NaN        NaN   \n",
       "120   9.000000    8.000000        4.0        18.0       24.0        8.0   \n",
       "121        NaN         NaN        NaN         NaN        NaN        NaN   \n",
       "\n",
       "     LA_ideal   N_actual   N_ideal   P_actual    P_ideal Subject  \n",
       "1         2.0   2.000000  1.000000   4.000000   5.000000    1002  \n",
       "3         2.2   2.000000  1.333333   3.000000   4.333333    1004  \n",
       "7         2.0   1.666667  1.000000   3.333333   5.000000    1008  \n",
       "8         2.4   1.666667  2.000000   3.666667   3.666667    1009  \n",
       "13        1.4   1.666667  1.000000   4.000000   4.000000    1014  \n",
       "..        ...        ...       ...        ...        ...     ...  \n",
       "117       5.0   6.000000  3.000000   7.000000  12.000000  DND118  \n",
       "118       7.0   3.000000  4.000000  12.000000  12.000000  DND119  \n",
       "119       NaN        NaN       NaN        NaN        NaN  DND120  \n",
       "120       9.0  10.000000  3.000000  11.000000  15.000000  DND121  \n",
       "121       NaN        NaN       NaN        NaN        NaN  DND122  \n",
       "\n",
       "[158 rows x 18 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging all the tables into one DF\n",
    "SURVEY_SMALL = SURVEY['AVI'].loc[:,features['AVI']].copy()\n",
    "SURVEY_SMALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMOGRAPHICS\n",
      "MEDICAL_SCREENING\n",
      "BISBAS\n",
      "BIS\n",
      "TPQ_NS\n",
      "NEO_SF\n",
      "SWLS\n",
      "FTP\n",
      "SBQ\n"
     ]
    }
   ],
   "source": [
    "for table in list(features.keys())[1:]:\n",
    "    print(table)\n",
    "    SURVEY[table]['Subject'] = SURVEY[table]['Subject'].astype(str) #make subjects a string\n",
    "    SURVEY_SMALL = SURVEY_SMALL.merge(SURVEY[table].loc[:,features[table]], how = 'left', on = ['Subject','Experiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>HAN_actual</th>\n",
       "      <th>HAN_ideal</th>\n",
       "      <th>HAP_actual</th>\n",
       "      <th>HAP_ideal</th>\n",
       "      <th>HA_actual</th>\n",
       "      <th>HA_ideal</th>\n",
       "      <th>LAN_actual</th>\n",
       "      <th>LAN_ideal</th>\n",
       "      <th>LAP_actual</th>\n",
       "      <th>LAP_ideal</th>\n",
       "      <th>LA_actual</th>\n",
       "      <th>LA_ideal</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>N_ideal</th>\n",
       "      <th>P_actual</th>\n",
       "      <th>P_ideal</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Children</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Household_income</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_FS</th>\n",
       "      <th>BAS_RR</th>\n",
       "      <th>BIS.5</th>\n",
       "      <th>BIS_total</th>\n",
       "      <th>NS_total</th>\n",
       "      <th>Conscientiousness_scaled</th>\n",
       "      <th>Extraversion_scaled</th>\n",
       "      <th>Neuroticism_scaled</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>FTP</th>\n",
       "      <th>SBQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>R00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1002</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$10,000-$19,999</td>\n",
       "      <td>Single</td>\n",
       "      <td>Female</td>\n",
       "      <td>23.725936</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>61.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1004</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>White/Pacific Islander</td>\n",
       "      <td>$10,000-$19,999</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>30.221958</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>91.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1008</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.306605</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>103.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1009</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>28.408163</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1014</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$120,000-$129,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>31.256942</td>\n",
       "      <td>167.600000</td>\n",
       "      <td>87.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>DND</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>DND118</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>177.930854</td>\n",
       "      <td>72.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.463542</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>DND</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>DND119</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>$90,000-$99,999</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>175.370228</td>\n",
       "      <td>97.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>DND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND120</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$30,000-$39,999</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>DND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND122</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>$120,000-$129,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiment  HAN_actual  HAN_ideal  HAP_actual  HAP_ideal  HA_actual  \\\n",
       "0          R00    2.000000   1.000000         3.6        4.0   2.000000   \n",
       "1          R00    1.333333   1.666667         2.8        4.4   2.666667   \n",
       "2          R00    1.666667   1.000000         2.2        3.2   2.000000   \n",
       "3          R00    1.333333   1.666667         3.8        3.8   2.333333   \n",
       "4          R00    1.666667   1.333333         3.4        3.8   2.333333   \n",
       "..         ...         ...        ...         ...        ...        ...   \n",
       "153        DND    5.000000   3.000000        12.0       17.0   7.000000   \n",
       "154        DND    3.000000   3.000000        12.0       15.0   8.000000   \n",
       "155        DND         NaN        NaN         NaN        NaN        NaN   \n",
       "156        DND    6.000000   3.000000        16.0       18.0   7.000000   \n",
       "157        DND         NaN        NaN         NaN        NaN        NaN   \n",
       "\n",
       "      HA_ideal  LAN_actual  LAN_ideal  LAP_actual  LAP_ideal  LA_actual  \\\n",
       "0     3.333333    2.000000        1.0         3.8        4.8        2.4   \n",
       "1     3.333333    2.333333        2.0         2.2        4.0        2.0   \n",
       "2     2.000000    2.000000        1.0         2.2        4.0        2.0   \n",
       "3     2.666667    2.000000        2.0         3.0        3.4        2.4   \n",
       "4     2.333333    1.666667        1.0         3.8        4.2        1.4   \n",
       "..         ...         ...        ...         ...        ...        ...   \n",
       "153   8.000000    6.000000        3.0        13.0       16.0        5.0   \n",
       "154  10.000000    6.000000        5.0        18.0       18.0        8.0   \n",
       "155        NaN         NaN        NaN         NaN        NaN        NaN   \n",
       "156   9.000000    8.000000        4.0        18.0       24.0        8.0   \n",
       "157        NaN         NaN        NaN         NaN        NaN        NaN   \n",
       "\n",
       "     LA_ideal   N_actual   N_ideal   P_actual    P_ideal Subject   Age  \\\n",
       "0         2.0   2.000000  1.000000   4.000000   5.000000    1002  32.0   \n",
       "1         2.2   2.000000  1.333333   3.000000   4.333333    1004  28.0   \n",
       "2         2.0   1.666667  1.000000   3.333333   5.000000    1008  46.0   \n",
       "3         2.4   1.666667  2.000000   3.666667   3.666667    1009  58.0   \n",
       "4         1.4   1.666667  1.000000   4.000000   4.000000    1014  68.0   \n",
       "..        ...        ...       ...        ...        ...     ...   ...   \n",
       "153       5.0   6.000000  3.000000   7.000000  12.000000  DND118  59.0   \n",
       "154       7.0   3.000000  4.000000  12.000000  12.000000  DND119  57.0   \n",
       "155       NaN        NaN       NaN        NaN        NaN  DND120  50.0   \n",
       "156       9.0  10.000000  3.000000  11.000000  15.000000  DND121  61.0   \n",
       "157       NaN        NaN       NaN        NaN        NaN  DND122  50.0   \n",
       "\n",
       "     Children               Ethnicity   Household_income Marital_Status  \\\n",
       "0         0.0                   White    $10,000-$19,999         Single   \n",
       "1         0.0  White/Pacific Islander    $10,000-$19,999         Single   \n",
       "2         2.0                   White   $150,000 or more        Married   \n",
       "3         0.0                   White   $150,000 or more        Married   \n",
       "4         3.0                   White  $120,000-$129,999        Married   \n",
       "..        ...                     ...                ...            ...   \n",
       "153       1.0                   White  $150,000 or more         Married   \n",
       "154       1.0                   Black    $90,000-$99,999       Divorced   \n",
       "155       2.0                   White    $30,000-$39,999         Single   \n",
       "156       4.0                   White    $70,000-$79,999        Married   \n",
       "157       3.0                   Black  $120,000-$129,999        Married   \n",
       "\n",
       "        Sex        BMI  Height (cm)  Weight (kg)  BAS_D  BAS_FS  BAS_RR  \\\n",
       "0    Female  23.725936   161.000000         61.5   15.0    16.0    24.0   \n",
       "1      Male  30.221958   174.000000         91.5   14.0    18.0    25.0   \n",
       "2      Male  31.306605   182.000000        103.7   11.0    12.0    21.0   \n",
       "3      Male  28.408163   175.000000         87.0   13.0    12.0    19.0   \n",
       "4    Female  31.256942   167.600000         87.8   14.0    11.0    18.0   \n",
       "..      ...        ...          ...          ...    ...     ...     ...   \n",
       "153    Male  22.900000   177.930854         72.5   10.0    14.0    15.0   \n",
       "154    Male  31.800000   175.370228         97.8    7.0     9.0    10.0   \n",
       "155    Male        NaN          NaN          NaN    NaN     NaN     NaN   \n",
       "156    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "157    Male        NaN          NaN          NaN    NaN     NaN     NaN   \n",
       "\n",
       "     BIS.5  BIS_total  NS_total  Conscientiousness_scaled  \\\n",
       "0     21.0       55.0      16.0                  0.708333   \n",
       "1     22.0       67.0      18.0                  0.770833   \n",
       "2     27.0       62.0      11.0                  0.750000   \n",
       "3     21.0       45.0       7.0                  0.750000   \n",
       "4     19.0       52.0       9.0                  0.770833   \n",
       "..     ...        ...       ...                       ...   \n",
       "153   20.0       71.0      17.0                  0.489583   \n",
       "154   17.0       61.0      18.0                  0.625000   \n",
       "155    NaN        NaN       NaN                       NaN   \n",
       "156   20.0       72.0      16.0                  0.598958   \n",
       "157    NaN        NaN       NaN                       NaN   \n",
       "\n",
       "     Extraversion_scaled  Neuroticism_scaled  SWLS   FTP   SBQ  \n",
       "0               0.750000            0.291667  20.0   6.8  55.0  \n",
       "1               0.750000            0.333333  25.0   5.3  45.0  \n",
       "2               0.729167            0.333333  24.0   5.0  57.0  \n",
       "3               0.687500            0.291667  22.0   5.0  53.0  \n",
       "4               0.500000            0.291667  25.0   3.7  55.0  \n",
       "..                   ...                 ...   ...   ...   ...  \n",
       "153             0.614583            0.463542  19.0  51.0  53.0  \n",
       "154             0.520833            0.197917  23.0  54.0  52.0  \n",
       "155                  NaN                 NaN   NaN   NaN   0.0  \n",
       "156             0.578125            0.359375   4.0  35.0  55.0  \n",
       "157                  NaN                 NaN   NaN   NaN   0.0  \n",
       "\n",
       "[158 rows x 39 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SURVEY_SMALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge EXP, SURVEY, and SLEEP DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set everything as string\n",
    "EXP['subject'] = EXP.subject.astype(str)\n",
    "SURVEY_SMALL['Subject'] =  SURVEY_SMALL['Subject'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Experiment                   0\n",
       " HAN_actual                  47\n",
       " HAN_ideal                   47\n",
       " HAP_actual                  47\n",
       " HAP_ideal                   47\n",
       " HA_actual                   47\n",
       " HA_ideal                    47\n",
       " LAN_actual                  47\n",
       " LAN_ideal                   47\n",
       " LAP_actual                  47\n",
       " LAP_ideal                   47\n",
       " LA_actual                   47\n",
       " LA_ideal                    47\n",
       " N_actual                    47\n",
       " N_ideal                     47\n",
       " P_actual                    47\n",
       " P_ideal                     47\n",
       " Subject                      0\n",
       " Age                          0\n",
       " Children                     0\n",
       " Ethnicity                    0\n",
       " Household_income             1\n",
       " Marital_Status               0\n",
       " Sex                          0\n",
       " BMI                         25\n",
       " Height (cm)                 70\n",
       " Weight (kg)                 70\n",
       " BAS_D                       47\n",
       " BAS_FS                      47\n",
       " BAS_RR                      47\n",
       " BIS.5                       47\n",
       " BIS_total                   47\n",
       " NS_total                    47\n",
       " Conscientiousness_scaled    47\n",
       " Extraversion_scaled         47\n",
       " Neuroticism_scaled          47\n",
       " SWLS                        47\n",
       " FTP                         47\n",
       " SBQ                          0\n",
       " dtype: int64, (158, 39))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have a lot of missing values\n",
    "SURVEY_SMALL.isna().sum(), SURVEY_SMALL.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment                   0\n",
       "HAN_actual                   0\n",
       "HAN_ideal                    0\n",
       "HAP_actual                   0\n",
       "HAP_ideal                    0\n",
       "HA_actual                    0\n",
       "HA_ideal                     0\n",
       "LAN_actual                   0\n",
       "LAN_ideal                    0\n",
       "LAP_actual                   0\n",
       "LAP_ideal                    0\n",
       "LA_actual                    0\n",
       "LA_ideal                     0\n",
       "N_actual                     0\n",
       "N_ideal                      0\n",
       "P_actual                     0\n",
       "P_ideal                      0\n",
       "Subject                      0\n",
       "Age                          0\n",
       "Children                     0\n",
       "Ethnicity                    0\n",
       "Household_income             1\n",
       "Marital_Status               0\n",
       "Sex                          0\n",
       "BMI                          0\n",
       "Height (cm)                 23\n",
       "Weight (kg)                 23\n",
       "BAS_D                        0\n",
       "BAS_FS                       0\n",
       "BAS_RR                       0\n",
       "BIS.5                        0\n",
       "BIS_total                    0\n",
       "NS_total                     0\n",
       "Conscientiousness_scaled     0\n",
       "Extraversion_scaled          0\n",
       "Neuroticism_scaled           0\n",
       "SWLS                         5\n",
       "FTP                          0\n",
       "SBQ                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It's maybe extreme but let's use this for our model. \n",
    "# Delete every row that has more than 4 missing values\n",
    "SURVEY_SMALL = SURVEY_SMALL.loc[SURVEY_SMALL.isna().T.sum() < 4,:]\n",
    "SURVEY_SMALL.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 39)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SURVEY_SMALL.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some brief insights\n",
    "- There are a lot of subjects that do not have weight nor height in DND, but we have BMI for everybody.\n",
    "- We could choose to input this features or not use them into our model\n",
    "- Some subjects do not have a value for SWLS. Maybe we should drop this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2678, 56)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join Experience samplng and Survey\n",
    "ALL_DATA = EXP.merge(SURVEY_SMALL, how='left', left_on=['subject','experiment'], right_on=['Subject','Experiment'])\n",
    "ALL_DATA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject                       0\n",
       "la_p                          1\n",
       "ha_p                          0\n",
       "ha_n                          0\n",
       "la_n                          0\n",
       "la                            0\n",
       "p                             0\n",
       "n                             0\n",
       "ha                            0\n",
       "start_survey                  8\n",
       "survey_no                     0\n",
       "experiment                    0\n",
       "DATE                          0\n",
       "Period_of_day                 8\n",
       "VALENCE                       1\n",
       "VALENCE_mean                  1\n",
       "Date_only_date                8\n",
       "Experiment                   22\n",
       "HAN_actual                   22\n",
       "HAN_ideal                    22\n",
       "HAP_actual                   22\n",
       "HAP_ideal                    22\n",
       "HA_actual                    22\n",
       "HA_ideal                     22\n",
       "LAN_actual                   22\n",
       "LAN_ideal                    22\n",
       "LAP_actual                   22\n",
       "LAP_ideal                    22\n",
       "LA_actual                    22\n",
       "LA_ideal                     22\n",
       "N_actual                     22\n",
       "N_ideal                      22\n",
       "P_actual                     22\n",
       "P_ideal                      22\n",
       "Subject                      22\n",
       "Age                          22\n",
       "Children                     22\n",
       "Ethnicity                    22\n",
       "Household_income             48\n",
       "Marital_Status               22\n",
       "Sex                          22\n",
       "BMI                          22\n",
       "Height (cm)                 550\n",
       "Weight (kg)                 550\n",
       "BAS_D                        22\n",
       "BAS_FS                       22\n",
       "BAS_RR                       22\n",
       "BIS.5                        22\n",
       "BIS_total                    22\n",
       "NS_total                     22\n",
       "Conscientiousness_scaled     22\n",
       "Extraversion_scaled          22\n",
       "Neuroticism_scaled           22\n",
       "SWLS                        162\n",
       "FTP                          22\n",
       "SBQ                          22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "ALL_DATA.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2656, 56)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to delete the subjects that are not in the SURVEY_SMALL dataset\n",
    "ALL_DATA_SMALL = ALL_DATA.loc[ALL_DATA['subject'].isin(SURVEY_SMALL['Subject'])]\n",
    "ALL_DATA_SMALL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject                       0\n",
       "la_p                          1\n",
       "ha_p                          0\n",
       "ha_n                          0\n",
       "la_n                          0\n",
       "la                            0\n",
       "p                             0\n",
       "n                             0\n",
       "ha                            0\n",
       "start_survey                  8\n",
       "survey_no                     0\n",
       "experiment                    0\n",
       "DATE                          0\n",
       "Period_of_day                 8\n",
       "VALENCE                       1\n",
       "VALENCE_mean                  1\n",
       "Date_only_date                8\n",
       "Experiment                    0\n",
       "HAN_actual                    0\n",
       "HAN_ideal                     0\n",
       "HAP_actual                    0\n",
       "HAP_ideal                     0\n",
       "HA_actual                     0\n",
       "HA_ideal                      0\n",
       "LAN_actual                    0\n",
       "LAN_ideal                     0\n",
       "LAP_actual                    0\n",
       "LAP_ideal                     0\n",
       "LA_actual                     0\n",
       "LA_ideal                      0\n",
       "N_actual                      0\n",
       "N_ideal                       0\n",
       "P_actual                      0\n",
       "P_ideal                       0\n",
       "Subject                       0\n",
       "Age                           0\n",
       "Children                      0\n",
       "Ethnicity                     0\n",
       "Household_income             26\n",
       "Marital_Status                0\n",
       "Sex                           0\n",
       "BMI                           0\n",
       "Height (cm)                 528\n",
       "Weight (kg)                 528\n",
       "BAS_D                         0\n",
       "BAS_FS                        0\n",
       "BAS_RR                        0\n",
       "BIS.5                         0\n",
       "BIS_total                     0\n",
       "NS_total                      0\n",
       "Conscientiousness_scaled      0\n",
       "Extraversion_scaled           0\n",
       "Neuroticism_scaled            0\n",
       "SWLS                        140\n",
       "FTP                           0\n",
       "SBQ                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_DATA_SMALL.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ID</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Minutes REM Sleep</th>\n",
       "      <th>Minutes Light Sleep</th>\n",
       "      <th>Minutes Deep Sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-16</td>\n",
       "      <td>477</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>505</td>\n",
       "      <td>0716</td>\n",
       "      <td>1002</td>\n",
       "      <td>R00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>404</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>462</td>\n",
       "      <td>0717</td>\n",
       "      <td>1002</td>\n",
       "      <td>R00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-18</td>\n",
       "      <td>361</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>382</td>\n",
       "      <td>0718</td>\n",
       "      <td>1002</td>\n",
       "      <td>R00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>281</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>291</td>\n",
       "      <td>0719</td>\n",
       "      <td>1002</td>\n",
       "      <td>R00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>409</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>427</td>\n",
       "      <td>0720</td>\n",
       "      <td>1002</td>\n",
       "      <td>R00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1191</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>301</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND121</td>\n",
       "      <td>DND</td>\n",
       "      <td>2018-04-16 4:10AM</td>\n",
       "      <td>2018-04-16 9:19AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1192</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>136</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND121</td>\n",
       "      <td>DND</td>\n",
       "      <td>2018-04-17 7:40AM</td>\n",
       "      <td>2018-04-17 10:05AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1193</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND121</td>\n",
       "      <td>DND</td>\n",
       "      <td>2018-04-18 8:33AM</td>\n",
       "      <td>2018-04-18 10:16AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1194</td>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>201</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND121</td>\n",
       "      <td>DND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>349</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DND121</td>\n",
       "      <td>DND</td>\n",
       "      <td>2018-04-20 2:55AM</td>\n",
       "      <td>2018-04-20 8:54AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Minutes Asleep Minutes Awake Number of Awakenings Time in Bed  \\\n",
       "0    2015-07-16            477            20                   16         505   \n",
       "1    2015-07-17            404            45                   17         462   \n",
       "2    2015-07-18            361            17                   13         382   \n",
       "3    2015-07-19            281             9                    4         291   \n",
       "4    2015-07-20            409            18                   15         427   \n",
       "...         ...            ...           ...                  ...         ...   \n",
       "1191 2018-04-16            301             6                    1         309   \n",
       "1192 2018-04-17            136             9                    1         145   \n",
       "1193 2018-04-18             98             4                    0         103   \n",
       "1194 2018-04-19            201             6                    1         209   \n",
       "1195 2018-04-20            349            10                    1         359   \n",
       "\n",
       "      DATE      ID Experiment         Start Time            End Time  \\\n",
       "0     0716    1002        R00                NaN                 NaN   \n",
       "1     0717    1002        R00                NaN                 NaN   \n",
       "2     0718    1002        R00                NaN                 NaN   \n",
       "3     0719    1002        R00                NaN                 NaN   \n",
       "4     0720    1002        R00                NaN                 NaN   \n",
       "...    ...     ...        ...                ...                 ...   \n",
       "1191   NaN  DND121        DND  2018-04-16 4:10AM   2018-04-16 9:19AM   \n",
       "1192   NaN  DND121        DND  2018-04-17 7:40AM  2018-04-17 10:05AM   \n",
       "1193   NaN  DND121        DND  2018-04-18 8:33AM  2018-04-18 10:16AM   \n",
       "1194   NaN  DND121        DND                NaN                 NaN   \n",
       "1195   NaN  DND121        DND  2018-04-20 2:55AM   2018-04-20 8:54AM   \n",
       "\n",
       "      Minutes REM Sleep  Minutes Light Sleep  Minutes Deep Sleep  \n",
       "0                   NaN                  NaN                 NaN  \n",
       "1                   NaN                  NaN                 NaN  \n",
       "2                   NaN                  NaN                 NaN  \n",
       "3                   NaN                  NaN                 NaN  \n",
       "4                   NaN                  NaN                 NaN  \n",
       "...                 ...                  ...                 ...  \n",
       "1191                NaN                  NaN                 NaN  \n",
       "1192                NaN                  NaN                 NaN  \n",
       "1193                NaN                  NaN                 NaN  \n",
       "1194                NaN                  NaN                 NaN  \n",
       "1195                NaN                  NaN                 NaN  \n",
       "\n",
       "[1196 rows x 13 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge sleep data. Be sure to use the same data types.\n",
    "SLEEP['Date'] = pd.to_datetime(SLEEP['Date'],errors = 'coerce')\n",
    "SLEEP[\"ID\"] = SLEEP[\"ID\"].astype(str)\n",
    "SLEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE_y                  1981\n",
       "Height (cm)              528\n",
       "Weight (kg)              528\n",
       "Experiment_y             355\n",
       "Time in Bed              355\n",
       "Number of Awakenings     355\n",
       "Minutes Awake            355\n",
       "Minutes Asleep           355\n",
       "Date                     355\n",
       "ID                       355\n",
       "SWLS                     140\n",
       "Household_income          26\n",
       "start_survey               8\n",
       "Period_of_day              8\n",
       "Date_only_date             8\n",
       "VALENCE_mean               1\n",
       "VALENCE                    1\n",
       "la_p                       1\n",
       "HAN_actual                 0\n",
       "Experiment_x               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SLEEP.iloc[:,:-5] because we do not have any data for REM, Light nor Deep sleep\n",
    "# Check the features with most missing values\n",
    "ALL_DATA_SMALL.merge(SLEEP.iloc[:,:-5], how='left', left_on=['subject','experiment', 'Date_only_date'], right_on=['ID','Experiment', 'Date']).isna().sum().sort_values(ascending =False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA_SMALL = ALL_DATA_SMALL.merge(SLEEP.iloc[:,:-5], how='left', left_on=['subject','experiment', 'Date_only_date'], right_on=['ID','Experiment', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>la_p</th>\n",
       "      <th>ha_p</th>\n",
       "      <th>ha_n</th>\n",
       "      <th>la_n</th>\n",
       "      <th>la</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>ha</th>\n",
       "      <th>start_survey</th>\n",
       "      <th>survey_no</th>\n",
       "      <th>experiment</th>\n",
       "      <th>DATE_x</th>\n",
       "      <th>Period_of_day</th>\n",
       "      <th>VALENCE</th>\n",
       "      <th>VALENCE_mean</th>\n",
       "      <th>Date_only_date</th>\n",
       "      <th>Experiment_x</th>\n",
       "      <th>HAN_actual</th>\n",
       "      <th>HAN_ideal</th>\n",
       "      <th>HAP_actual</th>\n",
       "      <th>HAP_ideal</th>\n",
       "      <th>HA_actual</th>\n",
       "      <th>HA_ideal</th>\n",
       "      <th>LAN_actual</th>\n",
       "      <th>LAN_ideal</th>\n",
       "      <th>LAP_actual</th>\n",
       "      <th>LAP_ideal</th>\n",
       "      <th>LA_actual</th>\n",
       "      <th>LA_ideal</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>N_ideal</th>\n",
       "      <th>P_actual</th>\n",
       "      <th>P_ideal</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Children</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Household_income</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_FS</th>\n",
       "      <th>BAS_RR</th>\n",
       "      <th>BIS.5</th>\n",
       "      <th>BIS_total</th>\n",
       "      <th>NS_total</th>\n",
       "      <th>Conscientiousness_scaled</th>\n",
       "      <th>Extraversion_scaled</th>\n",
       "      <th>Neuroticism_scaled</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>FTP</th>\n",
       "      <th>SBQ</th>\n",
       "      <th>Date</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>DATE_y</th>\n",
       "      <th>ID</th>\n",
       "      <th>Experiment_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-19 13:49:36</td>\n",
       "      <td>1</td>\n",
       "      <td>R00</td>\n",
       "      <td>0219</td>\n",
       "      <td>Evening</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016-02-19</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$90,000-$99,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>160.500000</td>\n",
       "      <td>70.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-20 07:32:33</td>\n",
       "      <td>2</td>\n",
       "      <td>R00</td>\n",
       "      <td>0220</td>\n",
       "      <td>Morning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$90,000-$99,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>160.500000</td>\n",
       "      <td>70.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>147</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>157</td>\n",
       "      <td>0220</td>\n",
       "      <td>1047</td>\n",
       "      <td>R00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-20 15:39:23</td>\n",
       "      <td>3</td>\n",
       "      <td>R00</td>\n",
       "      <td>0220</td>\n",
       "      <td>Evening</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$90,000-$99,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>160.500000</td>\n",
       "      <td>70.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>147</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>157</td>\n",
       "      <td>0220</td>\n",
       "      <td>1047</td>\n",
       "      <td>R00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-20 21:13:34</td>\n",
       "      <td>4</td>\n",
       "      <td>R00</td>\n",
       "      <td>0220</td>\n",
       "      <td>Night</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$90,000-$99,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>160.500000</td>\n",
       "      <td>70.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>147</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>157</td>\n",
       "      <td>0220</td>\n",
       "      <td>1047</td>\n",
       "      <td>R00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-21 07:11:48</td>\n",
       "      <td>5</td>\n",
       "      <td>R00</td>\n",
       "      <td>0221</td>\n",
       "      <td>Morning</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$90,000-$99,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>160.500000</td>\n",
       "      <td>70.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>317</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>357</td>\n",
       "      <td>0221</td>\n",
       "      <td>1047</td>\n",
       "      <td>R00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2651</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-01 18:00:19</td>\n",
       "      <td>27</td>\n",
       "      <td>DND</td>\n",
       "      <td>0401</td>\n",
       "      <td>Night</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2652</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-01 23:42:54</td>\n",
       "      <td>28</td>\n",
       "      <td>DND</td>\n",
       "      <td>0401</td>\n",
       "      <td>Night</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2653</td>\n",
       "      <td>DND121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 16:47:21</td>\n",
       "      <td>29</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Evening</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2654</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 16:47:27</td>\n",
       "      <td>30</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Evening</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2655</td>\n",
       "      <td>DND121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 20:07:11</td>\n",
       "      <td>31</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Night</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2656 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  la_p  ha_p  ha_n  la_n   la    p    n   ha        start_survey  \\\n",
       "0       1047   2.0   3.0   1.0   1.0  2.0  4.0  1.0  1.0 2016-02-19 13:49:36   \n",
       "1       1047   2.0   1.0   1.0   2.0  3.0  3.0  1.0  1.0 2016-02-20 07:32:33   \n",
       "2       1047   3.0   3.0   1.0   1.0  3.0  5.0  1.0  1.0 2016-02-20 15:39:23   \n",
       "3       1047   4.0   3.0   1.0   1.0  2.0  4.0  1.0  1.0 2016-02-20 21:13:34   \n",
       "4       1047   4.0   1.0   1.0   2.0  4.0  2.0  1.0  1.0 2016-02-21 07:11:48   \n",
       "...      ...   ...   ...   ...   ...  ...  ...  ...  ...                 ...   \n",
       "2651  DND121   2.0   1.0   4.0   2.0  2.0  1.0  4.0  1.0 2018-04-01 18:00:19   \n",
       "2652  DND121   2.0   1.0   3.0   2.0  2.0  1.0  4.0  1.0 2018-04-01 23:42:54   \n",
       "2653  DND121   1.0   3.0   3.0   2.0  1.0  2.0  4.0  1.0 2018-04-02 16:47:21   \n",
       "2654  DND121   2.0   3.0   1.0   2.0  2.0  4.0  2.0  1.0 2018-04-02 16:47:27   \n",
       "2655  DND121   3.0   1.0   2.0   2.0  3.0  1.0  4.0  1.0 2018-04-02 20:07:11   \n",
       "\n",
       "      survey_no experiment DATE_x Period_of_day  VALENCE  VALENCE_mean  \\\n",
       "0             1        R00   0219       Evening      6.0      2.000000   \n",
       "1             2        R00   0220       Morning      2.0      0.666667   \n",
       "2             3        R00   0220       Evening      8.0      2.666667   \n",
       "3             4        R00   0220         Night      8.0      2.666667   \n",
       "4             5        R00   0221       Morning      3.0      1.000000   \n",
       "...         ...        ...    ...           ...      ...           ...   \n",
       "2651         27        DND   0401         Night     -6.0     -2.000000   \n",
       "2652         28        DND   0401         Night     -5.0     -1.666667   \n",
       "2653         29        DND   0402       Evening     -3.0     -1.000000   \n",
       "2654         30        DND   0402       Evening      4.0      1.333333   \n",
       "2655         31        DND   0402         Night     -3.0     -1.000000   \n",
       "\n",
       "     Date_only_date Experiment_x  HAN_actual  HAN_ideal  HAP_actual  \\\n",
       "0        2016-02-19          R00    1.333333        1.0         2.6   \n",
       "1        2016-02-20          R00    1.333333        1.0         2.6   \n",
       "2        2016-02-20          R00    1.333333        1.0         2.6   \n",
       "3        2016-02-20          R00    1.333333        1.0         2.6   \n",
       "4        2016-02-21          R00    1.333333        1.0         2.6   \n",
       "...             ...          ...         ...        ...         ...   \n",
       "2651     2018-04-01          DND    6.000000        3.0        16.0   \n",
       "2652     2018-04-01          DND    6.000000        3.0        16.0   \n",
       "2653     2018-04-02          DND    6.000000        3.0        16.0   \n",
       "2654     2018-04-02          DND    6.000000        3.0        16.0   \n",
       "2655     2018-04-02          DND    6.000000        3.0        16.0   \n",
       "\n",
       "      HAP_ideal  HA_actual  HA_ideal  LAN_actual  LAN_ideal  LAP_actual  \\\n",
       "0           2.8        2.0  2.333333    1.666667        1.0         3.6   \n",
       "1           2.8        2.0  2.333333    1.666667        1.0         3.6   \n",
       "2           2.8        2.0  2.333333    1.666667        1.0         3.6   \n",
       "3           2.8        2.0  2.333333    1.666667        1.0         3.6   \n",
       "4           2.8        2.0  2.333333    1.666667        1.0         3.6   \n",
       "...         ...        ...       ...         ...        ...         ...   \n",
       "2651       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "2652       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "2653       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "2654       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "2655       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "\n",
       "      LAP_ideal  LA_actual  LA_ideal  N_actual  N_ideal   P_actual    P_ideal  \\\n",
       "0           4.2        2.0       1.8       1.0      1.0   4.333333   4.333333   \n",
       "1           4.2        2.0       1.8       1.0      1.0   4.333333   4.333333   \n",
       "2           4.2        2.0       1.8       1.0      1.0   4.333333   4.333333   \n",
       "3           4.2        2.0       1.8       1.0      1.0   4.333333   4.333333   \n",
       "4           4.2        2.0       1.8       1.0      1.0   4.333333   4.333333   \n",
       "...         ...        ...       ...       ...      ...        ...        ...   \n",
       "2651       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "2652       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "2653       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "2654       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "2655       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "\n",
       "     Subject   Age  Children Ethnicity Household_income Marital_Status  \\\n",
       "0       1047  43.0       3.0     White  $90,000-$99,999        Married   \n",
       "1       1047  43.0       3.0     White  $90,000-$99,999        Married   \n",
       "2       1047  43.0       3.0     White  $90,000-$99,999        Married   \n",
       "3       1047  43.0       3.0     White  $90,000-$99,999        Married   \n",
       "4       1047  43.0       3.0     White  $90,000-$99,999        Married   \n",
       "...      ...   ...       ...       ...              ...            ...   \n",
       "2651  DND121  61.0       4.0     White  $70,000-$79,999        Married   \n",
       "2652  DND121  61.0       4.0     White  $70,000-$79,999        Married   \n",
       "2653  DND121  61.0       4.0     White  $70,000-$79,999        Married   \n",
       "2654  DND121  61.0       4.0     White  $70,000-$79,999        Married   \n",
       "2655  DND121  61.0       4.0     White  $70,000-$79,999        Married   \n",
       "\n",
       "         Sex        BMI  Height (cm)  Weight (kg)  BAS_D  BAS_FS  BAS_RR  \\\n",
       "0     Female  27.328927   160.500000         70.4   14.0    16.0    23.0   \n",
       "1     Female  27.328927   160.500000         70.4   14.0    16.0    23.0   \n",
       "2     Female  27.328927   160.500000         70.4   14.0    16.0    23.0   \n",
       "3     Female  27.328927   160.500000         70.4   14.0    16.0    23.0   \n",
       "4     Female  27.328927   160.500000         70.4   14.0    16.0    23.0   \n",
       "...      ...        ...          ...          ...    ...     ...     ...   \n",
       "2651    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "2652    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "2653    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "2654    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "2655    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "\n",
       "      BIS.5  BIS_total  NS_total  Conscientiousness_scaled  \\\n",
       "0      24.0       51.0      11.0                  0.875000   \n",
       "1      24.0       51.0      11.0                  0.875000   \n",
       "2      24.0       51.0      11.0                  0.875000   \n",
       "3      24.0       51.0      11.0                  0.875000   \n",
       "4      24.0       51.0      11.0                  0.875000   \n",
       "...     ...        ...       ...                       ...   \n",
       "2651   20.0       72.0      16.0                  0.598958   \n",
       "2652   20.0       72.0      16.0                  0.598958   \n",
       "2653   20.0       72.0      16.0                  0.598958   \n",
       "2654   20.0       72.0      16.0                  0.598958   \n",
       "2655   20.0       72.0      16.0                  0.598958   \n",
       "\n",
       "      Extraversion_scaled  Neuroticism_scaled  SWLS   FTP   SBQ       Date  \\\n",
       "0                0.583333            0.208333  25.0   5.5  60.0        NaT   \n",
       "1                0.583333            0.208333  25.0   5.5  60.0 2016-02-20   \n",
       "2                0.583333            0.208333  25.0   5.5  60.0 2016-02-20   \n",
       "3                0.583333            0.208333  25.0   5.5  60.0 2016-02-20   \n",
       "4                0.583333            0.208333  25.0   5.5  60.0 2016-02-21   \n",
       "...                   ...                 ...   ...   ...   ...        ...   \n",
       "2651             0.578125            0.359375   4.0  35.0  55.0        NaT   \n",
       "2652             0.578125            0.359375   4.0  35.0  55.0        NaT   \n",
       "2653             0.578125            0.359375   4.0  35.0  55.0        NaT   \n",
       "2654             0.578125            0.359375   4.0  35.0  55.0        NaT   \n",
       "2655             0.578125            0.359375   4.0  35.0  55.0        NaT   \n",
       "\n",
       "     Minutes Asleep Minutes Awake Number of Awakenings Time in Bed DATE_y  \\\n",
       "0               NaN           NaN                  NaN         NaN    NaN   \n",
       "1               147            10                    6         157   0220   \n",
       "2               147            10                    6         157   0220   \n",
       "3               147            10                    6         157   0220   \n",
       "4               317            40                   17         357   0221   \n",
       "...             ...           ...                  ...         ...    ...   \n",
       "2651            NaN           NaN                  NaN         NaN    NaN   \n",
       "2652            NaN           NaN                  NaN         NaN    NaN   \n",
       "2653            NaN           NaN                  NaN         NaN    NaN   \n",
       "2654            NaN           NaN                  NaN         NaN    NaN   \n",
       "2655            NaN           NaN                  NaN         NaN    NaN   \n",
       "\n",
       "        ID Experiment_y  \n",
       "0      NaN          NaN  \n",
       "1     1047          R00  \n",
       "2     1047          R00  \n",
       "3     1047          R00  \n",
       "4     1047          R00  \n",
       "...    ...          ...  \n",
       "2651   NaN          NaN  \n",
       "2652   NaN          NaN  \n",
       "2653   NaN          NaN  \n",
       "2654   NaN          NaN  \n",
       "2655   NaN          NaN  \n",
       "\n",
       "[2656 rows x 64 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_DATA_SMALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE_y                  0.745858\n",
       "Height (cm)             0.198795\n",
       "Weight (kg)             0.198795\n",
       "Experiment_y            0.133660\n",
       "Time in Bed             0.133660\n",
       "Number of Awakenings    0.133660\n",
       "Minutes Awake           0.133660\n",
       "Minutes Asleep          0.133660\n",
       "Date                    0.133660\n",
       "ID                      0.133660\n",
       "SWLS                    0.052711\n",
       "Household_income        0.009789\n",
       "start_survey            0.003012\n",
       "Period_of_day           0.003012\n",
       "Date_only_date          0.003012\n",
       "VALENCE_mean            0.000377\n",
       "VALENCE                 0.000377\n",
       "la_p                    0.000377\n",
       "HAN_actual              0.000000\n",
       "Experiment_x            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ALL_DATA_SMALL.isna().sum()/ALL_DATA_SMALL.shape[0]).sort_values(ascending= False) [:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing subjects with sleep data. We should try removing this ones before checking for problematic features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will remove all the columns that have more than 140 missing values or more than a 10% of missing ratio.<br>\n",
    "I will keep SWLS, Household_income and I will input this values in the future.\n",
    "I will need to delete all the rows without a `start survey` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>la_p</th>\n",
       "      <th>ha_p</th>\n",
       "      <th>ha_n</th>\n",
       "      <th>la_n</th>\n",
       "      <th>la</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>ha</th>\n",
       "      <th>start_survey</th>\n",
       "      <th>survey_no</th>\n",
       "      <th>experiment</th>\n",
       "      <th>DATE_x</th>\n",
       "      <th>Period_of_day</th>\n",
       "      <th>VALENCE</th>\n",
       "      <th>VALENCE_mean</th>\n",
       "      <th>Date_only_date</th>\n",
       "      <th>Experiment_x</th>\n",
       "      <th>HAN_actual</th>\n",
       "      <th>HAN_ideal</th>\n",
       "      <th>HAP_actual</th>\n",
       "      <th>HAP_ideal</th>\n",
       "      <th>HA_actual</th>\n",
       "      <th>HA_ideal</th>\n",
       "      <th>LAN_actual</th>\n",
       "      <th>LAN_ideal</th>\n",
       "      <th>LAP_actual</th>\n",
       "      <th>LAP_ideal</th>\n",
       "      <th>LA_actual</th>\n",
       "      <th>LA_ideal</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>N_ideal</th>\n",
       "      <th>P_actual</th>\n",
       "      <th>P_ideal</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Children</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Household_income</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_FS</th>\n",
       "      <th>BAS_RR</th>\n",
       "      <th>BIS.5</th>\n",
       "      <th>BIS_total</th>\n",
       "      <th>NS_total</th>\n",
       "      <th>Conscientiousness_scaled</th>\n",
       "      <th>Extraversion_scaled</th>\n",
       "      <th>Neuroticism_scaled</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>FTP</th>\n",
       "      <th>SBQ</th>\n",
       "      <th>Date</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>DATE_y</th>\n",
       "      <th>ID</th>\n",
       "      <th>Experiment_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-19 13:49:36</td>\n",
       "      <td>1</td>\n",
       "      <td>R00</td>\n",
       "      <td>0219</td>\n",
       "      <td>Evening</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016-02-19</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$90,000-$99,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>160.500000</td>\n",
       "      <td>70.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1084</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-10-14 14:21:53</td>\n",
       "      <td>1</td>\n",
       "      <td>R00</td>\n",
       "      <td>1014</td>\n",
       "      <td>Evening</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1084</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.834466</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1084</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-10-15 09:33:35</td>\n",
       "      <td>2</td>\n",
       "      <td>R00</td>\n",
       "      <td>1015</td>\n",
       "      <td>Morning</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1084</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.834466</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1084</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-10-15 16:04:46</td>\n",
       "      <td>3</td>\n",
       "      <td>R00</td>\n",
       "      <td>1015</td>\n",
       "      <td>Evening</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1084</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.834466</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1084</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-10-15 18:53:55</td>\n",
       "      <td>4</td>\n",
       "      <td>R00</td>\n",
       "      <td>1015</td>\n",
       "      <td>Night</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>R00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1084</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.834466</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2651</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-01 18:00:19</td>\n",
       "      <td>27</td>\n",
       "      <td>DND</td>\n",
       "      <td>0401</td>\n",
       "      <td>Night</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2652</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-01 23:42:54</td>\n",
       "      <td>28</td>\n",
       "      <td>DND</td>\n",
       "      <td>0401</td>\n",
       "      <td>Night</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2653</td>\n",
       "      <td>DND121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 16:47:21</td>\n",
       "      <td>29</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Evening</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2654</td>\n",
       "      <td>DND121</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 16:47:27</td>\n",
       "      <td>30</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Evening</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2655</td>\n",
       "      <td>DND121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 20:07:11</td>\n",
       "      <td>31</td>\n",
       "      <td>DND</td>\n",
       "      <td>0402</td>\n",
       "      <td>Night</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>DND</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>DND121</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "      <td>$70,000-$79,999</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>182.894211</td>\n",
       "      <td>114.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  la_p  ha_p  ha_n  la_n   la    p    n   ha        start_survey  \\\n",
       "0       1047   2.0   3.0   1.0   1.0  2.0  4.0  1.0  1.0 2016-02-19 13:49:36   \n",
       "27      1084   4.0   3.0   1.0   3.0  3.0  3.0  1.0  1.0 2016-10-14 14:21:53   \n",
       "28      1084   4.0   4.0   1.0   3.0  3.0  3.0  1.0  1.0 2016-10-15 09:33:35   \n",
       "29      1084   3.0   2.0   1.0   4.0  3.0  3.0  1.0  1.0 2016-10-15 16:04:46   \n",
       "30      1084   4.0   5.0   1.0   1.0  3.0  4.0  1.0  1.0 2016-10-15 18:53:55   \n",
       "...      ...   ...   ...   ...   ...  ...  ...  ...  ...                 ...   \n",
       "2651  DND121   2.0   1.0   4.0   2.0  2.0  1.0  4.0  1.0 2018-04-01 18:00:19   \n",
       "2652  DND121   2.0   1.0   3.0   2.0  2.0  1.0  4.0  1.0 2018-04-01 23:42:54   \n",
       "2653  DND121   1.0   3.0   3.0   2.0  1.0  2.0  4.0  1.0 2018-04-02 16:47:21   \n",
       "2654  DND121   2.0   3.0   1.0   2.0  2.0  4.0  2.0  1.0 2018-04-02 16:47:27   \n",
       "2655  DND121   3.0   1.0   2.0   2.0  3.0  1.0  4.0  1.0 2018-04-02 20:07:11   \n",
       "\n",
       "      survey_no experiment DATE_x Period_of_day  VALENCE  VALENCE_mean  \\\n",
       "0             1        R00   0219       Evening      6.0      2.000000   \n",
       "27            1        R00   1014       Evening      5.0      1.666667   \n",
       "28            2        R00   1015       Morning      6.0      2.000000   \n",
       "29            3        R00   1015       Evening      2.0      0.666667   \n",
       "30            4        R00   1015         Night     10.0      3.333333   \n",
       "...         ...        ...    ...           ...      ...           ...   \n",
       "2651         27        DND   0401         Night     -6.0     -2.000000   \n",
       "2652         28        DND   0401         Night     -5.0     -1.666667   \n",
       "2653         29        DND   0402       Evening     -3.0     -1.000000   \n",
       "2654         30        DND   0402       Evening      4.0      1.333333   \n",
       "2655         31        DND   0402         Night     -3.0     -1.000000   \n",
       "\n",
       "     Date_only_date Experiment_x  HAN_actual  HAN_ideal  HAP_actual  \\\n",
       "0        2016-02-19          R00    1.333333        1.0         2.6   \n",
       "27       2016-10-14          R00    1.666667        1.0         3.6   \n",
       "28       2016-10-15          R00    1.666667        1.0         3.6   \n",
       "29       2016-10-15          R00    1.666667        1.0         3.6   \n",
       "30       2016-10-15          R00    1.666667        1.0         3.6   \n",
       "...             ...          ...         ...        ...         ...   \n",
       "2651     2018-04-01          DND    6.000000        3.0        16.0   \n",
       "2652     2018-04-01          DND    6.000000        3.0        16.0   \n",
       "2653     2018-04-02          DND    6.000000        3.0        16.0   \n",
       "2654     2018-04-02          DND    6.000000        3.0        16.0   \n",
       "2655     2018-04-02          DND    6.000000        3.0        16.0   \n",
       "\n",
       "      HAP_ideal  HA_actual  HA_ideal  LAN_actual  LAN_ideal  LAP_actual  \\\n",
       "0           2.8        2.0  2.333333    1.666667        1.0         3.6   \n",
       "27          4.4        2.0  2.666667    3.000000        1.0         3.4   \n",
       "28          4.4        2.0  2.666667    3.000000        1.0         3.4   \n",
       "29          4.4        2.0  2.666667    3.000000        1.0         3.4   \n",
       "30          4.4        2.0  2.666667    3.000000        1.0         3.4   \n",
       "...         ...        ...       ...         ...        ...         ...   \n",
       "2651       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "2652       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "2653       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "2654       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "2655       18.0        7.0  9.000000    8.000000        4.0        18.0   \n",
       "\n",
       "      LAP_ideal  LA_actual  LA_ideal  N_actual  N_ideal   P_actual    P_ideal  \\\n",
       "0           4.2        2.0       1.8       1.0      1.0   4.333333   4.333333   \n",
       "27          4.4        3.2       2.0       2.0      1.0   2.333333   2.333333   \n",
       "28          4.4        3.2       2.0       2.0      1.0   2.333333   2.333333   \n",
       "29          4.4        3.2       2.0       2.0      1.0   2.333333   2.333333   \n",
       "30          4.4        3.2       2.0       2.0      1.0   2.333333   2.333333   \n",
       "...         ...        ...       ...       ...      ...        ...        ...   \n",
       "2651       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "2652       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "2653       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "2654       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "2655       24.0        8.0       9.0      10.0      3.0  11.000000  15.000000   \n",
       "\n",
       "     Subject   Age  Children Ethnicity  Household_income Marital_Status  \\\n",
       "0       1047  43.0       3.0     White   $90,000-$99,999        Married   \n",
       "27      1084  53.0       4.0     White  $150,000 or more       Divorced   \n",
       "28      1084  53.0       4.0     White  $150,000 or more       Divorced   \n",
       "29      1084  53.0       4.0     White  $150,000 or more       Divorced   \n",
       "30      1084  53.0       4.0     White  $150,000 or more       Divorced   \n",
       "...      ...   ...       ...       ...               ...            ...   \n",
       "2651  DND121  61.0       4.0     White   $70,000-$79,999        Married   \n",
       "2652  DND121  61.0       4.0     White   $70,000-$79,999        Married   \n",
       "2653  DND121  61.0       4.0     White   $70,000-$79,999        Married   \n",
       "2654  DND121  61.0       4.0     White   $70,000-$79,999        Married   \n",
       "2655  DND121  61.0       4.0     White   $70,000-$79,999        Married   \n",
       "\n",
       "         Sex        BMI  Height (cm)  Weight (kg)  BAS_D  BAS_FS  BAS_RR  \\\n",
       "0     Female  27.328927   160.500000         70.4   14.0    16.0    23.0   \n",
       "27      Male  33.834466   177.000000        106.0   16.0    14.0    21.0   \n",
       "28      Male  33.834466   177.000000        106.0   16.0    14.0    21.0   \n",
       "29      Male  33.834466   177.000000        106.0   16.0    14.0    21.0   \n",
       "30      Male  33.834466   177.000000        106.0   16.0    14.0    21.0   \n",
       "...      ...        ...          ...          ...    ...     ...     ...   \n",
       "2651    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "2652    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "2653    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "2654    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "2655    Male  34.200000   182.894211        114.4   10.0    12.0    14.0   \n",
       "\n",
       "      BIS.5  BIS_total  NS_total  Conscientiousness_scaled  \\\n",
       "0      24.0       51.0      11.0                  0.875000   \n",
       "27     12.0       80.0      23.0                  0.729167   \n",
       "28     12.0       80.0      23.0                  0.729167   \n",
       "29     12.0       80.0      23.0                  0.729167   \n",
       "30     12.0       80.0      23.0                  0.729167   \n",
       "...     ...        ...       ...                       ...   \n",
       "2651   20.0       72.0      16.0                  0.598958   \n",
       "2652   20.0       72.0      16.0                  0.598958   \n",
       "2653   20.0       72.0      16.0                  0.598958   \n",
       "2654   20.0       72.0      16.0                  0.598958   \n",
       "2655   20.0       72.0      16.0                  0.598958   \n",
       "\n",
       "      Extraversion_scaled  Neuroticism_scaled  SWLS   FTP   SBQ Date  \\\n",
       "0                0.583333            0.208333  25.0   5.5  60.0  NaT   \n",
       "27               0.625000            0.270833  10.0   5.6  52.0  NaT   \n",
       "28               0.625000            0.270833  10.0   5.6  52.0  NaT   \n",
       "29               0.625000            0.270833  10.0   5.6  52.0  NaT   \n",
       "30               0.625000            0.270833  10.0   5.6  52.0  NaT   \n",
       "...                   ...                 ...   ...   ...   ...  ...   \n",
       "2651             0.578125            0.359375   4.0  35.0  55.0  NaT   \n",
       "2652             0.578125            0.359375   4.0  35.0  55.0  NaT   \n",
       "2653             0.578125            0.359375   4.0  35.0  55.0  NaT   \n",
       "2654             0.578125            0.359375   4.0  35.0  55.0  NaT   \n",
       "2655             0.578125            0.359375   4.0  35.0  55.0  NaT   \n",
       "\n",
       "     Minutes Asleep Minutes Awake Number of Awakenings Time in Bed DATE_y  \\\n",
       "0               NaN           NaN                  NaN         NaN    NaN   \n",
       "27              NaN           NaN                  NaN         NaN    NaN   \n",
       "28              NaN           NaN                  NaN         NaN    NaN   \n",
       "29              NaN           NaN                  NaN         NaN    NaN   \n",
       "30              NaN           NaN                  NaN         NaN    NaN   \n",
       "...             ...           ...                  ...         ...    ...   \n",
       "2651            NaN           NaN                  NaN         NaN    NaN   \n",
       "2652            NaN           NaN                  NaN         NaN    NaN   \n",
       "2653            NaN           NaN                  NaN         NaN    NaN   \n",
       "2654            NaN           NaN                  NaN         NaN    NaN   \n",
       "2655            NaN           NaN                  NaN         NaN    NaN   \n",
       "\n",
       "       ID Experiment_y  \n",
       "0     NaN          NaN  \n",
       "27    NaN          NaN  \n",
       "28    NaN          NaN  \n",
       "29    NaN          NaN  \n",
       "30    NaN          NaN  \n",
       "...   ...          ...  \n",
       "2651  NaN          NaN  \n",
       "2652  NaN          NaN  \n",
       "2653  NaN          NaN  \n",
       "2654  NaN          NaN  \n",
       "2655  NaN          NaN  \n",
       "\n",
       "[355 rows x 64 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_DATA_SMALL.loc[ALL_DATA_SMALL['Minutes Asleep'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approx 355 rows are missing sleeping data. We should remove this ones in order to have a fully complet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESTRICTED_DATA = ALL_DATA_SMALL.loc[ALL_DATA_SMALL['Minutes Asleep'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2301, 59)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop messy columns drom the joins\n",
    "RESTRICTED_DATA = RESTRICTED_DATA.drop(columns=['DATE_y', 'ID', 'Experiment_y', 'DATE_x' , 'Experiment_x'])\n",
    "RESTRICTED_DATA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Height (cm)         0.201217\n",
       "Weight (kg)         0.201217\n",
       "SWLS                0.047371\n",
       "Household_income    0.011299\n",
       "Time in Bed         0.000000\n",
       "VALENCE_mean        0.000000\n",
       "LAP_actual          0.000000\n",
       "LAN_ideal           0.000000\n",
       "LAN_actual          0.000000\n",
       "HA_ideal            0.000000\n",
       "HA_actual           0.000000\n",
       "HAP_ideal           0.000000\n",
       "HAP_actual          0.000000\n",
       "HAN_ideal           0.000000\n",
       "HAN_actual          0.000000\n",
       "Date_only_date      0.000000\n",
       "VALENCE             0.000000\n",
       "LA_actual           0.000000\n",
       "Period_of_day       0.000000\n",
       "experiment          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(RESTRICTED_DATA.isna().sum()/RESTRICTED_DATA.shape[0]).sort_values(ascending= False) [:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE CAN OBSERVE THAT WHEN WE REMOVE ALL THE COMPLICATED ROWS (THE ONES WITH MISSING SLEEP DATA) WE HAVE A DATASET WITH FEWER A MISSING RATE. <br>\n",
    "We still should delete Height and Weight and only use BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESTRICTED_DATA = RESTRICTED_DATA.drop(columns=['Height (cm)', 'Weight (kg)' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject\n",
       "1051       2\n",
       "1087       3\n",
       "1030       3\n",
       "DND091     4\n",
       "DND083     6\n",
       "DND115     9\n",
       "1041       9\n",
       "1029       9\n",
       "1018      10\n",
       "1037      11\n",
       "1032      12\n",
       "1045      13\n",
       "1060      14\n",
       "DND007    14\n",
       "DND046    15\n",
       "Name: experiment, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some metrics of the final dataset\n",
    "# Number of sirveys per subject. Ordered\n",
    "RESTRICTED_DATA.groupby('subject').aggregate('count')['experiment'].sort_values(ascending = True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_row_per_subj = RESTRICTED_DATA.groupby('subject').aggregate('count')['experiment']\n",
    "plt.boxplot(num_row_per_subj)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(num_row_per_subj)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.782178217821784, 7.094510498119007)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_row_per_subj.mean(), num_row_per_subj.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2301, 57)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESTRICTED_DATA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some conlcusion about the data\n",
    "- It seems that the amount of surveys anwswered (experience sampling) has a skewed distribution without some outliers. \n",
    "- I do not consider that the difference between subjects is big enough to be a problem. (mean 22.8 surveys answered, with a SD of 7)\n",
    "- We removed all the features that presented a big proportion of missing cases (> 10% missing rate). This included variables as:\n",
    "    - Education (encoded differentially in the datasets).\n",
    "    - Religion (not present in DND)\n",
    "    - Height and Weight. But every subject has a BMI value.\n",
    "- The final dataset has a total of 2301 rows and 57 features. The number of features will be different for the modeling phase (variables as Experiment, Date and survey number will be removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hot encoding and Label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical to numerical\n",
    "- Ethnicity\n",
    "\n",
    "- Marital_Status\n",
    "\n",
    "- Sex\n",
    "\n",
    "- Period_of_day\n",
    "\n",
    "### Ordinal\n",
    "- Household_income\n",
    "\n",
    "In order to do so we should encode Ordinal variables as a single variable with values [0,1,2,...,n] and we should encode Categorical Variables with one hot encoding. <br>\n",
    "See this [link](https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b) for an axample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "DF = pd.get_dummies(RESTRICTED_DATA,columns=['Sex','Ethnicity','Marital_Status','Period_of_day']) #dummy encoding for categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$90,000-$99,999', '$150,000 or more', '$20,000-$29,999',\n",
       "       '$70,000-$79,999', '$60,000-$69,999', 'Less than $10,000',\n",
       "       '$30,000-$39,999', '$40,000-$49,999', '$50,000-$59,999',\n",
       "       '$120,000-$129,999', '$80,000-$89,999', '$10,000-$19,999',\n",
       "       '$140,000-$149,999', '$150,000 or more ', '$130,000-$139,000',\n",
       "       '$110,000-$119,999', '$100,000-$109,999', nan], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " DF['Household_income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's order the categories in an ordinal way from 0 to 15\n",
    "cat = ['Less than $10,000',\n",
    "       '$10,000-$19,999',\n",
    "      '$20,000-$29,999',\n",
    "     '$30,000-$39,999',\n",
    "     '$40,000-$49,999',\n",
    "     '$50,000-$59,999',\n",
    "     '$60,000-$69,999',\n",
    "     '$70,000-$79,999',\n",
    "     '$80,000-$89,999',\n",
    "     '$90,000-$99,999',\n",
    "     '$100,000-$109,999',\n",
    "     '$110,000-$119,999',\n",
    "     '$120,000-$129,999',\n",
    "     '$130,000-$139,000',\n",
    "     '$140,000-$149,999',\n",
    "     '$150,000 or more']\n",
    "cat_map = {k:v for k,v in zip(cat,range(len(cat)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Household_income'] = DF['Household_income'].replace(cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 15, 2, 7, 6, 0, 3, 4, 5, 12, 8, 1, 14, '$150,000 or more ', 13,\n",
       "       11, 10, nan], dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['Household_income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Household_income'] = DF['Household_income'].replace(to_replace= '$150,000 or more ' , value = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9., 15.,  2.,  7.,  6.,  0.,  3.,  4.,  5., 12.,  8.,  1., 14.,\n",
       "       13., 11., 10., nan])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['Household_income'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I do have a doubt about the variable `SUBJECT`. \n",
    "## How we should encode this one? In a one hot encoding? Not use it in models that do not take into acount repeated measures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing data\n",
    "I must divide the datasets first (X,y)\n",
    "\n",
    "Should I input values for different X datasets (train,test)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](https://machinelearningmastery.com/handle-missing-data-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputing SWLS\n",
    "transformed_DF = SimpleImputer().fit_transform(DF.loc[:,['SWLS','SBQ','FTP']])\n",
    "DF['SWLS'] = transformed_DF[:,0] #we input the value for SWLS. \n",
    "#In this case I am not using all the matrix because the function need to transform all the data into float and I have string vars\n",
    "\n",
    "\n",
    "#transforming to scalar. This is going to be useful when scaling\n",
    "DF['Minutes Awake'] = DF['Minutes Awake'].astype(float)\n",
    "DF['Minutes Asleep'] = DF['Minutes Asleep'].astype(float)\n",
    "DF['Number of Awakenings'] = DF['Number of Awakenings'].astype(float)\n",
    "DF['Time in Bed'] = DF['Time in Bed'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the DF clean without HR nor STEPS Time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../EDA/All_clean_data/DF_R00_DND_WITHOUT_HR_STEPS.pickle', 'wb') as file:\n",
    "#    pickle.dump(DF,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('../EDA/All_clean_data/exp_steps_hr_sleep_survey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30 mins prior time point\n",
    "DF['start_survey_30m_ahead'] =DF['start_survey'] - datetime.timedelta(minutes=30)\n",
    "DF['start_survey_1h_ahead'] = DF['start_survey'] - datetime.timedelta(minutes=60)\n",
    "DF['start_survey_3h_ahead'] = DF['start_survey'] - datetime.timedelta(hours=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to calculate a new field called `date_time` to combine date and time\n",
    "    #STEPS['date_time'] = STEPS['Date'].astype(str) + ' ' + STEPS['TIME'].astype(str) \n",
    "    #STEPS['date_time'] = pd.to_datetime(STEPS['date_time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../EDA/All_clean_data/STEPS_R00_DND.pickle','wb') as file:\n",
    "#    pickle.dump(STEPS,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../EDA/All_clean_data/STEPS_R00_DND.pickle', 'rb') as file:\n",
    "    STEPS = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR['Date'] = pd.to_datetime(HR['Date'], format= '%Y-%m-%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HR['date_time'] = HR['Date'].astype(str) + ' ' + HR['TIME'].astype(str) \n",
    "#HR['date_time'] = pd.to_datetime(HR['date_time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../EDA/All_clean_data/HR_R00_DND.pickle','wb') as file:\n",
    "#    pickle.dump(HR,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../EDA/All_clean_data/HR_R00_DND.pickle', 'rb') as file:\n",
    "    HR = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['subject', 'start_survey',\n",
    "        'start_survey_5m_ahead', 'start_survey_10m_ahead','step_max', 'step_min', 'step_median', 'steps_max_3h', 'steps_min_3h', 'steps_mean_3h', 'steps_var_3h', 'steps_median_3h', \n",
    "        'move_rate_3h', 'active_rate_3h', 'very_active_rate_3h', 'running_rate_3h', 'steps_max_1h', 'steps_min_1h', 'steps_mean_1h', 'steps_var_1h', 'steps_median_1h', 'move_rate_1h', \n",
    "        'active_rate_1h', 'very_active_rate_1h', 'running_rate_1h', 'steps_max_30m','steps_min_30m', 'steps_mean_30m', 'steps_var_30m', 'steps_median_30m', 'move_rate_30m', 'active_rate_30m',\n",
    "        'very_active_rate_30m', 'running_rate_30m', \n",
    "        'steps_max_10m', 'steps_min_10m', 'steps_mean_10m', 'steps_var_10m', 'steps_median_10m', 'move_rate_10m', 'active_rate_10m', 'very_active_rate_10m', 'running_rate_10m',\n",
    "        'steps_max_5m', 'steps_min_5m', 'steps_mean_5m', 'steps_var_5m', 'steps_median_5m', 'move_rate_5m', 'active_rate_5m', 'very_active_rate_5m', 'running_rate_5m','hr_max','hr_min',\n",
    "        'hr_med','SDNN_3h','pHR2_3h','rMSSD_3h','low_hr_3h','high_hr_3h','l_h_3h','CR_3h','hr_mean_3h','hr_var_3h','hr_std_3h','hr_median_3h','hr_rest_rate_3h','hr_moderate_rate_3h',\n",
    "        'hr_very_active_rate_3h','SDNN_1h','pHR2_1h','rMSSD_1h','low_hr_1h','high_hr_1h', 'l_h_1h', 'CR_1h', 'hr_mean_1h', 'hr_var_1h', 'hr_std_1h', 'hr_median_1h', 'hr_rest_rate_1h', \n",
    "        'hr_moderate_rate_1h', 'hr_very_active_rate_1h', 'SDNN_30m', 'pHR2_30m', 'rMSSD_30m', 'low_hr_30m', 'high_hr_30m', 'l_h_30m', 'CR_30m', 'hr_mean_30m', 'hr_var_30m', 'hr_std_30m',\n",
    "        'hr_median_30m', 'hr_rest_rate_30m', 'hr_moderate_rate_30m', 'hr_very_active_rate_30m', 'SDNN_10m', 'pHR2_10m', 'rMSSD_10m', 'low_hr_10m', 'high_hr_10m', 'l_h_10m','CR_10m',\n",
    "        'hr_mean_10m','hr_var_10m','hr_std_10m','hr_median_10m','hr_rest_rate_10m','hr_moderate_rate_10m','hr_very_active_rate_10m','SDNN_5m','pHR2_5m','rMSSD_5m','low_hr_5m','high_hr_5m',\n",
    "        'l_h_5m','CR_5m','hr_mean_5m','hr_var_5m','hr_std_5m','hr_median_5m','hr_rest_rate_5m','hr_moderate_rate_5m','hr_very_active_rate_5m','hr_0','hr_0.3','hr_0.5','hr_0.8','hr_1']      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_small = df_features.loc[:,cols].copy()\n",
    "df_features_small ['subject'] = df_features_small ['subject'].replace(to_replace = 'DND1', value = 'DND', regex = True,)\n",
    "df_features_small ['start_survey'] = pd.to_datetime(df_features_small ['start_survey'], errors='coerce')\n",
    "DF_complete = DF.merge(df_features_small, on = ['subject','start_survey'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>la_p</th>\n",
       "      <th>ha_p</th>\n",
       "      <th>ha_n</th>\n",
       "      <th>la_n</th>\n",
       "      <th>la</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>ha</th>\n",
       "      <th>start_survey</th>\n",
       "      <th>survey_no</th>\n",
       "      <th>experiment</th>\n",
       "      <th>VALENCE</th>\n",
       "      <th>VALENCE_mean</th>\n",
       "      <th>Date_only_date</th>\n",
       "      <th>HAN_actual</th>\n",
       "      <th>HAN_ideal</th>\n",
       "      <th>HAP_actual</th>\n",
       "      <th>HAP_ideal</th>\n",
       "      <th>HA_actual</th>\n",
       "      <th>HA_ideal</th>\n",
       "      <th>LAN_actual</th>\n",
       "      <th>LAN_ideal</th>\n",
       "      <th>LAP_actual</th>\n",
       "      <th>LAP_ideal</th>\n",
       "      <th>LA_actual</th>\n",
       "      <th>LA_ideal</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>N_ideal</th>\n",
       "      <th>P_actual</th>\n",
       "      <th>P_ideal</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Children</th>\n",
       "      <th>Household_income</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_FS</th>\n",
       "      <th>BAS_RR</th>\n",
       "      <th>BIS.5</th>\n",
       "      <th>BIS_total</th>\n",
       "      <th>NS_total</th>\n",
       "      <th>Conscientiousness_scaled</th>\n",
       "      <th>Extraversion_scaled</th>\n",
       "      <th>Neuroticism_scaled</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>FTP</th>\n",
       "      <th>SBQ</th>\n",
       "      <th>Date</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Biracial</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Hispanic</th>\n",
       "      <th>Ethnicity_Hispanic/Caucasian</th>\n",
       "      <th>Ethnicity_Hispanic/Other</th>\n",
       "      <th>Ethnicity_More than 1 race</th>\n",
       "      <th>Ethnicity_Native Hawaiian/Pacific Islander</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "      <th>Ethnicity_White/Pacific Islander</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Engaged</th>\n",
       "      <th>Marital_Status_Living with partner</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Widowed</th>\n",
       "      <th>Period_of_day_Evening</th>\n",
       "      <th>Period_of_day_Morning</th>\n",
       "      <th>Period_of_day_Night</th>\n",
       "      <th>start_survey_30m_ahead</th>\n",
       "      <th>start_survey_1h_ahead</th>\n",
       "      <th>start_survey_3h_ahead</th>\n",
       "      <th>start_survey_5m_ahead</th>\n",
       "      <th>start_survey_10m_ahead</th>\n",
       "      <th>step_max</th>\n",
       "      <th>step_min</th>\n",
       "      <th>step_median</th>\n",
       "      <th>steps_max_3h</th>\n",
       "      <th>steps_min_3h</th>\n",
       "      <th>steps_mean_3h</th>\n",
       "      <th>steps_var_3h</th>\n",
       "      <th>steps_median_3h</th>\n",
       "      <th>move_rate_3h</th>\n",
       "      <th>active_rate_3h</th>\n",
       "      <th>very_active_rate_3h</th>\n",
       "      <th>running_rate_3h</th>\n",
       "      <th>steps_max_1h</th>\n",
       "      <th>steps_min_1h</th>\n",
       "      <th>steps_mean_1h</th>\n",
       "      <th>steps_var_1h</th>\n",
       "      <th>steps_median_1h</th>\n",
       "      <th>move_rate_1h</th>\n",
       "      <th>active_rate_1h</th>\n",
       "      <th>very_active_rate_1h</th>\n",
       "      <th>running_rate_1h</th>\n",
       "      <th>steps_max_30m</th>\n",
       "      <th>steps_min_30m</th>\n",
       "      <th>steps_mean_30m</th>\n",
       "      <th>steps_var_30m</th>\n",
       "      <th>steps_median_30m</th>\n",
       "      <th>move_rate_30m</th>\n",
       "      <th>active_rate_30m</th>\n",
       "      <th>very_active_rate_30m</th>\n",
       "      <th>running_rate_30m</th>\n",
       "      <th>steps_max_10m</th>\n",
       "      <th>steps_min_10m</th>\n",
       "      <th>steps_mean_10m</th>\n",
       "      <th>steps_var_10m</th>\n",
       "      <th>steps_median_10m</th>\n",
       "      <th>move_rate_10m</th>\n",
       "      <th>active_rate_10m</th>\n",
       "      <th>very_active_rate_10m</th>\n",
       "      <th>running_rate_10m</th>\n",
       "      <th>steps_max_5m</th>\n",
       "      <th>steps_min_5m</th>\n",
       "      <th>steps_mean_5m</th>\n",
       "      <th>steps_var_5m</th>\n",
       "      <th>steps_median_5m</th>\n",
       "      <th>move_rate_5m</th>\n",
       "      <th>active_rate_5m</th>\n",
       "      <th>very_active_rate_5m</th>\n",
       "      <th>running_rate_5m</th>\n",
       "      <th>hr_max</th>\n",
       "      <th>hr_min</th>\n",
       "      <th>hr_med</th>\n",
       "      <th>SDNN_3h</th>\n",
       "      <th>pHR2_3h</th>\n",
       "      <th>rMSSD_3h</th>\n",
       "      <th>low_hr_3h</th>\n",
       "      <th>high_hr_3h</th>\n",
       "      <th>l_h_3h</th>\n",
       "      <th>CR_3h</th>\n",
       "      <th>hr_mean_3h</th>\n",
       "      <th>hr_var_3h</th>\n",
       "      <th>hr_std_3h</th>\n",
       "      <th>hr_median_3h</th>\n",
       "      <th>hr_rest_rate_3h</th>\n",
       "      <th>hr_moderate_rate_3h</th>\n",
       "      <th>hr_very_active_rate_3h</th>\n",
       "      <th>SDNN_1h</th>\n",
       "      <th>pHR2_1h</th>\n",
       "      <th>rMSSD_1h</th>\n",
       "      <th>low_hr_1h</th>\n",
       "      <th>high_hr_1h</th>\n",
       "      <th>l_h_1h</th>\n",
       "      <th>CR_1h</th>\n",
       "      <th>hr_mean_1h</th>\n",
       "      <th>hr_var_1h</th>\n",
       "      <th>hr_std_1h</th>\n",
       "      <th>hr_median_1h</th>\n",
       "      <th>hr_rest_rate_1h</th>\n",
       "      <th>hr_moderate_rate_1h</th>\n",
       "      <th>hr_very_active_rate_1h</th>\n",
       "      <th>SDNN_30m</th>\n",
       "      <th>pHR2_30m</th>\n",
       "      <th>rMSSD_30m</th>\n",
       "      <th>low_hr_30m</th>\n",
       "      <th>high_hr_30m</th>\n",
       "      <th>l_h_30m</th>\n",
       "      <th>CR_30m</th>\n",
       "      <th>hr_mean_30m</th>\n",
       "      <th>hr_var_30m</th>\n",
       "      <th>hr_std_30m</th>\n",
       "      <th>hr_median_30m</th>\n",
       "      <th>hr_rest_rate_30m</th>\n",
       "      <th>hr_moderate_rate_30m</th>\n",
       "      <th>hr_very_active_rate_30m</th>\n",
       "      <th>SDNN_10m</th>\n",
       "      <th>pHR2_10m</th>\n",
       "      <th>rMSSD_10m</th>\n",
       "      <th>low_hr_10m</th>\n",
       "      <th>high_hr_10m</th>\n",
       "      <th>l_h_10m</th>\n",
       "      <th>CR_10m</th>\n",
       "      <th>hr_mean_10m</th>\n",
       "      <th>hr_var_10m</th>\n",
       "      <th>hr_std_10m</th>\n",
       "      <th>hr_median_10m</th>\n",
       "      <th>hr_rest_rate_10m</th>\n",
       "      <th>hr_moderate_rate_10m</th>\n",
       "      <th>hr_very_active_rate_10m</th>\n",
       "      <th>SDNN_5m</th>\n",
       "      <th>pHR2_5m</th>\n",
       "      <th>rMSSD_5m</th>\n",
       "      <th>low_hr_5m</th>\n",
       "      <th>high_hr_5m</th>\n",
       "      <th>l_h_5m</th>\n",
       "      <th>CR_5m</th>\n",
       "      <th>hr_mean_5m</th>\n",
       "      <th>hr_var_5m</th>\n",
       "      <th>hr_std_5m</th>\n",
       "      <th>hr_median_5m</th>\n",
       "      <th>hr_rest_rate_5m</th>\n",
       "      <th>hr_moderate_rate_5m</th>\n",
       "      <th>hr_very_active_rate_5m</th>\n",
       "      <th>hr_0</th>\n",
       "      <th>hr_0.3</th>\n",
       "      <th>hr_0.5</th>\n",
       "      <th>hr_0.8</th>\n",
       "      <th>hr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1079</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-09-03 10:43:07</td>\n",
       "      <td>11</td>\n",
       "      <td>R00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1079</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.351541</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>228.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-03 10:13:07</td>\n",
       "      <td>2016-09-03 09:43:07</td>\n",
       "      <td>2016-09-03 07:43:07</td>\n",
       "      <td>2016-09-03 10:38:07</td>\n",
       "      <td>2016-09-03 10:33:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1079</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-09-03 15:02:31</td>\n",
       "      <td>12</td>\n",
       "      <td>R00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1079</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.351541</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>228.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-03 14:32:31</td>\n",
       "      <td>2016-09-03 14:02:31</td>\n",
       "      <td>2016-09-03 12:02:31</td>\n",
       "      <td>2016-09-03 14:57:31</td>\n",
       "      <td>2016-09-03 14:52:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.069608</td>\n",
       "      <td>1.359787</td>\n",
       "      <td>61.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>70.7238</td>\n",
       "      <td>17.558933</td>\n",
       "      <td>4.190338</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.132223</td>\n",
       "      <td>0.390793</td>\n",
       "      <td>0.018609</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>1.380776</td>\n",
       "      <td>61.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.61157</td>\n",
       "      <td>67.285714</td>\n",
       "      <td>6.142412</td>\n",
       "      <td>2.478389</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.397516</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.03871</td>\n",
       "      <td>1.150035</td>\n",
       "      <td>61.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.835616</td>\n",
       "      <td>0.603306</td>\n",
       "      <td>66.532051</td>\n",
       "      <td>6.121547</td>\n",
       "      <td>2.474176</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.040016</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>66.4</td>\n",
       "      <td>8.408163</td>\n",
       "      <td>2.899683</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1.208941</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>66.0</td>\n",
       "      <td>11.230769</td>\n",
       "      <td>3.351234</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject  la_p  ha_p  ha_n  la_n   la    p    n   ha        start_survey  \\\n",
       "99     1079   4.0   4.0   1.0   1.0  2.0  3.0  1.0  2.0 2016-09-03 10:43:07   \n",
       "100    1079   4.0   4.0   1.0   1.0  4.0  3.0  1.0  1.0 2016-09-03 15:02:31   \n",
       "\n",
       "     survey_no experiment  VALENCE  VALENCE_mean Date_only_date  HAN_actual  \\\n",
       "99          11        R00      8.0      2.666667     2016-09-03         2.0   \n",
       "100         12        R00      8.0      2.666667     2016-09-03         2.0   \n",
       "\n",
       "     HAN_ideal  HAP_actual  HAP_ideal  HA_actual  HA_ideal  LAN_actual  \\\n",
       "99         1.0         3.8        4.4        3.0       3.0         2.0   \n",
       "100        1.0         3.8        4.4        3.0       3.0         2.0   \n",
       "\n",
       "     LAN_ideal  LAP_actual  LAP_ideal  LA_actual  LA_ideal  N_actual  N_ideal  \\\n",
       "99         1.0         4.2        4.6        2.0       1.4  1.666667      1.0   \n",
       "100        1.0         4.2        4.6        2.0       1.4  1.666667      1.0   \n",
       "\n",
       "     P_actual   P_ideal Subject   Age  Children  Household_income        BMI  \\\n",
       "99   3.666667  4.333333    1079  59.0       1.0               2.0  25.351541   \n",
       "100  3.666667  4.333333    1079  59.0       1.0               2.0  25.351541   \n",
       "\n",
       "     BAS_D  BAS_FS  BAS_RR  BIS.5  BIS_total  NS_total  \\\n",
       "99    19.0    14.0    25.0   25.0       54.0      11.0   \n",
       "100   19.0    14.0    25.0   25.0       54.0      11.0   \n",
       "\n",
       "     Conscientiousness_scaled  Extraversion_scaled  Neuroticism_scaled  SWLS  \\\n",
       "99                   0.979167             0.666667            0.083333  17.0   \n",
       "100                  0.979167             0.666667            0.083333  17.0   \n",
       "\n",
       "     FTP   SBQ       Date  Minutes Asleep  Minutes Awake  \\\n",
       "99   6.9  51.0 2016-09-03           228.0           10.0   \n",
       "100  6.9  51.0 2016-09-03           228.0           10.0   \n",
       "\n",
       "     Number of Awakenings  Time in Bed  Sex_Female  Sex_Male  Ethnicity_Asian  \\\n",
       "99                    1.0        238.0           0         1                0   \n",
       "100                   1.0        238.0           0         1                0   \n",
       "\n",
       "     Ethnicity_Biracial  Ethnicity_Black  Ethnicity_Hispanic  \\\n",
       "99                    0                1                   0   \n",
       "100                   0                1                   0   \n",
       "\n",
       "     Ethnicity_Hispanic/Caucasian  Ethnicity_Hispanic/Other  \\\n",
       "99                              0                         0   \n",
       "100                             0                         0   \n",
       "\n",
       "     Ethnicity_More than 1 race  Ethnicity_Native Hawaiian/Pacific Islander  \\\n",
       "99                            0                                           0   \n",
       "100                           0                                           0   \n",
       "\n",
       "     Ethnicity_White  Ethnicity_White/Pacific Islander  \\\n",
       "99                 0                                 0   \n",
       "100                0                                 0   \n",
       "\n",
       "     Marital_Status_Divorced  Marital_Status_Engaged  \\\n",
       "99                         0                       0   \n",
       "100                        0                       0   \n",
       "\n",
       "     Marital_Status_Living with partner  Marital_Status_Married  \\\n",
       "99                                    0                       0   \n",
       "100                                   0                       0   \n",
       "\n",
       "     Marital_Status_Single  Marital_Status_Widowed  Period_of_day_Evening  \\\n",
       "99                       1                       0                      0   \n",
       "100                      1                       0                      1   \n",
       "\n",
       "     Period_of_day_Morning  Period_of_day_Night start_survey_30m_ahead  \\\n",
       "99                       1                    0    2016-09-03 10:13:07   \n",
       "100                      0                    0    2016-09-03 14:32:31   \n",
       "\n",
       "    start_survey_1h_ahead start_survey_3h_ahead start_survey_5m_ahead  \\\n",
       "99    2016-09-03 09:43:07   2016-09-03 07:43:07   2016-09-03 10:38:07   \n",
       "100   2016-09-03 14:02:31   2016-09-03 12:02:31   2016-09-03 14:57:31   \n",
       "\n",
       "    start_survey_10m_ahead  step_max  step_min  step_median  steps_max_3h  \\\n",
       "99     2016-09-03 10:33:07       NaN       NaN          NaN           NaN   \n",
       "100    2016-09-03 14:52:31       NaN       NaN          NaN           NaN   \n",
       "\n",
       "     steps_min_3h  steps_mean_3h  steps_var_3h  steps_median_3h  move_rate_3h  \\\n",
       "99            NaN            NaN           NaN              NaN           NaN   \n",
       "100           NaN            NaN           NaN              NaN           NaN   \n",
       "\n",
       "     active_rate_3h  very_active_rate_3h  running_rate_3h  steps_max_1h  \\\n",
       "99              NaN                  NaN              NaN           NaN   \n",
       "100             NaN                  NaN              NaN           NaN   \n",
       "\n",
       "     steps_min_1h  steps_mean_1h  steps_var_1h  steps_median_1h  move_rate_1h  \\\n",
       "99            NaN            NaN           NaN              NaN           NaN   \n",
       "100           NaN            NaN           NaN              NaN           NaN   \n",
       "\n",
       "     active_rate_1h  very_active_rate_1h  running_rate_1h  steps_max_30m  \\\n",
       "99              NaN                  NaN              NaN            NaN   \n",
       "100             NaN                  NaN              NaN            NaN   \n",
       "\n",
       "     steps_min_30m  steps_mean_30m  steps_var_30m  steps_median_30m  \\\n",
       "99             NaN             NaN            NaN               NaN   \n",
       "100            NaN             NaN            NaN               NaN   \n",
       "\n",
       "     move_rate_30m  active_rate_30m  very_active_rate_30m  running_rate_30m  \\\n",
       "99             NaN              NaN                   NaN               NaN   \n",
       "100            NaN              NaN                   NaN               NaN   \n",
       "\n",
       "     steps_max_10m  steps_min_10m  steps_mean_10m  steps_var_10m  \\\n",
       "99             NaN            NaN             NaN            NaN   \n",
       "100            NaN            NaN             NaN            NaN   \n",
       "\n",
       "     steps_median_10m  move_rate_10m  active_rate_10m  very_active_rate_10m  \\\n",
       "99                NaN            NaN              NaN                   NaN   \n",
       "100               NaN            NaN              NaN                   NaN   \n",
       "\n",
       "     running_rate_10m  steps_max_5m  steps_min_5m  steps_mean_5m  \\\n",
       "99                NaN           NaN           NaN            NaN   \n",
       "100               NaN           NaN           NaN            NaN   \n",
       "\n",
       "     steps_var_5m  steps_median_5m  move_rate_5m  active_rate_5m  \\\n",
       "99            NaN              NaN           NaN             NaN   \n",
       "100           NaN              NaN           NaN             NaN   \n",
       "\n",
       "     very_active_rate_5m  running_rate_5m  hr_max  hr_min  hr_med   SDNN_3h  \\\n",
       "99                   NaN              NaN     NaN     NaN     NaN       NaN   \n",
       "100                  NaN              NaN   121.0    49.0    71.0  0.000809   \n",
       "\n",
       "      pHR2_3h  rMSSD_3h  low_hr_3h  high_hr_3h    l_h_3h     CR_3h  \\\n",
       "99        NaN       NaN        NaN         NaN       NaN       NaN   \n",
       "100  0.069608  1.359787       61.0        98.0  0.622449  0.809917   \n",
       "\n",
       "     hr_mean_3h  hr_var_3h  hr_std_3h  hr_median_3h  hr_rest_rate_3h  \\\n",
       "99          NaN        NaN        NaN           NaN              NaN   \n",
       "100     70.7238  17.558933   4.190338          70.0         0.132223   \n",
       "\n",
       "     hr_moderate_rate_3h  hr_very_active_rate_3h   SDNN_1h   pHR2_1h  \\\n",
       "99                   NaN                     NaN       NaN       NaN   \n",
       "100             0.390793                0.018609  0.000546  0.065421   \n",
       "\n",
       "     rMSSD_1h  low_hr_1h  high_hr_1h    l_h_1h    CR_1h  hr_mean_1h  \\\n",
       "99        NaN        NaN         NaN       NaN      NaN         NaN   \n",
       "100  1.380776       61.0        74.0  0.824324  0.61157   67.285714   \n",
       "\n",
       "     hr_var_1h  hr_std_1h  hr_median_1h  hr_rest_rate_1h  hr_moderate_rate_1h  \\\n",
       "99         NaN        NaN           NaN              NaN                  NaN   \n",
       "100   6.142412   2.478389          67.0         0.397516             0.049689   \n",
       "\n",
       "     hr_very_active_rate_1h  SDNN_30m  pHR2_30m  rMSSD_30m  low_hr_30m  \\\n",
       "99                      NaN       NaN       NaN        NaN         NaN   \n",
       "100                     0.0  0.000557   0.03871   1.150035        61.0   \n",
       "\n",
       "     high_hr_30m   l_h_30m    CR_30m  hr_mean_30m  hr_var_30m  hr_std_30m  \\\n",
       "99           NaN       NaN       NaN          NaN         NaN         NaN   \n",
       "100         73.0  0.835616  0.603306    66.532051    6.121547    2.474176   \n",
       "\n",
       "     hr_median_30m  hr_rest_rate_30m  hr_moderate_rate_30m  \\\n",
       "99             NaN               NaN                   NaN   \n",
       "100           66.0          0.519231              0.012821   \n",
       "\n",
       "     hr_very_active_rate_30m  SDNN_10m  pHR2_10m  rMSSD_10m  low_hr_10m  \\\n",
       "99                       NaN       NaN       NaN        NaN         NaN   \n",
       "100                      0.0  0.000654  0.020408   1.040016        61.0   \n",
       "\n",
       "     high_hr_10m   l_h_10m    CR_10m  hr_mean_10m  hr_var_10m  hr_std_10m  \\\n",
       "99           NaN       NaN       NaN          NaN         NaN         NaN   \n",
       "100         70.0  0.871429  0.578512         66.4    8.408163    2.899683   \n",
       "\n",
       "     hr_median_10m  hr_rest_rate_10m  hr_moderate_rate_10m  \\\n",
       "99             NaN               NaN                   NaN   \n",
       "100           66.0              0.54                   0.0   \n",
       "\n",
       "     hr_very_active_rate_10m   SDNN_5m   pHR2_5m  rMSSD_5m  low_hr_5m  \\\n",
       "99                       NaN       NaN       NaN       NaN        NaN   \n",
       "100                      0.0  0.000758  0.038462  1.208941       61.0   \n",
       "\n",
       "     high_hr_5m    l_h_5m     CR_5m  hr_mean_5m  hr_var_5m  hr_std_5m  \\\n",
       "99          NaN       NaN       NaN         NaN        NaN        NaN   \n",
       "100        70.0  0.871429  0.578512        66.0  11.230769   3.351234   \n",
       "\n",
       "     hr_median_5m  hr_rest_rate_5m  hr_moderate_rate_5m  \\\n",
       "99            NaN              NaN                  NaN   \n",
       "100          67.0         0.481481                  0.0   \n",
       "\n",
       "     hr_very_active_rate_5m  hr_0  hr_0.3  hr_0.5  hr_0.8   hr_1  \n",
       "99                      NaN   NaN     NaN     NaN     NaN    NaN  \n",
       "100                     0.0  49.0    66.0    71.0    80.0  121.0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_complete.iloc[[99,100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have missing case where subjects have steps data or HR bot no both. \n",
    "#### I am going to delete the cases with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2301, 205)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_complete_nona = DF_complete.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2017, 205)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_complete_nona.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING DF\n",
    "with open('./DF_comple_no_NAN.pickle', 'wb') as file:\n",
    "    pickle.dump(DF_complete_nona, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Transform\n",
    "#### I need to research more about this given that the sampling rate in this case is weird (sometime 1 every 15 scs, sometimes 1 every 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "def fourier(df,subject,start_survey, time):\n",
    "    '''\n",
    "    df : HR or STEPS\n",
    "    '''\n",
    "    delta_time = start_survey - datetime.timedelta(hours = time)\n",
    "    filtered = df.loc[(df['ID'] == subject) & ((df['date_time'] >= delta_time) &  (df['date_time'] <= start_survey))]\n",
    "    f, ps =  signal.welch (filtered['VALUE'], 1/10, scaling='spectrum') #assuming a SR of 1 smaplig every 10 sec.\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "small = fourier(HR, DF_complete_nona['subject'][5] , DF_complete_nona['start_survey'][5], 1)\n",
    "f,ps = signal.welch (small['VALUE'], 1/10, scaling='spectrum') #assuming a SR of 1 smaplig every 10 sec.\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(f,np.sqrt(ps))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('Linear spectrum [V RMS]')\n",
    "plt.title('Power spectrum (scipy.signal.welch)')\n",
    "plt.show()\n",
    "\n",
    "#Possible things to do:\n",
    "#    - Take the average power in window of [ b > freq > a ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split by subject Train / Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_We can make the assumption that every row is independent. This is not accurate, but we should research about how to deal with this._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ask kyle about how to deal with the repeated measures. <br>_\n",
    "_There is a problem In the case we include subject as a feature in a ML model, we are not going to be able to predict unknown subjects. Unless we hot encode...but:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One hot encoding cluster is an option, but this has known bad performance as explained in this excellent blog post (and as we’ll show below). Long story short, directly using high cardinality categorical variables as features in a model sucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe a Mixed Effect Random Forest could be useful. **[Link](https://towardsdatascience.com/mixed-effects-random-forests-6ecbb85cb177)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once fit the MERF can be used to predict for data in the **“Known”** clusters, that the MERF saw in training, the prediction includes the random effect correction.\n",
    "This approach should be better for Known subjects that a common RF approach. Nevertheless, the accuracy for **Unknow** subjects will depend on the complexity of the data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am going to make two different datasets just to start coding a model. \n",
    "\n",
    "One is going to be a X,y (I will use this one in a nested CV in the future) and other one would be [X_train, y_train, X_test, y_test] where the test dataset will be composed by:\n",
    "- Unknown (new)  subjects (clusters) that the model had no knowledge of at training time (I will include the subjects with the least amount of repeated measures) \n",
    "- Known  subjects (clusters) that the model trained on\n",
    "\n",
    "I am making the assumption that subjects with lower repeated measures are independent and that there is no latent variable that is correlated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>la_p</th>\n",
       "      <th>ha_p</th>\n",
       "      <th>ha_n</th>\n",
       "      <th>la_n</th>\n",
       "      <th>la</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>ha</th>\n",
       "      <th>start_survey</th>\n",
       "      <th>survey_no</th>\n",
       "      <th>experiment</th>\n",
       "      <th>VALENCE</th>\n",
       "      <th>VALENCE_mean</th>\n",
       "      <th>Date_only_date</th>\n",
       "      <th>HAN_actual</th>\n",
       "      <th>HAN_ideal</th>\n",
       "      <th>HAP_actual</th>\n",
       "      <th>HAP_ideal</th>\n",
       "      <th>HA_actual</th>\n",
       "      <th>HA_ideal</th>\n",
       "      <th>LAN_actual</th>\n",
       "      <th>LAN_ideal</th>\n",
       "      <th>LAP_actual</th>\n",
       "      <th>LAP_ideal</th>\n",
       "      <th>LA_actual</th>\n",
       "      <th>LA_ideal</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>N_ideal</th>\n",
       "      <th>P_actual</th>\n",
       "      <th>P_ideal</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Children</th>\n",
       "      <th>Household_income</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_FS</th>\n",
       "      <th>BAS_RR</th>\n",
       "      <th>BIS.5</th>\n",
       "      <th>BIS_total</th>\n",
       "      <th>NS_total</th>\n",
       "      <th>Conscientiousness_scaled</th>\n",
       "      <th>Extraversion_scaled</th>\n",
       "      <th>Neuroticism_scaled</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>FTP</th>\n",
       "      <th>SBQ</th>\n",
       "      <th>Date</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Biracial</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Hispanic</th>\n",
       "      <th>Ethnicity_Hispanic/Caucasian</th>\n",
       "      <th>Ethnicity_Hispanic/Other</th>\n",
       "      <th>Ethnicity_More than 1 race</th>\n",
       "      <th>Ethnicity_Native Hawaiian/Pacific Islander</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "      <th>Ethnicity_White/Pacific Islander</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Engaged</th>\n",
       "      <th>Marital_Status_Living with partner</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Widowed</th>\n",
       "      <th>Period_of_day_Evening</th>\n",
       "      <th>Period_of_day_Morning</th>\n",
       "      <th>Period_of_day_Night</th>\n",
       "      <th>start_survey_30m_ahead</th>\n",
       "      <th>start_survey_1h_ahead</th>\n",
       "      <th>start_survey_3h_ahead</th>\n",
       "      <th>start_survey_5m_ahead</th>\n",
       "      <th>start_survey_10m_ahead</th>\n",
       "      <th>step_max</th>\n",
       "      <th>step_min</th>\n",
       "      <th>step_median</th>\n",
       "      <th>steps_max_3h</th>\n",
       "      <th>steps_min_3h</th>\n",
       "      <th>steps_mean_3h</th>\n",
       "      <th>steps_var_3h</th>\n",
       "      <th>steps_median_3h</th>\n",
       "      <th>move_rate_3h</th>\n",
       "      <th>active_rate_3h</th>\n",
       "      <th>very_active_rate_3h</th>\n",
       "      <th>running_rate_3h</th>\n",
       "      <th>steps_max_1h</th>\n",
       "      <th>steps_min_1h</th>\n",
       "      <th>steps_mean_1h</th>\n",
       "      <th>steps_var_1h</th>\n",
       "      <th>steps_median_1h</th>\n",
       "      <th>move_rate_1h</th>\n",
       "      <th>active_rate_1h</th>\n",
       "      <th>very_active_rate_1h</th>\n",
       "      <th>running_rate_1h</th>\n",
       "      <th>steps_max_30m</th>\n",
       "      <th>steps_min_30m</th>\n",
       "      <th>steps_mean_30m</th>\n",
       "      <th>steps_var_30m</th>\n",
       "      <th>steps_median_30m</th>\n",
       "      <th>move_rate_30m</th>\n",
       "      <th>active_rate_30m</th>\n",
       "      <th>very_active_rate_30m</th>\n",
       "      <th>running_rate_30m</th>\n",
       "      <th>steps_max_10m</th>\n",
       "      <th>steps_min_10m</th>\n",
       "      <th>steps_mean_10m</th>\n",
       "      <th>steps_var_10m</th>\n",
       "      <th>steps_median_10m</th>\n",
       "      <th>move_rate_10m</th>\n",
       "      <th>active_rate_10m</th>\n",
       "      <th>very_active_rate_10m</th>\n",
       "      <th>running_rate_10m</th>\n",
       "      <th>steps_max_5m</th>\n",
       "      <th>steps_min_5m</th>\n",
       "      <th>steps_mean_5m</th>\n",
       "      <th>steps_var_5m</th>\n",
       "      <th>steps_median_5m</th>\n",
       "      <th>move_rate_5m</th>\n",
       "      <th>active_rate_5m</th>\n",
       "      <th>very_active_rate_5m</th>\n",
       "      <th>running_rate_5m</th>\n",
       "      <th>hr_max</th>\n",
       "      <th>hr_min</th>\n",
       "      <th>hr_med</th>\n",
       "      <th>SDNN_3h</th>\n",
       "      <th>pHR2_3h</th>\n",
       "      <th>rMSSD_3h</th>\n",
       "      <th>low_hr_3h</th>\n",
       "      <th>high_hr_3h</th>\n",
       "      <th>l_h_3h</th>\n",
       "      <th>CR_3h</th>\n",
       "      <th>hr_mean_3h</th>\n",
       "      <th>hr_var_3h</th>\n",
       "      <th>hr_std_3h</th>\n",
       "      <th>hr_median_3h</th>\n",
       "      <th>hr_rest_rate_3h</th>\n",
       "      <th>hr_moderate_rate_3h</th>\n",
       "      <th>hr_very_active_rate_3h</th>\n",
       "      <th>SDNN_1h</th>\n",
       "      <th>pHR2_1h</th>\n",
       "      <th>rMSSD_1h</th>\n",
       "      <th>low_hr_1h</th>\n",
       "      <th>high_hr_1h</th>\n",
       "      <th>l_h_1h</th>\n",
       "      <th>CR_1h</th>\n",
       "      <th>hr_mean_1h</th>\n",
       "      <th>hr_var_1h</th>\n",
       "      <th>hr_std_1h</th>\n",
       "      <th>hr_median_1h</th>\n",
       "      <th>hr_rest_rate_1h</th>\n",
       "      <th>hr_moderate_rate_1h</th>\n",
       "      <th>hr_very_active_rate_1h</th>\n",
       "      <th>SDNN_30m</th>\n",
       "      <th>pHR2_30m</th>\n",
       "      <th>rMSSD_30m</th>\n",
       "      <th>low_hr_30m</th>\n",
       "      <th>high_hr_30m</th>\n",
       "      <th>l_h_30m</th>\n",
       "      <th>CR_30m</th>\n",
       "      <th>hr_mean_30m</th>\n",
       "      <th>hr_var_30m</th>\n",
       "      <th>hr_std_30m</th>\n",
       "      <th>hr_median_30m</th>\n",
       "      <th>hr_rest_rate_30m</th>\n",
       "      <th>hr_moderate_rate_30m</th>\n",
       "      <th>hr_very_active_rate_30m</th>\n",
       "      <th>SDNN_10m</th>\n",
       "      <th>pHR2_10m</th>\n",
       "      <th>rMSSD_10m</th>\n",
       "      <th>low_hr_10m</th>\n",
       "      <th>high_hr_10m</th>\n",
       "      <th>l_h_10m</th>\n",
       "      <th>CR_10m</th>\n",
       "      <th>hr_mean_10m</th>\n",
       "      <th>hr_var_10m</th>\n",
       "      <th>hr_std_10m</th>\n",
       "      <th>hr_median_10m</th>\n",
       "      <th>hr_rest_rate_10m</th>\n",
       "      <th>hr_moderate_rate_10m</th>\n",
       "      <th>hr_very_active_rate_10m</th>\n",
       "      <th>SDNN_5m</th>\n",
       "      <th>pHR2_5m</th>\n",
       "      <th>rMSSD_5m</th>\n",
       "      <th>low_hr_5m</th>\n",
       "      <th>high_hr_5m</th>\n",
       "      <th>l_h_5m</th>\n",
       "      <th>CR_5m</th>\n",
       "      <th>hr_mean_5m</th>\n",
       "      <th>hr_var_5m</th>\n",
       "      <th>hr_std_5m</th>\n",
       "      <th>hr_median_5m</th>\n",
       "      <th>hr_rest_rate_5m</th>\n",
       "      <th>hr_moderate_rate_5m</th>\n",
       "      <th>hr_very_active_rate_5m</th>\n",
       "      <th>hr_0</th>\n",
       "      <th>hr_0.3</th>\n",
       "      <th>hr_0.5</th>\n",
       "      <th>hr_0.8</th>\n",
       "      <th>hr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-20 21:13:34</td>\n",
       "      <td>4</td>\n",
       "      <td>R00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>147.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-20 20:43:34</td>\n",
       "      <td>2016-02-20 20:13:34</td>\n",
       "      <td>2016-02-20 18:13:34</td>\n",
       "      <td>2016-02-20 21:08:34</td>\n",
       "      <td>2016-02-20 21:03:34</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.311111</td>\n",
       "      <td>209.813284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.216667</td>\n",
       "      <td>133.325141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>260.947126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>726.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1251.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>127.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.151828</td>\n",
       "      <td>2.057286</td>\n",
       "      <td>63.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>79.605805</td>\n",
       "      <td>107.223097</td>\n",
       "      <td>10.354859</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.555243</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>1.950937</td>\n",
       "      <td>64.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>76.411043</td>\n",
       "      <td>31.498216</td>\n",
       "      <td>5.612327</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.690184</td>\n",
       "      <td>0.070552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.140244</td>\n",
       "      <td>1.844570</td>\n",
       "      <td>69.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>78.654545</td>\n",
       "      <td>37.800665</td>\n",
       "      <td>6.148225</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.539394</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>1.978700</td>\n",
       "      <td>71.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>81.916667</td>\n",
       "      <td>61.806497</td>\n",
       "      <td>7.861711</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.968502</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>85.757576</td>\n",
       "      <td>68.189394</td>\n",
       "      <td>8.257687</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-21 07:11:48</td>\n",
       "      <td>5</td>\n",
       "      <td>R00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>317.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-21 06:41:48</td>\n",
       "      <td>2016-02-21 06:11:48</td>\n",
       "      <td>2016-02-21 04:11:48</td>\n",
       "      <td>2016-02-21 07:06:48</td>\n",
       "      <td>2016-02-21 07:01:48</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.205556</td>\n",
       "      <td>60.074829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>17.922034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.648276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>77.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.164480</td>\n",
       "      <td>3.189919</td>\n",
       "      <td>42.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>58.940524</td>\n",
       "      <td>93.349638</td>\n",
       "      <td>9.661762</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.553427</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>2.899143</td>\n",
       "      <td>44.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>59.724234</td>\n",
       "      <td>113.496366</td>\n",
       "      <td>10.653467</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.604457</td>\n",
       "      <td>0.200557</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.251811</td>\n",
       "      <td>50.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>60.913514</td>\n",
       "      <td>150.818566</td>\n",
       "      <td>12.280821</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>3.180557</td>\n",
       "      <td>50.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>66.628571</td>\n",
       "      <td>325.019462</td>\n",
       "      <td>18.028296</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.456693</td>\n",
       "      <td>53.034483</td>\n",
       "      <td>3.463054</td>\n",
       "      <td>1.860928</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-21 16:21:31</td>\n",
       "      <td>6</td>\n",
       "      <td>R00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>317.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-21 15:51:31</td>\n",
       "      <td>2016-02-21 15:21:31</td>\n",
       "      <td>2016-02-21 13:21:31</td>\n",
       "      <td>2016-02-21 16:16:31</td>\n",
       "      <td>2016-02-21 16:11:31</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.950000</td>\n",
       "      <td>417.265642</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.566667</td>\n",
       "      <td>434.148023</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>484.533333</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>742.622222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1029.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>127.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.168531</td>\n",
       "      <td>2.259787</td>\n",
       "      <td>58.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>84.674367</td>\n",
       "      <td>148.673153</td>\n",
       "      <td>12.193160</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.346498</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>2.271544</td>\n",
       "      <td>58.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.487395</td>\n",
       "      <td>0.937008</td>\n",
       "      <td>89.058427</td>\n",
       "      <td>183.032615</td>\n",
       "      <td>13.528955</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.925843</td>\n",
       "      <td>0.476404</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>2.237032</td>\n",
       "      <td>66.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>88.798283</td>\n",
       "      <td>154.722066</td>\n",
       "      <td>12.438732</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.446352</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.455153</td>\n",
       "      <td>66.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>77.589041</td>\n",
       "      <td>38.745434</td>\n",
       "      <td>6.224583</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>2.037527</td>\n",
       "      <td>66.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>76.852941</td>\n",
       "      <td>51.947415</td>\n",
       "      <td>7.207456</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>42.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1047</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-22 08:38:31</td>\n",
       "      <td>7</td>\n",
       "      <td>R00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-22 08:08:31</td>\n",
       "      <td>2016-02-22 07:38:31</td>\n",
       "      <td>2016-02-22 05:38:31</td>\n",
       "      <td>2016-02-22 08:33:31</td>\n",
       "      <td>2016-02-22 08:28:31</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>124.613128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>193.648305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.125108</td>\n",
       "      <td>2.243964</td>\n",
       "      <td>43.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.387387</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>73.071552</td>\n",
       "      <td>166.872357</td>\n",
       "      <td>12.917908</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.709483</td>\n",
       "      <td>0.141379</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.077694</td>\n",
       "      <td>1.869824</td>\n",
       "      <td>57.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>72.535000</td>\n",
       "      <td>40.655414</td>\n",
       "      <td>6.376160</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.046422</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>71.228856</td>\n",
       "      <td>10.887363</td>\n",
       "      <td>3.299600</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1.201850</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>10.870624</td>\n",
       "      <td>3.297063</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>69.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>8.648649</td>\n",
       "      <td>2.940858</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1047</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-02-22 13:57:37</td>\n",
       "      <td>8</td>\n",
       "      <td>R00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-22 13:27:37</td>\n",
       "      <td>2016-02-22 12:57:37</td>\n",
       "      <td>2016-02-22 10:57:37</td>\n",
       "      <td>2016-02-22 13:52:37</td>\n",
       "      <td>2016-02-22 13:47:37</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.577778</td>\n",
       "      <td>496.803973</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>535.345763</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>61.610345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.170872</td>\n",
       "      <td>2.072757</td>\n",
       "      <td>65.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>98.662824</td>\n",
       "      <td>119.034032</td>\n",
       "      <td>10.910272</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.115566</td>\n",
       "      <td>1.631789</td>\n",
       "      <td>77.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.877863</td>\n",
       "      <td>95.423529</td>\n",
       "      <td>119.768313</td>\n",
       "      <td>10.943871</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628235</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>1.242368</td>\n",
       "      <td>77.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>85.583784</td>\n",
       "      <td>77.168214</td>\n",
       "      <td>8.784544</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194595</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820413</td>\n",
       "      <td>79.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.648855</td>\n",
       "      <td>81.320755</td>\n",
       "      <td>2.914369</td>\n",
       "      <td>1.707152</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721110</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.641221</td>\n",
       "      <td>81.846154</td>\n",
       "      <td>2.935385</td>\n",
       "      <td>1.713296</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  la_p  ha_p  ha_n  la_n   la    p    n   ha        start_survey  \\\n",
       "2    1047   4.0   3.0   1.0   1.0  2.0  4.0  1.0  1.0 2016-02-20 21:13:34   \n",
       "3    1047   4.0   1.0   1.0   2.0  4.0  2.0  1.0  1.0 2016-02-21 07:11:48   \n",
       "4    1047   2.0   2.0   1.0   2.0  1.0  5.0  1.0  1.0 2016-02-21 16:21:31   \n",
       "5    1047   3.0   1.0   1.0   2.0  2.0  3.0  1.0  1.0 2016-02-22 08:38:31   \n",
       "6    1047   3.0   3.0   1.0   1.0  2.0  4.0  1.0  2.0 2016-02-22 13:57:37   \n",
       "\n",
       "   survey_no experiment  VALENCE  VALENCE_mean Date_only_date  HAN_actual  \\\n",
       "2          4        R00      8.0      2.666667     2016-02-20    1.333333   \n",
       "3          5        R00      3.0      1.000000     2016-02-21    1.333333   \n",
       "4          6        R00      5.0      1.666667     2016-02-21    1.333333   \n",
       "5          7        R00      3.0      1.000000     2016-02-22    1.333333   \n",
       "6          8        R00      7.0      2.333333     2016-02-22    1.333333   \n",
       "\n",
       "   HAN_ideal  HAP_actual  HAP_ideal  HA_actual  HA_ideal  LAN_actual  \\\n",
       "2        1.0         2.6        2.8        2.0  2.333333    1.666667   \n",
       "3        1.0         2.6        2.8        2.0  2.333333    1.666667   \n",
       "4        1.0         2.6        2.8        2.0  2.333333    1.666667   \n",
       "5        1.0         2.6        2.8        2.0  2.333333    1.666667   \n",
       "6        1.0         2.6        2.8        2.0  2.333333    1.666667   \n",
       "\n",
       "   LAN_ideal  LAP_actual  LAP_ideal  LA_actual  LA_ideal  N_actual  N_ideal  \\\n",
       "2        1.0         3.6        4.2        2.0       1.8       1.0      1.0   \n",
       "3        1.0         3.6        4.2        2.0       1.8       1.0      1.0   \n",
       "4        1.0         3.6        4.2        2.0       1.8       1.0      1.0   \n",
       "5        1.0         3.6        4.2        2.0       1.8       1.0      1.0   \n",
       "6        1.0         3.6        4.2        2.0       1.8       1.0      1.0   \n",
       "\n",
       "   P_actual   P_ideal Subject   Age  Children  Household_income        BMI  \\\n",
       "2  4.333333  4.333333    1047  43.0       3.0               9.0  27.328927   \n",
       "3  4.333333  4.333333    1047  43.0       3.0               9.0  27.328927   \n",
       "4  4.333333  4.333333    1047  43.0       3.0               9.0  27.328927   \n",
       "5  4.333333  4.333333    1047  43.0       3.0               9.0  27.328927   \n",
       "6  4.333333  4.333333    1047  43.0       3.0               9.0  27.328927   \n",
       "\n",
       "   BAS_D  BAS_FS  BAS_RR  BIS.5  BIS_total  NS_total  \\\n",
       "2   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "3   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "4   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "5   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "6   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "\n",
       "   Conscientiousness_scaled  Extraversion_scaled  Neuroticism_scaled  SWLS  \\\n",
       "2                     0.875             0.583333            0.208333  25.0   \n",
       "3                     0.875             0.583333            0.208333  25.0   \n",
       "4                     0.875             0.583333            0.208333  25.0   \n",
       "5                     0.875             0.583333            0.208333  25.0   \n",
       "6                     0.875             0.583333            0.208333  25.0   \n",
       "\n",
       "   FTP   SBQ       Date  Minutes Asleep  Minutes Awake  Number of Awakenings  \\\n",
       "2  5.5  60.0 2016-02-20           147.0           10.0                   6.0   \n",
       "3  5.5  60.0 2016-02-21           317.0           40.0                  17.0   \n",
       "4  5.5  60.0 2016-02-21           317.0           40.0                  17.0   \n",
       "5  5.5  60.0 2016-02-22           419.0           34.0                  17.0   \n",
       "6  5.5  60.0 2016-02-22           419.0           34.0                  17.0   \n",
       "\n",
       "   Time in Bed  Sex_Female  Sex_Male  Ethnicity_Asian  Ethnicity_Biracial  \\\n",
       "2        157.0           1         0                0                   0   \n",
       "3        357.0           1         0                0                   0   \n",
       "4        357.0           1         0                0                   0   \n",
       "5        453.0           1         0                0                   0   \n",
       "6        453.0           1         0                0                   0   \n",
       "\n",
       "   Ethnicity_Black  Ethnicity_Hispanic  Ethnicity_Hispanic/Caucasian  \\\n",
       "2                0                   0                             0   \n",
       "3                0                   0                             0   \n",
       "4                0                   0                             0   \n",
       "5                0                   0                             0   \n",
       "6                0                   0                             0   \n",
       "\n",
       "   Ethnicity_Hispanic/Other  Ethnicity_More than 1 race  \\\n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "5                         0                           0   \n",
       "6                         0                           0   \n",
       "\n",
       "   Ethnicity_Native Hawaiian/Pacific Islander  Ethnicity_White  \\\n",
       "2                                           0                1   \n",
       "3                                           0                1   \n",
       "4                                           0                1   \n",
       "5                                           0                1   \n",
       "6                                           0                1   \n",
       "\n",
       "   Ethnicity_White/Pacific Islander  Marital_Status_Divorced  \\\n",
       "2                                 0                        0   \n",
       "3                                 0                        0   \n",
       "4                                 0                        0   \n",
       "5                                 0                        0   \n",
       "6                                 0                        0   \n",
       "\n",
       "   Marital_Status_Engaged  Marital_Status_Living with partner  \\\n",
       "2                       0                                   0   \n",
       "3                       0                                   0   \n",
       "4                       0                                   0   \n",
       "5                       0                                   0   \n",
       "6                       0                                   0   \n",
       "\n",
       "   Marital_Status_Married  Marital_Status_Single  Marital_Status_Widowed  \\\n",
       "2                       1                      0                       0   \n",
       "3                       1                      0                       0   \n",
       "4                       1                      0                       0   \n",
       "5                       1                      0                       0   \n",
       "6                       1                      0                       0   \n",
       "\n",
       "   Period_of_day_Evening  Period_of_day_Morning  Period_of_day_Night  \\\n",
       "2                      0                      0                    1   \n",
       "3                      0                      1                    0   \n",
       "4                      1                      0                    0   \n",
       "5                      0                      1                    0   \n",
       "6                      1                      0                    0   \n",
       "\n",
       "  start_survey_30m_ahead start_survey_1h_ahead start_survey_3h_ahead  \\\n",
       "2    2016-02-20 20:43:34   2016-02-20 20:13:34   2016-02-20 18:13:34   \n",
       "3    2016-02-21 06:41:48   2016-02-21 06:11:48   2016-02-21 04:11:48   \n",
       "4    2016-02-21 15:51:31   2016-02-21 15:21:31   2016-02-21 13:21:31   \n",
       "5    2016-02-22 08:08:31   2016-02-22 07:38:31   2016-02-22 05:38:31   \n",
       "6    2016-02-22 13:27:37   2016-02-22 12:57:37   2016-02-22 10:57:37   \n",
       "\n",
       "  start_survey_5m_ahead start_survey_10m_ahead  step_max  step_min  \\\n",
       "2   2016-02-20 21:08:34    2016-02-20 21:03:34     110.0       0.0   \n",
       "3   2016-02-21 07:06:48    2016-02-21 07:01:48     111.0       0.0   \n",
       "4   2016-02-21 16:16:31    2016-02-21 16:11:31     111.0       0.0   \n",
       "5   2016-02-22 08:33:31    2016-02-22 08:28:31     111.0       0.0   \n",
       "6   2016-02-22 13:52:37    2016-02-22 13:47:37     111.0       0.0   \n",
       "\n",
       "   step_median  steps_max_3h  steps_min_3h  steps_mean_3h  steps_var_3h  \\\n",
       "2          0.0         110.0           0.0       4.311111    209.813284   \n",
       "3          0.0          70.0           0.0       1.205556     60.074829   \n",
       "4          0.0         102.0           0.0      18.950000    417.265642   \n",
       "5          0.0          72.0           0.0       3.750000    124.613128   \n",
       "6          0.0          87.0           0.0      26.577778    496.803973   \n",
       "\n",
       "   steps_median_3h  move_rate_3h  active_rate_3h  very_active_rate_3h  \\\n",
       "2              0.0      0.155556        0.100000             0.066667   \n",
       "3              0.0      0.044444        0.033333             0.016667   \n",
       "4             14.5      0.672222        0.577778             0.377778   \n",
       "5              0.0      0.166667        0.105556             0.061111   \n",
       "6             22.5      0.766667        0.727778             0.550000   \n",
       "\n",
       "   running_rate_3h  steps_max_1h  steps_min_1h  steps_mean_1h  steps_var_1h  \\\n",
       "2         0.044444          76.0           0.0       2.216667    133.325141   \n",
       "3         0.011111          21.0           0.0       1.100000     17.922034   \n",
       "4         0.238889          86.0           0.0      19.566667    434.148023   \n",
       "5         0.038889          72.0           0.0       3.250000    193.648305   \n",
       "6         0.383333          87.0           0.0      19.100000    535.345763   \n",
       "\n",
       "   steps_median_1h  move_rate_1h  active_rate_1h  very_active_rate_1h  \\\n",
       "2              0.0      0.050000        0.033333             0.033333   \n",
       "3              0.0      0.066667        0.066667             0.016667   \n",
       "4             14.5      0.683333        0.583333             0.400000   \n",
       "5              0.0      0.066667        0.050000             0.050000   \n",
       "6             14.0      0.550000        0.516667             0.366667   \n",
       "\n",
       "   running_rate_1h  steps_max_30m  steps_min_30m  steps_mean_30m  \\\n",
       "2         0.033333           76.0            0.0        4.133333   \n",
       "3         0.000000           21.0            0.0        1.800000   \n",
       "4         0.233333           74.0            0.0       24.466667   \n",
       "5         0.050000            0.0            0.0        0.000000   \n",
       "6         0.266667           31.0            0.0        2.900000   \n",
       "\n",
       "   steps_var_30m  steps_median_30m  move_rate_30m  active_rate_30m  \\\n",
       "2     260.947126               0.0       0.066667         0.066667   \n",
       "3      30.648276               0.0       0.100000         0.100000   \n",
       "4     484.533333              23.0       0.733333         0.666667   \n",
       "5       0.000000               0.0       0.000000         0.000000   \n",
       "6      61.610345               0.0       0.133333         0.133333   \n",
       "\n",
       "   very_active_rate_30m  running_rate_30m  steps_max_10m  steps_min_10m  \\\n",
       "2              0.066667          0.066667           76.0            0.0   \n",
       "3              0.033333          0.000000           21.0            0.0   \n",
       "4              0.533333          0.333333           74.0            0.0   \n",
       "5              0.000000          0.000000            0.0            0.0   \n",
       "6              0.066667          0.033333            0.0            0.0   \n",
       "\n",
       "   steps_mean_10m  steps_var_10m  steps_median_10m  move_rate_10m  \\\n",
       "2            12.4     726.933333               0.0            0.2   \n",
       "3             5.4      77.155556               0.0            0.3   \n",
       "4            21.8     742.622222              16.0            0.6   \n",
       "5             0.0       0.000000               0.0            0.0   \n",
       "6             0.0       0.000000               0.0            0.0   \n",
       "\n",
       "   active_rate_10m  very_active_rate_10m  running_rate_10m  steps_max_5m  \\\n",
       "2              0.2                   0.2               0.2          76.0   \n",
       "3              0.3                   0.1               0.0           0.0   \n",
       "4              0.6                   0.4               0.2          74.0   \n",
       "5              0.0                   0.0               0.0           0.0   \n",
       "6              0.0                   0.0               0.0           0.0   \n",
       "\n",
       "   steps_min_5m  steps_mean_5m  steps_var_5m  steps_median_5m  move_rate_5m  \\\n",
       "2           0.0           24.8        1251.2              0.0           0.4   \n",
       "3           0.0            0.0           0.0              0.0           0.0   \n",
       "4           0.0           19.2        1029.2              0.0           0.4   \n",
       "5           0.0            0.0           0.0              0.0           0.0   \n",
       "6           0.0            0.0           0.0              0.0           0.0   \n",
       "\n",
       "   active_rate_5m  very_active_rate_5m  running_rate_5m  hr_max  hr_min  \\\n",
       "2             0.4                  0.4              0.4   127.0    63.0   \n",
       "3             0.0                  0.0              0.0   127.0    42.0   \n",
       "4             0.4                  0.4              0.2   127.0    42.0   \n",
       "5             0.0                  0.0              0.0   131.0    42.0   \n",
       "6             0.0                  0.0              0.0   131.0    42.0   \n",
       "\n",
       "   hr_med   SDNN_3h   pHR2_3h  rMSSD_3h  low_hr_3h  high_hr_3h    l_h_3h  \\\n",
       "2    85.0  0.001523  0.151828  2.057286       63.0       114.0  0.552632   \n",
       "3    65.0  0.002603  0.164480  3.189919       42.0       103.0  0.407767   \n",
       "4    70.0  0.001690  0.168531  2.259787       58.0       124.0  0.467742   \n",
       "5    67.0  0.002445  0.125108  2.243964       43.0       111.0  0.387387   \n",
       "6    71.0  0.001169  0.170872  2.072757       65.0       128.0  0.507812   \n",
       "\n",
       "      CR_3h  hr_mean_3h   hr_var_3h  hr_std_3h  hr_median_3h  hr_rest_rate_3h  \\\n",
       "2  0.897638   79.605805  107.223097  10.354859          77.0         0.555243   \n",
       "3  0.811024   58.940524   93.349638   9.661762          58.0         0.553427   \n",
       "4  0.976378   84.674367  148.673153  12.193160          83.0         0.011177   \n",
       "5  0.847328   73.071552  166.872357  12.917908          72.0         0.117241   \n",
       "6  0.977099   98.662824  119.034032  10.910272         100.0         0.000000   \n",
       "\n",
       "   hr_moderate_rate_3h  hr_very_active_rate_3h   SDNN_1h   pHR2_1h  rMSSD_1h  \\\n",
       "2             0.179775                0.081461  0.000918  0.123077  1.950937   \n",
       "3             0.185484                0.023185  0.002703  0.178771  2.899143   \n",
       "4             0.885246                0.346498  0.001724  0.180180  2.271544   \n",
       "5             0.709483                0.141379  0.001187  0.077694  1.869824   \n",
       "6             0.988473                0.697406  0.001238  0.115566  1.631789   \n",
       "\n",
       "   low_hr_1h  high_hr_1h    l_h_1h     CR_1h  hr_mean_1h   hr_var_1h  \\\n",
       "2       64.0        99.0  0.646465  0.779528   76.411043   31.498216   \n",
       "3       44.0       103.0  0.427184  0.811024   59.724234  113.496366   \n",
       "4       58.0       119.0  0.487395  0.937008   89.058427  183.032615   \n",
       "5       57.0       101.0  0.564356  0.770992   72.535000   40.655414   \n",
       "6       77.0       115.0  0.669565  0.877863   95.423529  119.768313   \n",
       "\n",
       "   hr_std_1h  hr_median_1h  hr_rest_rate_1h  hr_moderate_rate_1h  \\\n",
       "2   5.612327          76.0         0.690184             0.070552   \n",
       "3  10.653467          57.0         0.604457             0.200557   \n",
       "4  13.528955          88.0         0.013483             0.925843   \n",
       "5   6.376160          72.0         0.012500             0.835000   \n",
       "6  10.943871         100.0         0.000000             1.000000   \n",
       "\n",
       "   hr_very_active_rate_1h  SDNN_30m  pHR2_30m  rMSSD_30m  low_hr_30m  \\\n",
       "2                0.000000  0.000943  0.140244   1.844570        69.0   \n",
       "3                0.038997  0.002822  0.125000   2.251811        50.0   \n",
       "4                0.476404  0.001571  0.172414   2.237032        66.0   \n",
       "5                0.020000  0.000638  0.010000   1.046422        65.0   \n",
       "6                0.628235  0.001121  0.048913   1.242368        77.0   \n",
       "\n",
       "   high_hr_30m   l_h_30m    CR_30m  hr_mean_30m  hr_var_30m  hr_std_30m  \\\n",
       "2         99.0  0.696970  0.779528    78.654545   37.800665    6.148225   \n",
       "3        103.0  0.485437  0.811024    60.913514  150.818566   12.280821   \n",
       "4        117.0  0.564103  0.921260    88.798283  154.722066   12.438732   \n",
       "5         82.0  0.792683  0.625954    71.228856   10.887363    3.299600   \n",
       "6        111.0  0.693694  0.847328    85.583784   77.168214    8.784544   \n",
       "\n",
       "   hr_median_30m  hr_rest_rate_30m  hr_moderate_rate_30m  \\\n",
       "2           77.0          0.539394              0.121212   \n",
       "3           57.0          0.675676              0.151351   \n",
       "4           86.0          0.000000              0.952790   \n",
       "5           71.0          0.000000              0.885572   \n",
       "6           82.0          0.000000              1.000000   \n",
       "\n",
       "   hr_very_active_rate_30m  SDNN_10m  pHR2_10m  rMSSD_10m  low_hr_10m  \\\n",
       "2                 0.000000  0.001125  0.186441   1.978700        71.0   \n",
       "3                 0.075676  0.003763  0.188406   3.180557        50.0   \n",
       "4                 0.446352  0.001028  0.166667   2.455153        66.0   \n",
       "5                 0.000000  0.000624  0.027778   1.201850        65.0   \n",
       "6                 0.194595  0.000255  0.000000   0.820413        79.0   \n",
       "\n",
       "   high_hr_10m   l_h_10m    CR_10m  hr_mean_10m  hr_var_10m  hr_std_10m  \\\n",
       "2         99.0  0.717172  0.779528    81.916667   61.806497    7.861711   \n",
       "3        103.0  0.485437  0.811024    66.628571  325.019462   18.028296   \n",
       "4         91.0  0.725275  0.716535    77.589041   38.745434    6.224583   \n",
       "5         82.0  0.792683  0.625954    72.178082   10.870624    3.297063   \n",
       "6         85.0  0.929412  0.648855    81.320755    2.914369    1.707152   \n",
       "\n",
       "   hr_median_10m  hr_rest_rate_10m  hr_moderate_rate_10m  \\\n",
       "2           80.0          0.316667              0.233333   \n",
       "3           56.0          0.557143              0.342857   \n",
       "4           77.0          0.000000              0.849315   \n",
       "5           72.0          0.000000              0.931507   \n",
       "6           81.0          0.000000              1.000000   \n",
       "\n",
       "   hr_very_active_rate_10m   SDNN_5m   pHR2_5m  rMSSD_5m  low_hr_5m  \\\n",
       "2                 0.000000  0.001094  0.125000  1.968502       76.0   \n",
       "3                 0.200000  0.000643  0.035714  1.224745       50.0   \n",
       "4                 0.054795  0.001182  0.181818  2.037527       66.0   \n",
       "5                 0.000000  0.000522  0.054054  1.414214       69.0   \n",
       "6                 0.000000  0.000252  0.000000  0.721110       79.0   \n",
       "\n",
       "   high_hr_5m    l_h_5m     CR_5m  hr_mean_5m  hr_var_5m  hr_std_5m  \\\n",
       "2        99.0  0.767677  0.779528   85.757576  68.189394   8.257687   \n",
       "3        58.0  0.862069  0.456693   53.034483   3.463054   1.860928   \n",
       "4        91.0  0.725275  0.716535   76.852941  51.947415   7.207456   \n",
       "5        82.0  0.841463  0.625954   74.000000   8.648649   2.940858   \n",
       "6        84.0  0.940476  0.641221   81.846154   2.935385   1.713296   \n",
       "\n",
       "   hr_median_5m  hr_rest_rate_5m  hr_moderate_rate_5m  hr_very_active_rate_5m  \\\n",
       "2          82.0         0.181818             0.424242                0.000000   \n",
       "3          53.0         1.000000             0.000000                0.000000   \n",
       "4          75.0         0.000000             0.764706                0.117647   \n",
       "5          73.5         0.000000             1.000000                0.000000   \n",
       "6          82.5         0.000000             1.000000                0.000000   \n",
       "\n",
       "   hr_0  hr_0.3  hr_0.5  hr_0.8   hr_1  \n",
       "2  63.0    77.0    85.0    99.0  127.0  \n",
       "3  42.0    58.0    65.0    88.0  127.0  \n",
       "4  42.0    61.0    70.0    88.0  127.0  \n",
       "5  42.0    58.0    67.0    87.0  131.0  \n",
       "6  42.0    60.0    71.0    94.0  131.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_complete_nona.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#Solving a problem. DND has a different scale for AVI\n",
    "cols_5 = ['HAP_actual', 'LAP_actual', 'LA_actual', 'HAP_ideal', 'LAP_ideal', 'LA_ideal']\n",
    "cols_3 = ['HAN_actual', 'HAN_ideal', 'HA_actual', 'HA_ideal', 'LAN_actual', 'LAN_ideal', 'N_actual', 'N_ideal', 'P_actual', 'P_ideal']\n",
    "for i in cols_5:\n",
    "    DF_complete_nona.loc[DF_complete_nona.experiment == 'DND',i] = DF_complete_nona.loc[DF_complete_nona.experiment == 'DND',i].apply(lambda x: x/5)\n",
    "for i in cols_3:\n",
    "    DF_complete_nona.loc[DF_complete_nona.experiment == 'DND',i] = DF_complete_nona.loc[DF_complete_nona.experiment == 'DND',i].apply(lambda x: x/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>la_p</th>\n",
       "      <th>ha_p</th>\n",
       "      <th>ha_n</th>\n",
       "      <th>la_n</th>\n",
       "      <th>la</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>ha</th>\n",
       "      <th>start_survey</th>\n",
       "      <th>survey_no</th>\n",
       "      <th>experiment</th>\n",
       "      <th>VALENCE</th>\n",
       "      <th>VALENCE_mean</th>\n",
       "      <th>Date_only_date</th>\n",
       "      <th>HAN_actual</th>\n",
       "      <th>HAN_ideal</th>\n",
       "      <th>HAP_actual</th>\n",
       "      <th>HAP_ideal</th>\n",
       "      <th>HA_actual</th>\n",
       "      <th>HA_ideal</th>\n",
       "      <th>LAN_actual</th>\n",
       "      <th>LAN_ideal</th>\n",
       "      <th>LAP_actual</th>\n",
       "      <th>LAP_ideal</th>\n",
       "      <th>LA_actual</th>\n",
       "      <th>LA_ideal</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>N_ideal</th>\n",
       "      <th>P_actual</th>\n",
       "      <th>P_ideal</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Children</th>\n",
       "      <th>Household_income</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_FS</th>\n",
       "      <th>BAS_RR</th>\n",
       "      <th>BIS.5</th>\n",
       "      <th>BIS_total</th>\n",
       "      <th>NS_total</th>\n",
       "      <th>Conscientiousness_scaled</th>\n",
       "      <th>Extraversion_scaled</th>\n",
       "      <th>Neuroticism_scaled</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>FTP</th>\n",
       "      <th>SBQ</th>\n",
       "      <th>Date</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Biracial</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Hispanic</th>\n",
       "      <th>Ethnicity_Hispanic/Caucasian</th>\n",
       "      <th>Ethnicity_Hispanic/Other</th>\n",
       "      <th>Ethnicity_More than 1 race</th>\n",
       "      <th>Ethnicity_Native Hawaiian/Pacific Islander</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "      <th>Ethnicity_White/Pacific Islander</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Engaged</th>\n",
       "      <th>Marital_Status_Living with partner</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Widowed</th>\n",
       "      <th>Period_of_day_Evening</th>\n",
       "      <th>Period_of_day_Morning</th>\n",
       "      <th>Period_of_day_Night</th>\n",
       "      <th>start_survey_30m_ahead</th>\n",
       "      <th>start_survey_1h_ahead</th>\n",
       "      <th>start_survey_3h_ahead</th>\n",
       "      <th>start_survey_5m_ahead</th>\n",
       "      <th>start_survey_10m_ahead</th>\n",
       "      <th>step_max</th>\n",
       "      <th>step_min</th>\n",
       "      <th>step_median</th>\n",
       "      <th>steps_max_3h</th>\n",
       "      <th>steps_min_3h</th>\n",
       "      <th>steps_mean_3h</th>\n",
       "      <th>steps_var_3h</th>\n",
       "      <th>steps_median_3h</th>\n",
       "      <th>move_rate_3h</th>\n",
       "      <th>active_rate_3h</th>\n",
       "      <th>very_active_rate_3h</th>\n",
       "      <th>running_rate_3h</th>\n",
       "      <th>steps_max_1h</th>\n",
       "      <th>steps_min_1h</th>\n",
       "      <th>steps_mean_1h</th>\n",
       "      <th>steps_var_1h</th>\n",
       "      <th>steps_median_1h</th>\n",
       "      <th>move_rate_1h</th>\n",
       "      <th>active_rate_1h</th>\n",
       "      <th>very_active_rate_1h</th>\n",
       "      <th>running_rate_1h</th>\n",
       "      <th>steps_max_30m</th>\n",
       "      <th>steps_min_30m</th>\n",
       "      <th>steps_mean_30m</th>\n",
       "      <th>steps_var_30m</th>\n",
       "      <th>steps_median_30m</th>\n",
       "      <th>move_rate_30m</th>\n",
       "      <th>active_rate_30m</th>\n",
       "      <th>very_active_rate_30m</th>\n",
       "      <th>running_rate_30m</th>\n",
       "      <th>steps_max_10m</th>\n",
       "      <th>steps_min_10m</th>\n",
       "      <th>steps_mean_10m</th>\n",
       "      <th>steps_var_10m</th>\n",
       "      <th>steps_median_10m</th>\n",
       "      <th>move_rate_10m</th>\n",
       "      <th>active_rate_10m</th>\n",
       "      <th>very_active_rate_10m</th>\n",
       "      <th>running_rate_10m</th>\n",
       "      <th>steps_max_5m</th>\n",
       "      <th>steps_min_5m</th>\n",
       "      <th>steps_mean_5m</th>\n",
       "      <th>steps_var_5m</th>\n",
       "      <th>steps_median_5m</th>\n",
       "      <th>move_rate_5m</th>\n",
       "      <th>active_rate_5m</th>\n",
       "      <th>very_active_rate_5m</th>\n",
       "      <th>running_rate_5m</th>\n",
       "      <th>hr_max</th>\n",
       "      <th>hr_min</th>\n",
       "      <th>hr_med</th>\n",
       "      <th>SDNN_3h</th>\n",
       "      <th>pHR2_3h</th>\n",
       "      <th>rMSSD_3h</th>\n",
       "      <th>low_hr_3h</th>\n",
       "      <th>high_hr_3h</th>\n",
       "      <th>l_h_3h</th>\n",
       "      <th>CR_3h</th>\n",
       "      <th>hr_mean_3h</th>\n",
       "      <th>hr_var_3h</th>\n",
       "      <th>hr_std_3h</th>\n",
       "      <th>hr_median_3h</th>\n",
       "      <th>hr_rest_rate_3h</th>\n",
       "      <th>hr_moderate_rate_3h</th>\n",
       "      <th>hr_very_active_rate_3h</th>\n",
       "      <th>SDNN_1h</th>\n",
       "      <th>pHR2_1h</th>\n",
       "      <th>rMSSD_1h</th>\n",
       "      <th>low_hr_1h</th>\n",
       "      <th>high_hr_1h</th>\n",
       "      <th>l_h_1h</th>\n",
       "      <th>CR_1h</th>\n",
       "      <th>hr_mean_1h</th>\n",
       "      <th>hr_var_1h</th>\n",
       "      <th>hr_std_1h</th>\n",
       "      <th>hr_median_1h</th>\n",
       "      <th>hr_rest_rate_1h</th>\n",
       "      <th>hr_moderate_rate_1h</th>\n",
       "      <th>hr_very_active_rate_1h</th>\n",
       "      <th>SDNN_30m</th>\n",
       "      <th>pHR2_30m</th>\n",
       "      <th>rMSSD_30m</th>\n",
       "      <th>low_hr_30m</th>\n",
       "      <th>high_hr_30m</th>\n",
       "      <th>l_h_30m</th>\n",
       "      <th>CR_30m</th>\n",
       "      <th>hr_mean_30m</th>\n",
       "      <th>hr_var_30m</th>\n",
       "      <th>hr_std_30m</th>\n",
       "      <th>hr_median_30m</th>\n",
       "      <th>hr_rest_rate_30m</th>\n",
       "      <th>hr_moderate_rate_30m</th>\n",
       "      <th>hr_very_active_rate_30m</th>\n",
       "      <th>SDNN_10m</th>\n",
       "      <th>pHR2_10m</th>\n",
       "      <th>rMSSD_10m</th>\n",
       "      <th>low_hr_10m</th>\n",
       "      <th>high_hr_10m</th>\n",
       "      <th>l_h_10m</th>\n",
       "      <th>CR_10m</th>\n",
       "      <th>hr_mean_10m</th>\n",
       "      <th>hr_var_10m</th>\n",
       "      <th>hr_std_10m</th>\n",
       "      <th>hr_median_10m</th>\n",
       "      <th>hr_rest_rate_10m</th>\n",
       "      <th>hr_moderate_rate_10m</th>\n",
       "      <th>hr_very_active_rate_10m</th>\n",
       "      <th>SDNN_5m</th>\n",
       "      <th>pHR2_5m</th>\n",
       "      <th>rMSSD_5m</th>\n",
       "      <th>low_hr_5m</th>\n",
       "      <th>high_hr_5m</th>\n",
       "      <th>l_h_5m</th>\n",
       "      <th>CR_5m</th>\n",
       "      <th>hr_mean_5m</th>\n",
       "      <th>hr_var_5m</th>\n",
       "      <th>hr_std_5m</th>\n",
       "      <th>hr_median_5m</th>\n",
       "      <th>hr_rest_rate_5m</th>\n",
       "      <th>hr_moderate_rate_5m</th>\n",
       "      <th>hr_very_active_rate_5m</th>\n",
       "      <th>hr_0</th>\n",
       "      <th>hr_0.3</th>\n",
       "      <th>hr_0.5</th>\n",
       "      <th>hr_0.8</th>\n",
       "      <th>hr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-20 21:13:34</td>\n",
       "      <td>4</td>\n",
       "      <td>R00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-20</td>\n",
       "      <td>147.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-20 20:43:34</td>\n",
       "      <td>2016-02-20 20:13:34</td>\n",
       "      <td>2016-02-20 18:13:34</td>\n",
       "      <td>2016-02-20 21:08:34</td>\n",
       "      <td>2016-02-20 21:03:34</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.311111</td>\n",
       "      <td>209.813284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.216667</td>\n",
       "      <td>133.325141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>260.947126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>726.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1251.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>127.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.151828</td>\n",
       "      <td>2.057286</td>\n",
       "      <td>63.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>79.605805</td>\n",
       "      <td>107.223097</td>\n",
       "      <td>10.354859</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.555243</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>1.950937</td>\n",
       "      <td>64.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>76.411043</td>\n",
       "      <td>31.498216</td>\n",
       "      <td>5.612327</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.690184</td>\n",
       "      <td>0.070552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.140244</td>\n",
       "      <td>1.844570</td>\n",
       "      <td>69.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>78.654545</td>\n",
       "      <td>37.800665</td>\n",
       "      <td>6.148225</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.539394</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>1.978700</td>\n",
       "      <td>71.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>81.916667</td>\n",
       "      <td>61.806497</td>\n",
       "      <td>7.861711</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.968502</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>85.757576</td>\n",
       "      <td>68.189394</td>\n",
       "      <td>8.257687</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-21 07:11:48</td>\n",
       "      <td>5</td>\n",
       "      <td>R00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>317.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-21 06:41:48</td>\n",
       "      <td>2016-02-21 06:11:48</td>\n",
       "      <td>2016-02-21 04:11:48</td>\n",
       "      <td>2016-02-21 07:06:48</td>\n",
       "      <td>2016-02-21 07:01:48</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.205556</td>\n",
       "      <td>60.074829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>17.922034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.648276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>77.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.164480</td>\n",
       "      <td>3.189919</td>\n",
       "      <td>42.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>58.940524</td>\n",
       "      <td>93.349638</td>\n",
       "      <td>9.661762</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.553427</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>2.899143</td>\n",
       "      <td>44.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>59.724234</td>\n",
       "      <td>113.496366</td>\n",
       "      <td>10.653467</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.604457</td>\n",
       "      <td>0.200557</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.251811</td>\n",
       "      <td>50.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>60.913514</td>\n",
       "      <td>150.818566</td>\n",
       "      <td>12.280821</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>3.180557</td>\n",
       "      <td>50.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>66.628571</td>\n",
       "      <td>325.019462</td>\n",
       "      <td>18.028296</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.456693</td>\n",
       "      <td>53.034483</td>\n",
       "      <td>3.463054</td>\n",
       "      <td>1.860928</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-21 16:21:31</td>\n",
       "      <td>6</td>\n",
       "      <td>R00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>317.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-21 15:51:31</td>\n",
       "      <td>2016-02-21 15:21:31</td>\n",
       "      <td>2016-02-21 13:21:31</td>\n",
       "      <td>2016-02-21 16:16:31</td>\n",
       "      <td>2016-02-21 16:11:31</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.950000</td>\n",
       "      <td>417.265642</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.566667</td>\n",
       "      <td>434.148023</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>484.533333</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>742.622222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1029.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>127.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.168531</td>\n",
       "      <td>2.259787</td>\n",
       "      <td>58.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>84.674367</td>\n",
       "      <td>148.673153</td>\n",
       "      <td>12.193160</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.346498</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>2.271544</td>\n",
       "      <td>58.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.487395</td>\n",
       "      <td>0.937008</td>\n",
       "      <td>89.058427</td>\n",
       "      <td>183.032615</td>\n",
       "      <td>13.528955</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.925843</td>\n",
       "      <td>0.476404</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>2.237032</td>\n",
       "      <td>66.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>88.798283</td>\n",
       "      <td>154.722066</td>\n",
       "      <td>12.438732</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.446352</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.455153</td>\n",
       "      <td>66.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>77.589041</td>\n",
       "      <td>38.745434</td>\n",
       "      <td>6.224583</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>2.037527</td>\n",
       "      <td>66.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>76.852941</td>\n",
       "      <td>51.947415</td>\n",
       "      <td>7.207456</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>42.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1047</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-22 08:38:31</td>\n",
       "      <td>7</td>\n",
       "      <td>R00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-22 08:08:31</td>\n",
       "      <td>2016-02-22 07:38:31</td>\n",
       "      <td>2016-02-22 05:38:31</td>\n",
       "      <td>2016-02-22 08:33:31</td>\n",
       "      <td>2016-02-22 08:28:31</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>124.613128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>193.648305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.125108</td>\n",
       "      <td>2.243964</td>\n",
       "      <td>43.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.387387</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>73.071552</td>\n",
       "      <td>166.872357</td>\n",
       "      <td>12.917908</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.709483</td>\n",
       "      <td>0.141379</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.077694</td>\n",
       "      <td>1.869824</td>\n",
       "      <td>57.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>72.535000</td>\n",
       "      <td>40.655414</td>\n",
       "      <td>6.376160</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.046422</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>71.228856</td>\n",
       "      <td>10.887363</td>\n",
       "      <td>3.299600</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1.201850</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>10.870624</td>\n",
       "      <td>3.297063</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>69.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>8.648649</td>\n",
       "      <td>2.940858</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1047</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-02-22 13:57:37</td>\n",
       "      <td>8</td>\n",
       "      <td>R00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-22 13:27:37</td>\n",
       "      <td>2016-02-22 12:57:37</td>\n",
       "      <td>2016-02-22 10:57:37</td>\n",
       "      <td>2016-02-22 13:52:37</td>\n",
       "      <td>2016-02-22 13:47:37</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.577778</td>\n",
       "      <td>496.803973</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>535.345763</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>61.610345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.170872</td>\n",
       "      <td>2.072757</td>\n",
       "      <td>65.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>98.662824</td>\n",
       "      <td>119.034032</td>\n",
       "      <td>10.910272</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.115566</td>\n",
       "      <td>1.631789</td>\n",
       "      <td>77.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.877863</td>\n",
       "      <td>95.423529</td>\n",
       "      <td>119.768313</td>\n",
       "      <td>10.943871</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628235</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>1.242368</td>\n",
       "      <td>77.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>85.583784</td>\n",
       "      <td>77.168214</td>\n",
       "      <td>8.784544</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194595</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820413</td>\n",
       "      <td>79.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.648855</td>\n",
       "      <td>81.320755</td>\n",
       "      <td>2.914369</td>\n",
       "      <td>1.707152</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721110</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.641221</td>\n",
       "      <td>81.846154</td>\n",
       "      <td>2.935385</td>\n",
       "      <td>1.713296</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2296</td>\n",
       "      <td>DND119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-17 16:18:10</td>\n",
       "      <td>23</td>\n",
       "      <td>DND</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>DND119</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>739.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-17 15:48:10</td>\n",
       "      <td>2018-03-17 15:18:10</td>\n",
       "      <td>2018-03-17 13:18:10</td>\n",
       "      <td>2018-03-17 16:13:10</td>\n",
       "      <td>2018-03-17 16:08:10</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.073858</td>\n",
       "      <td>1.467497</td>\n",
       "      <td>57.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>64.677670</td>\n",
       "      <td>16.741483</td>\n",
       "      <td>4.091636</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.988350</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>1.298748</td>\n",
       "      <td>59.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>66.972973</td>\n",
       "      <td>8.863725</td>\n",
       "      <td>2.977201</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731768</td>\n",
       "      <td>65.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>68.923077</td>\n",
       "      <td>2.794045</td>\n",
       "      <td>1.671540</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>69.808511</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.312785</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417029</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>70.625000</td>\n",
       "      <td>0.331522</td>\n",
       "      <td>0.575779</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2297</td>\n",
       "      <td>DND119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-03-17 23:00:04</td>\n",
       "      <td>24</td>\n",
       "      <td>DND</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>DND119</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>739.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-17 22:30:04</td>\n",
       "      <td>2018-03-17 22:00:04</td>\n",
       "      <td>2018-03-17 20:00:04</td>\n",
       "      <td>2018-03-17 22:55:04</td>\n",
       "      <td>2018-03-17 22:50:04</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>71.199876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.103670</td>\n",
       "      <td>1.745243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>83.830431</td>\n",
       "      <td>65.251036</td>\n",
       "      <td>8.077811</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.199817</td>\n",
       "      <td>0.435380</td>\n",
       "      <td>0.209899</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.087209</td>\n",
       "      <td>1.422412</td>\n",
       "      <td>73.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>78.936232</td>\n",
       "      <td>4.623829</td>\n",
       "      <td>2.150309</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.414493</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.092486</td>\n",
       "      <td>1.476208</td>\n",
       "      <td>73.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>77.632184</td>\n",
       "      <td>3.043120</td>\n",
       "      <td>1.744454</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>1.197482</td>\n",
       "      <td>73.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>76.907407</td>\n",
       "      <td>3.444095</td>\n",
       "      <td>1.855827</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1.143544</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>76.037037</td>\n",
       "      <td>2.729345</td>\n",
       "      <td>1.652073</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2298</td>\n",
       "      <td>DND119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-18 11:50:18</td>\n",
       "      <td>25</td>\n",
       "      <td>DND</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>DND119</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>372.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-18 11:20:18</td>\n",
       "      <td>2018-03-18 10:50:18</td>\n",
       "      <td>2018-03-18 08:50:18</td>\n",
       "      <td>2018-03-18 11:45:18</td>\n",
       "      <td>2018-03-18 11:40:18</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>27.786592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.092144</td>\n",
       "      <td>1.545934</td>\n",
       "      <td>69.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>78.250969</td>\n",
       "      <td>16.554800</td>\n",
       "      <td>4.068759</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.123062</td>\n",
       "      <td>0.037791</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.104615</td>\n",
       "      <td>1.705196</td>\n",
       "      <td>72.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>76.671779</td>\n",
       "      <td>4.350401</td>\n",
       "      <td>2.085762</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>1.365791</td>\n",
       "      <td>72.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>75.764331</td>\n",
       "      <td>3.540258</td>\n",
       "      <td>1.881557</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1.174734</td>\n",
       "      <td>72.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>74.843137</td>\n",
       "      <td>2.134902</td>\n",
       "      <td>1.461130</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>74.269231</td>\n",
       "      <td>1.564615</td>\n",
       "      <td>1.250846</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2299</td>\n",
       "      <td>DND119</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-18 17:57:54</td>\n",
       "      <td>26</td>\n",
       "      <td>DND</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>DND119</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>372.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-18 17:27:54</td>\n",
       "      <td>2018-03-18 16:57:54</td>\n",
       "      <td>2018-03-18 14:57:54</td>\n",
       "      <td>2018-03-18 17:52:54</td>\n",
       "      <td>2018-03-18 17:47:54</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.490909</td>\n",
       "      <td>29.739246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>71.399718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>78.350575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>33.955556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.122177</td>\n",
       "      <td>1.808604</td>\n",
       "      <td>63.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>75.685128</td>\n",
       "      <td>55.708762</td>\n",
       "      <td>7.463830</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.749744</td>\n",
       "      <td>0.130256</td>\n",
       "      <td>0.069744</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.108808</td>\n",
       "      <td>1.821006</td>\n",
       "      <td>67.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>79.976744</td>\n",
       "      <td>78.255934</td>\n",
       "      <td>8.846238</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.563307</td>\n",
       "      <td>0.260982</td>\n",
       "      <td>0.175711</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>1.647064</td>\n",
       "      <td>67.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>78.326531</td>\n",
       "      <td>15.533857</td>\n",
       "      <td>3.941301</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1.207122</td>\n",
       "      <td>72.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>79.394366</td>\n",
       "      <td>6.670825</td>\n",
       "      <td>2.582794</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1.196843</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>80.842105</td>\n",
       "      <td>3.704125</td>\n",
       "      <td>1.924610</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>DND119</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-18 22:24:58</td>\n",
       "      <td>27</td>\n",
       "      <td>DND</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>DND119</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>372.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-18 21:54:58</td>\n",
       "      <td>2018-03-18 21:24:58</td>\n",
       "      <td>2018-03-18 19:24:58</td>\n",
       "      <td>2018-03-18 22:19:58</td>\n",
       "      <td>2018-03-18 22:14:58</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.377778</td>\n",
       "      <td>251.621850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.128472</td>\n",
       "      <td>2.270738</td>\n",
       "      <td>62.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>90.870772</td>\n",
       "      <td>176.829640</td>\n",
       "      <td>13.297731</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.205551</td>\n",
       "      <td>0.761492</td>\n",
       "      <td>0.504770</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.067055</td>\n",
       "      <td>2.100257</td>\n",
       "      <td>62.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.613861</td>\n",
       "      <td>0.510101</td>\n",
       "      <td>88.598837</td>\n",
       "      <td>21.961048</td>\n",
       "      <td>4.686262</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.956395</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>1.030218</td>\n",
       "      <td>84.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>88.384146</td>\n",
       "      <td>5.587723</td>\n",
       "      <td>2.363836</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>86.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>88.061224</td>\n",
       "      <td>3.058673</td>\n",
       "      <td>1.748906</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807573</td>\n",
       "      <td>86.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>2.840580</td>\n",
       "      <td>1.685402</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  la_p  ha_p  ha_n  la_n   la    p    n   ha        start_survey  \\\n",
       "2       1047   4.0   3.0   1.0   1.0  2.0  4.0  1.0  1.0 2016-02-20 21:13:34   \n",
       "3       1047   4.0   1.0   1.0   2.0  4.0  2.0  1.0  1.0 2016-02-21 07:11:48   \n",
       "4       1047   2.0   2.0   1.0   2.0  1.0  5.0  1.0  1.0 2016-02-21 16:21:31   \n",
       "5       1047   3.0   1.0   1.0   2.0  2.0  3.0  1.0  1.0 2016-02-22 08:38:31   \n",
       "6       1047   3.0   3.0   1.0   1.0  2.0  4.0  1.0  2.0 2016-02-22 13:57:37   \n",
       "...      ...   ...   ...   ...   ...  ...  ...  ...  ...                 ...   \n",
       "2296  DND119   4.0   3.0   1.0   1.0  1.0  3.0  3.0  1.0 2018-03-17 16:18:10   \n",
       "2297  DND119   4.0   3.0   1.0   1.0  1.0  4.0  1.0  2.0 2018-03-17 23:00:04   \n",
       "2298  DND119   4.0   3.0   1.0   2.0  3.0  4.0  1.0  1.0 2018-03-18 11:50:18   \n",
       "2299  DND119   3.0   3.0   1.0   1.0  1.0  4.0  1.0  1.0 2018-03-18 17:57:54   \n",
       "2300  DND119   3.0   2.0   1.0   1.0  2.0  3.0  1.0  1.0 2018-03-18 22:24:58   \n",
       "\n",
       "      survey_no experiment  VALENCE  VALENCE_mean Date_only_date  HAN_actual  \\\n",
       "2             4        R00      8.0      2.666667     2016-02-20    1.333333   \n",
       "3             5        R00      3.0      1.000000     2016-02-21    1.333333   \n",
       "4             6        R00      5.0      1.666667     2016-02-21    1.333333   \n",
       "5             7        R00      3.0      1.000000     2016-02-22    1.333333   \n",
       "6             8        R00      7.0      2.333333     2016-02-22    1.333333   \n",
       "...         ...        ...      ...           ...            ...         ...   \n",
       "2296         23        DND      5.0      1.666667     2018-03-17    1.000000   \n",
       "2297         24        DND      8.0      2.666667     2018-03-17    1.000000   \n",
       "2298         25        DND      7.0      2.333333     2018-03-18    1.000000   \n",
       "2299         26        DND      7.0      2.333333     2018-03-18    1.000000   \n",
       "2300         27        DND      5.0      1.666667     2018-03-18    1.000000   \n",
       "\n",
       "      HAN_ideal  HAP_actual  HAP_ideal  HA_actual  HA_ideal  LAN_actual  \\\n",
       "2           1.0         2.6        2.8   2.000000  2.333333    1.666667   \n",
       "3           1.0         2.6        2.8   2.000000  2.333333    1.666667   \n",
       "4           1.0         2.6        2.8   2.000000  2.333333    1.666667   \n",
       "5           1.0         2.6        2.8   2.000000  2.333333    1.666667   \n",
       "6           1.0         2.6        2.8   2.000000  2.333333    1.666667   \n",
       "...         ...         ...        ...        ...       ...         ...   \n",
       "2296        1.0         2.4        3.0   2.666667  3.333333    2.000000   \n",
       "2297        1.0         2.4        3.0   2.666667  3.333333    2.000000   \n",
       "2298        1.0         2.4        3.0   2.666667  3.333333    2.000000   \n",
       "2299        1.0         2.4        3.0   2.666667  3.333333    2.000000   \n",
       "2300        1.0         2.4        3.0   2.666667  3.333333    2.000000   \n",
       "\n",
       "      LAN_ideal  LAP_actual  LAP_ideal  LA_actual  LA_ideal  N_actual  \\\n",
       "2      1.000000         3.6        4.2        2.0       1.8       1.0   \n",
       "3      1.000000         3.6        4.2        2.0       1.8       1.0   \n",
       "4      1.000000         3.6        4.2        2.0       1.8       1.0   \n",
       "5      1.000000         3.6        4.2        2.0       1.8       1.0   \n",
       "6      1.000000         3.6        4.2        2.0       1.8       1.0   \n",
       "...         ...         ...        ...        ...       ...       ...   \n",
       "2296   1.666667         3.6        3.6        1.6       1.4       1.0   \n",
       "2297   1.666667         3.6        3.6        1.6       1.4       1.0   \n",
       "2298   1.666667         3.6        3.6        1.6       1.4       1.0   \n",
       "2299   1.666667         3.6        3.6        1.6       1.4       1.0   \n",
       "2300   1.666667         3.6        3.6        1.6       1.4       1.0   \n",
       "\n",
       "       N_ideal  P_actual   P_ideal Subject   Age  Children  Household_income  \\\n",
       "2     1.000000  4.333333  4.333333    1047  43.0       3.0               9.0   \n",
       "3     1.000000  4.333333  4.333333    1047  43.0       3.0               9.0   \n",
       "4     1.000000  4.333333  4.333333    1047  43.0       3.0               9.0   \n",
       "5     1.000000  4.333333  4.333333    1047  43.0       3.0               9.0   \n",
       "6     1.000000  4.333333  4.333333    1047  43.0       3.0               9.0   \n",
       "...        ...       ...       ...     ...   ...       ...               ...   \n",
       "2296  1.333333  4.000000  4.000000  DND119  57.0       1.0               9.0   \n",
       "2297  1.333333  4.000000  4.000000  DND119  57.0       1.0               9.0   \n",
       "2298  1.333333  4.000000  4.000000  DND119  57.0       1.0               9.0   \n",
       "2299  1.333333  4.000000  4.000000  DND119  57.0       1.0               9.0   \n",
       "2300  1.333333  4.000000  4.000000  DND119  57.0       1.0               9.0   \n",
       "\n",
       "            BMI  BAS_D  BAS_FS  BAS_RR  BIS.5  BIS_total  NS_total  \\\n",
       "2     27.328927   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "3     27.328927   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "4     27.328927   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "5     27.328927   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "6     27.328927   14.0    16.0    23.0   24.0       51.0      11.0   \n",
       "...         ...    ...     ...     ...    ...        ...       ...   \n",
       "2296  31.800000    7.0     9.0    10.0   17.0       61.0      18.0   \n",
       "2297  31.800000    7.0     9.0    10.0   17.0       61.0      18.0   \n",
       "2298  31.800000    7.0     9.0    10.0   17.0       61.0      18.0   \n",
       "2299  31.800000    7.0     9.0    10.0   17.0       61.0      18.0   \n",
       "2300  31.800000    7.0     9.0    10.0   17.0       61.0      18.0   \n",
       "\n",
       "      Conscientiousness_scaled  Extraversion_scaled  Neuroticism_scaled  SWLS  \\\n",
       "2                        0.875             0.583333            0.208333  25.0   \n",
       "3                        0.875             0.583333            0.208333  25.0   \n",
       "4                        0.875             0.583333            0.208333  25.0   \n",
       "5                        0.875             0.583333            0.208333  25.0   \n",
       "6                        0.875             0.583333            0.208333  25.0   \n",
       "...                        ...                  ...                 ...   ...   \n",
       "2296                     0.625             0.520833            0.197917  23.0   \n",
       "2297                     0.625             0.520833            0.197917  23.0   \n",
       "2298                     0.625             0.520833            0.197917  23.0   \n",
       "2299                     0.625             0.520833            0.197917  23.0   \n",
       "2300                     0.625             0.520833            0.197917  23.0   \n",
       "\n",
       "       FTP   SBQ       Date  Minutes Asleep  Minutes Awake  \\\n",
       "2      5.5  60.0 2016-02-20           147.0           10.0   \n",
       "3      5.5  60.0 2016-02-21           317.0           40.0   \n",
       "4      5.5  60.0 2016-02-21           317.0           40.0   \n",
       "5      5.5  60.0 2016-02-22           419.0           34.0   \n",
       "6      5.5  60.0 2016-02-22           419.0           34.0   \n",
       "...    ...   ...        ...             ...            ...   \n",
       "2296  54.0  52.0 2018-03-17           739.0           14.0   \n",
       "2297  54.0  52.0 2018-03-17           739.0           14.0   \n",
       "2298  54.0  52.0 2018-03-18           372.0           16.0   \n",
       "2299  54.0  52.0 2018-03-18           372.0           16.0   \n",
       "2300  54.0  52.0 2018-03-18           372.0           16.0   \n",
       "\n",
       "      Number of Awakenings  Time in Bed  Sex_Female  Sex_Male  \\\n",
       "2                      6.0        157.0           1         0   \n",
       "3                     17.0        357.0           1         0   \n",
       "4                     17.0        357.0           1         0   \n",
       "5                     17.0        453.0           1         0   \n",
       "6                     17.0        453.0           1         0   \n",
       "...                    ...          ...         ...       ...   \n",
       "2296                   1.0        753.0           0         1   \n",
       "2297                   1.0        753.0           0         1   \n",
       "2298                   1.0        388.0           0         1   \n",
       "2299                   1.0        388.0           0         1   \n",
       "2300                   1.0        388.0           0         1   \n",
       "\n",
       "      Ethnicity_Asian  Ethnicity_Biracial  Ethnicity_Black  \\\n",
       "2                   0                   0                0   \n",
       "3                   0                   0                0   \n",
       "4                   0                   0                0   \n",
       "5                   0                   0                0   \n",
       "6                   0                   0                0   \n",
       "...               ...                 ...              ...   \n",
       "2296                0                   0                1   \n",
       "2297                0                   0                1   \n",
       "2298                0                   0                1   \n",
       "2299                0                   0                1   \n",
       "2300                0                   0                1   \n",
       "\n",
       "      Ethnicity_Hispanic  Ethnicity_Hispanic/Caucasian  \\\n",
       "2                      0                             0   \n",
       "3                      0                             0   \n",
       "4                      0                             0   \n",
       "5                      0                             0   \n",
       "6                      0                             0   \n",
       "...                  ...                           ...   \n",
       "2296                   0                             0   \n",
       "2297                   0                             0   \n",
       "2298                   0                             0   \n",
       "2299                   0                             0   \n",
       "2300                   0                             0   \n",
       "\n",
       "      Ethnicity_Hispanic/Other  Ethnicity_More than 1 race  \\\n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "5                            0                           0   \n",
       "6                            0                           0   \n",
       "...                        ...                         ...   \n",
       "2296                         0                           0   \n",
       "2297                         0                           0   \n",
       "2298                         0                           0   \n",
       "2299                         0                           0   \n",
       "2300                         0                           0   \n",
       "\n",
       "      Ethnicity_Native Hawaiian/Pacific Islander  Ethnicity_White  \\\n",
       "2                                              0                1   \n",
       "3                                              0                1   \n",
       "4                                              0                1   \n",
       "5                                              0                1   \n",
       "6                                              0                1   \n",
       "...                                          ...              ...   \n",
       "2296                                           0                0   \n",
       "2297                                           0                0   \n",
       "2298                                           0                0   \n",
       "2299                                           0                0   \n",
       "2300                                           0                0   \n",
       "\n",
       "      Ethnicity_White/Pacific Islander  Marital_Status_Divorced  \\\n",
       "2                                    0                        0   \n",
       "3                                    0                        0   \n",
       "4                                    0                        0   \n",
       "5                                    0                        0   \n",
       "6                                    0                        0   \n",
       "...                                ...                      ...   \n",
       "2296                                 0                        1   \n",
       "2297                                 0                        1   \n",
       "2298                                 0                        1   \n",
       "2299                                 0                        1   \n",
       "2300                                 0                        1   \n",
       "\n",
       "      Marital_Status_Engaged  Marital_Status_Living with partner  \\\n",
       "2                          0                                   0   \n",
       "3                          0                                   0   \n",
       "4                          0                                   0   \n",
       "5                          0                                   0   \n",
       "6                          0                                   0   \n",
       "...                      ...                                 ...   \n",
       "2296                       0                                   0   \n",
       "2297                       0                                   0   \n",
       "2298                       0                                   0   \n",
       "2299                       0                                   0   \n",
       "2300                       0                                   0   \n",
       "\n",
       "      Marital_Status_Married  Marital_Status_Single  Marital_Status_Widowed  \\\n",
       "2                          1                      0                       0   \n",
       "3                          1                      0                       0   \n",
       "4                          1                      0                       0   \n",
       "5                          1                      0                       0   \n",
       "6                          1                      0                       0   \n",
       "...                      ...                    ...                     ...   \n",
       "2296                       0                      0                       0   \n",
       "2297                       0                      0                       0   \n",
       "2298                       0                      0                       0   \n",
       "2299                       0                      0                       0   \n",
       "2300                       0                      0                       0   \n",
       "\n",
       "      Period_of_day_Evening  Period_of_day_Morning  Period_of_day_Night  \\\n",
       "2                         0                      0                    1   \n",
       "3                         0                      1                    0   \n",
       "4                         1                      0                    0   \n",
       "5                         0                      1                    0   \n",
       "6                         1                      0                    0   \n",
       "...                     ...                    ...                  ...   \n",
       "2296                      1                      0                    0   \n",
       "2297                      0                      0                    1   \n",
       "2298                      0                      1                    0   \n",
       "2299                      1                      0                    0   \n",
       "2300                      0                      0                    1   \n",
       "\n",
       "     start_survey_30m_ahead start_survey_1h_ahead start_survey_3h_ahead  \\\n",
       "2       2016-02-20 20:43:34   2016-02-20 20:13:34   2016-02-20 18:13:34   \n",
       "3       2016-02-21 06:41:48   2016-02-21 06:11:48   2016-02-21 04:11:48   \n",
       "4       2016-02-21 15:51:31   2016-02-21 15:21:31   2016-02-21 13:21:31   \n",
       "5       2016-02-22 08:08:31   2016-02-22 07:38:31   2016-02-22 05:38:31   \n",
       "6       2016-02-22 13:27:37   2016-02-22 12:57:37   2016-02-22 10:57:37   \n",
       "...                     ...                   ...                   ...   \n",
       "2296    2018-03-17 15:48:10   2018-03-17 15:18:10   2018-03-17 13:18:10   \n",
       "2297    2018-03-17 22:30:04   2018-03-17 22:00:04   2018-03-17 20:00:04   \n",
       "2298    2018-03-18 11:20:18   2018-03-18 10:50:18   2018-03-18 08:50:18   \n",
       "2299    2018-03-18 17:27:54   2018-03-18 16:57:54   2018-03-18 14:57:54   \n",
       "2300    2018-03-18 21:54:58   2018-03-18 21:24:58   2018-03-18 19:24:58   \n",
       "\n",
       "     start_survey_5m_ahead start_survey_10m_ahead  step_max  step_min  \\\n",
       "2      2016-02-20 21:08:34    2016-02-20 21:03:34     110.0       0.0   \n",
       "3      2016-02-21 07:06:48    2016-02-21 07:01:48     111.0       0.0   \n",
       "4      2016-02-21 16:16:31    2016-02-21 16:11:31     111.0       0.0   \n",
       "5      2016-02-22 08:33:31    2016-02-22 08:28:31     111.0       0.0   \n",
       "6      2016-02-22 13:52:37    2016-02-22 13:47:37     111.0       0.0   \n",
       "...                    ...                    ...       ...       ...   \n",
       "2296   2018-03-17 16:13:10    2018-03-17 16:08:10     112.0       0.0   \n",
       "2297   2018-03-17 22:55:04    2018-03-17 22:50:04     112.0       0.0   \n",
       "2298   2018-03-18 11:45:18    2018-03-18 11:40:18     112.0       0.0   \n",
       "2299   2018-03-18 17:52:54    2018-03-18 17:47:54     112.0       0.0   \n",
       "2300   2018-03-18 22:19:58    2018-03-18 22:14:58     112.0       0.0   \n",
       "\n",
       "      step_median  steps_max_3h  steps_min_3h  steps_mean_3h  steps_var_3h  \\\n",
       "2             0.0         110.0           0.0       4.311111    209.813284   \n",
       "3             0.0          70.0           0.0       1.205556     60.074829   \n",
       "4             0.0         102.0           0.0      18.950000    417.265642   \n",
       "5             0.0          72.0           0.0       3.750000    124.613128   \n",
       "6             0.0          87.0           0.0      26.577778    496.803973   \n",
       "...           ...           ...           ...            ...           ...   \n",
       "2296          0.0           6.0           0.0       0.033333      0.200000   \n",
       "2297          0.0          57.0           0.0       2.611111     71.199876   \n",
       "2298          0.0          62.0           0.0       0.700000     27.786592   \n",
       "2299          0.0          41.0           0.0       1.490909     29.739246   \n",
       "2300          0.0          73.0           0.0       7.377778    251.621850   \n",
       "\n",
       "      steps_median_3h  move_rate_3h  active_rate_3h  very_active_rate_3h  \\\n",
       "2                 0.0      0.155556        0.100000             0.066667   \n",
       "3                 0.0      0.044444        0.033333             0.016667   \n",
       "4                14.5      0.672222        0.577778             0.377778   \n",
       "5                 0.0      0.166667        0.105556             0.061111   \n",
       "6                22.5      0.766667        0.727778             0.550000   \n",
       "...               ...           ...             ...                  ...   \n",
       "2296              0.0      0.005556        0.000000             0.000000   \n",
       "2297              0.0      0.138889        0.094444             0.038889   \n",
       "2298              0.0      0.027778        0.022222             0.011111   \n",
       "2299              0.0      0.096970        0.054545             0.024242   \n",
       "2300              0.0      0.283333        0.205556             0.127778   \n",
       "\n",
       "      running_rate_3h  steps_max_1h  steps_min_1h  steps_mean_1h  \\\n",
       "2            0.044444          76.0           0.0       2.216667   \n",
       "3            0.011111          21.0           0.0       1.100000   \n",
       "4            0.238889          86.0           0.0      19.566667   \n",
       "5            0.038889          72.0           0.0       3.250000   \n",
       "6            0.383333          87.0           0.0      19.100000   \n",
       "...               ...           ...           ...            ...   \n",
       "2296         0.000000           0.0           0.0       0.000000   \n",
       "2297         0.016667           0.0           0.0       0.000000   \n",
       "2298         0.005556           0.0           0.0       0.000000   \n",
       "2299         0.006061          41.0           0.0       3.583333   \n",
       "2300         0.105556          43.0           0.0       1.450000   \n",
       "\n",
       "      steps_var_1h  steps_median_1h  move_rate_1h  active_rate_1h  \\\n",
       "2       133.325141              0.0      0.050000        0.033333   \n",
       "3        17.922034              0.0      0.066667        0.066667   \n",
       "4       434.148023             14.5      0.683333        0.583333   \n",
       "5       193.648305              0.0      0.066667        0.050000   \n",
       "6       535.345763             14.0      0.550000        0.516667   \n",
       "...            ...              ...           ...             ...   \n",
       "2296      0.000000              0.0      0.000000        0.000000   \n",
       "2297      0.000000              0.0      0.000000        0.000000   \n",
       "2298      0.000000              0.0      0.000000        0.000000   \n",
       "2299     71.399718              0.0      0.200000        0.150000   \n",
       "2300     46.150000              0.0      0.066667        0.033333   \n",
       "\n",
       "      very_active_rate_1h  running_rate_1h  steps_max_30m  steps_min_30m  \\\n",
       "2                0.033333         0.033333           76.0            0.0   \n",
       "3                0.016667         0.000000           21.0            0.0   \n",
       "4                0.400000         0.233333           74.0            0.0   \n",
       "5                0.050000         0.050000            0.0            0.0   \n",
       "6                0.366667         0.266667           31.0            0.0   \n",
       "...                   ...              ...            ...            ...   \n",
       "2296             0.000000         0.000000            0.0            0.0   \n",
       "2297             0.000000         0.000000            0.0            0.0   \n",
       "2298             0.000000         0.000000            0.0            0.0   \n",
       "2299             0.066667         0.016667           41.0            0.0   \n",
       "2300             0.033333         0.016667            0.0            0.0   \n",
       "\n",
       "      steps_mean_30m  steps_var_30m  steps_median_30m  move_rate_30m  \\\n",
       "2           4.133333     260.947126               0.0       0.066667   \n",
       "3           1.800000      30.648276               0.0       0.100000   \n",
       "4          24.466667     484.533333              23.0       0.733333   \n",
       "5           0.000000       0.000000               0.0       0.000000   \n",
       "6           2.900000      61.610345               0.0       0.133333   \n",
       "...              ...            ...               ...            ...   \n",
       "2296        0.000000       0.000000               0.0       0.000000   \n",
       "2297        0.000000       0.000000               0.0       0.000000   \n",
       "2298        0.000000       0.000000               0.0       0.000000   \n",
       "2299        3.166667      78.350575               0.0       0.166667   \n",
       "2300        0.000000       0.000000               0.0       0.000000   \n",
       "\n",
       "      active_rate_30m  very_active_rate_30m  running_rate_30m  steps_max_10m  \\\n",
       "2            0.066667              0.066667          0.066667           76.0   \n",
       "3            0.100000              0.033333          0.000000           21.0   \n",
       "4            0.666667              0.533333          0.333333           74.0   \n",
       "5            0.000000              0.000000          0.000000            0.0   \n",
       "6            0.133333              0.066667          0.033333            0.0   \n",
       "...               ...                   ...               ...            ...   \n",
       "2296         0.000000              0.000000          0.000000            0.0   \n",
       "2297         0.000000              0.000000          0.000000            0.0   \n",
       "2298         0.000000              0.000000          0.000000            0.0   \n",
       "2299         0.133333              0.066667          0.033333           14.0   \n",
       "2300         0.000000              0.000000          0.000000            0.0   \n",
       "\n",
       "      steps_min_10m  steps_mean_10m  steps_var_10m  steps_median_10m  \\\n",
       "2               0.0            12.4     726.933333               0.0   \n",
       "3               0.0             5.4      77.155556               0.0   \n",
       "4               0.0            21.8     742.622222              16.0   \n",
       "5               0.0             0.0       0.000000               0.0   \n",
       "6               0.0             0.0       0.000000               0.0   \n",
       "...             ...             ...            ...               ...   \n",
       "2296            0.0             0.0       0.000000               0.0   \n",
       "2297            0.0             0.0       0.000000               0.0   \n",
       "2298            0.0             0.0       0.000000               0.0   \n",
       "2299            0.0             3.2      33.955556               0.0   \n",
       "2300            0.0             0.0       0.000000               0.0   \n",
       "\n",
       "      move_rate_10m  active_rate_10m  very_active_rate_10m  running_rate_10m  \\\n",
       "2               0.2              0.2                   0.2               0.2   \n",
       "3               0.3              0.3                   0.1               0.0   \n",
       "4               0.6              0.6                   0.4               0.2   \n",
       "5               0.0              0.0                   0.0               0.0   \n",
       "6               0.0              0.0                   0.0               0.0   \n",
       "...             ...              ...                   ...               ...   \n",
       "2296            0.0              0.0                   0.0               0.0   \n",
       "2297            0.0              0.0                   0.0               0.0   \n",
       "2298            0.0              0.0                   0.0               0.0   \n",
       "2299            0.3              0.2                   0.0               0.0   \n",
       "2300            0.0              0.0                   0.0               0.0   \n",
       "\n",
       "      steps_max_5m  steps_min_5m  steps_mean_5m  steps_var_5m  \\\n",
       "2             76.0           0.0           24.8        1251.2   \n",
       "3              0.0           0.0            0.0           0.0   \n",
       "4             74.0           0.0           19.2        1029.2   \n",
       "5              0.0           0.0            0.0           0.0   \n",
       "6              0.0           0.0            0.0           0.0   \n",
       "...            ...           ...            ...           ...   \n",
       "2296           0.0           0.0            0.0           0.0   \n",
       "2297           0.0           0.0            0.0           0.0   \n",
       "2298           0.0           0.0            0.0           0.0   \n",
       "2299          14.0           0.0            3.6          36.8   \n",
       "2300           0.0           0.0            0.0           0.0   \n",
       "\n",
       "      steps_median_5m  move_rate_5m  active_rate_5m  very_active_rate_5m  \\\n",
       "2                 0.0           0.4             0.4                  0.4   \n",
       "3                 0.0           0.0             0.0                  0.0   \n",
       "4                 0.0           0.4             0.4                  0.4   \n",
       "5                 0.0           0.0             0.0                  0.0   \n",
       "6                 0.0           0.0             0.0                  0.0   \n",
       "...               ...           ...             ...                  ...   \n",
       "2296              0.0           0.0             0.0                  0.0   \n",
       "2297              0.0           0.0             0.0                  0.0   \n",
       "2298              0.0           0.0             0.0                  0.0   \n",
       "2299              0.0           0.4             0.2                  0.0   \n",
       "2300              0.0           0.0             0.0                  0.0   \n",
       "\n",
       "      running_rate_5m  hr_max  hr_min  hr_med   SDNN_3h   pHR2_3h  rMSSD_3h  \\\n",
       "2                 0.4   127.0    63.0    85.0  0.001523  0.151828  2.057286   \n",
       "3                 0.0   127.0    42.0    65.0  0.002603  0.164480  3.189919   \n",
       "4                 0.2   127.0    42.0    70.0  0.001690  0.168531  2.259787   \n",
       "5                 0.0   131.0    42.0    67.0  0.002445  0.125108  2.243964   \n",
       "6                 0.0   131.0    42.0    71.0  0.001169  0.170872  2.072757   \n",
       "...               ...     ...     ...     ...       ...       ...       ...   \n",
       "2296              0.0   198.0    49.0    82.0  0.000940  0.073858  1.467497   \n",
       "2297              0.0   198.0    49.0    82.0  0.001111  0.103670  1.745243   \n",
       "2298              0.0   198.0    49.0    82.0  0.000635  0.092144  1.545934   \n",
       "2299              0.0   198.0    49.0    82.0  0.001218  0.122177  1.808604   \n",
       "2300              0.0   198.0    49.0    82.0  0.001625  0.128472  2.270738   \n",
       "\n",
       "      low_hr_3h  high_hr_3h    l_h_3h     CR_3h  hr_mean_3h   hr_var_3h  \\\n",
       "2          63.0       114.0  0.552632  0.897638   79.605805  107.223097   \n",
       "3          42.0       103.0  0.407767  0.811024   58.940524   93.349638   \n",
       "4          58.0       124.0  0.467742  0.976378   84.674367  148.673153   \n",
       "5          43.0       111.0  0.387387  0.847328   73.071552  166.872357   \n",
       "6          65.0       128.0  0.507812  0.977099   98.662824  119.034032   \n",
       "...         ...         ...       ...       ...         ...         ...   \n",
       "2296       57.0        86.0  0.662791  0.434343   64.677670   16.741483   \n",
       "2297       64.0       117.0  0.547009  0.590909   83.830431   65.251036   \n",
       "2298       69.0        99.0  0.696970  0.500000   78.250969   16.554800   \n",
       "2299       63.0       107.0  0.588785  0.540404   75.685128   55.708762   \n",
       "2300       62.0       122.0  0.508197  0.616162   90.870772  176.829640   \n",
       "\n",
       "      hr_std_3h  hr_median_3h  hr_rest_rate_3h  hr_moderate_rate_3h  \\\n",
       "2     10.354859          77.0         0.555243             0.179775   \n",
       "3      9.661762          58.0         0.553427             0.185484   \n",
       "4     12.193160          83.0         0.011177             0.885246   \n",
       "5     12.917908          72.0         0.117241             0.709483   \n",
       "6     10.910272         100.0         0.000000             0.988473   \n",
       "...         ...           ...              ...                  ...   \n",
       "2296   4.091636          64.0         0.988350             0.005825   \n",
       "2297   8.077811          82.0         0.199817             0.435380   \n",
       "2298   4.068759          77.0         0.708333             0.123062   \n",
       "2299   7.463830          73.0         0.749744             0.130256   \n",
       "2300  13.297731          90.0         0.205551             0.761492   \n",
       "\n",
       "      hr_very_active_rate_3h   SDNN_1h   pHR2_1h  rMSSD_1h  low_hr_1h  \\\n",
       "2                   0.081461  0.000918  0.123077  1.950937       64.0   \n",
       "3                   0.023185  0.002703  0.178771  2.899143       44.0   \n",
       "4                   0.346498  0.001724  0.180180  2.271544       58.0   \n",
       "5                   0.141379  0.001187  0.077694  1.869824       57.0   \n",
       "6                   0.697406  0.001238  0.115566  1.631789       77.0   \n",
       "...                      ...       ...       ...       ...        ...   \n",
       "2296                0.000000  0.000665  0.042169  1.298748       59.0   \n",
       "2297                0.209899  0.000345  0.087209  1.422412       73.0   \n",
       "2298                0.037791  0.000350  0.104615  1.705196       72.0   \n",
       "2299                0.069744  0.001308  0.108808  1.821006       67.0   \n",
       "2300                0.504770  0.000643  0.067055  2.100257       62.0   \n",
       "\n",
       "      high_hr_1h    l_h_1h     CR_1h  hr_mean_1h   hr_var_1h  hr_std_1h  \\\n",
       "2           99.0  0.646465  0.779528   76.411043   31.498216   5.612327   \n",
       "3          103.0  0.427184  0.811024   59.724234  113.496366  10.653467   \n",
       "4          119.0  0.487395  0.937008   89.058427  183.032615  13.528955   \n",
       "5          101.0  0.564356  0.770992   72.535000   40.655414   6.376160   \n",
       "6          115.0  0.669565  0.877863   95.423529  119.768313  10.943871   \n",
       "...          ...       ...       ...         ...         ...        ...   \n",
       "2296        76.0  0.776316  0.383838   66.972973    8.863725   2.977201   \n",
       "2297        85.0  0.858824  0.429293   78.936232    4.623829   2.150309   \n",
       "2298        87.0  0.827586  0.439394   76.671779    4.350401   2.085762   \n",
       "2299       107.0  0.626168  0.540404   79.976744   78.255934   8.846238   \n",
       "2300       101.0  0.613861  0.510101   88.598837   21.961048   4.686262   \n",
       "\n",
       "      hr_median_1h  hr_rest_rate_1h  hr_moderate_rate_1h  \\\n",
       "2             76.0         0.690184             0.070552   \n",
       "3             57.0         0.604457             0.200557   \n",
       "4             88.0         0.013483             0.925843   \n",
       "5             72.0         0.012500             0.835000   \n",
       "6            100.0         0.000000             1.000000   \n",
       "...            ...              ...                  ...   \n",
       "2296          67.0         1.000000             0.000000   \n",
       "2297          79.0         0.414493             0.052174   \n",
       "2298          76.0         0.858896             0.012270   \n",
       "2299          78.0         0.563307             0.260982   \n",
       "2300          89.0         0.023256             0.956395   \n",
       "\n",
       "      hr_very_active_rate_1h  SDNN_30m  pHR2_30m  rMSSD_30m  low_hr_30m  \\\n",
       "2                   0.000000  0.000943  0.140244   1.844570        69.0   \n",
       "3                   0.038997  0.002822  0.125000   2.251811        50.0   \n",
       "4                   0.476404  0.001571  0.172414   2.237032        66.0   \n",
       "5                   0.020000  0.000638  0.010000   1.046422        65.0   \n",
       "6                   0.628235  0.001121  0.048913   1.242368        77.0   \n",
       "...                      ...       ...       ...        ...         ...   \n",
       "2296                0.000000  0.000352  0.000000   0.731768        65.0   \n",
       "2297                0.000000  0.000289  0.092486   1.476208        73.0   \n",
       "2298                0.000000  0.000323  0.057692   1.365791        72.0   \n",
       "2299                0.175711  0.000631  0.102564   1.647064        67.0   \n",
       "2300                0.351744  0.000298  0.012270   1.030218        84.0   \n",
       "\n",
       "      high_hr_30m   l_h_30m    CR_30m  hr_mean_30m  hr_var_30m  hr_std_30m  \\\n",
       "2            99.0  0.696970  0.779528    78.654545   37.800665    6.148225   \n",
       "3           103.0  0.485437  0.811024    60.913514  150.818566   12.280821   \n",
       "4           117.0  0.564103  0.921260    88.798283  154.722066   12.438732   \n",
       "5            82.0  0.792683  0.625954    71.228856   10.887363    3.299600   \n",
       "6           111.0  0.693694  0.847328    85.583784   77.168214    8.784544   \n",
       "...           ...       ...       ...          ...         ...         ...   \n",
       "2296         72.0  0.902778  0.363636    68.923077    2.794045    1.671540   \n",
       "2297         84.0  0.869048  0.424242    77.632184    3.043120    1.744454   \n",
       "2298         82.0  0.878049  0.414141    75.764331    3.540258    1.881557   \n",
       "2299         94.0  0.712766  0.474747    78.326531   15.533857    3.941301   \n",
       "2300         96.0  0.875000  0.484848    88.384146    5.587723    2.363836   \n",
       "\n",
       "      hr_median_30m  hr_rest_rate_30m  hr_moderate_rate_30m  \\\n",
       "2              77.0          0.539394              0.121212   \n",
       "3              57.0          0.675676              0.151351   \n",
       "4              86.0          0.000000              0.952790   \n",
       "5              71.0          0.000000              0.885572   \n",
       "6              82.0          0.000000              1.000000   \n",
       "...             ...               ...                   ...   \n",
       "2296           69.0          1.000000              0.000000   \n",
       "2297           78.0          0.706897              0.005747   \n",
       "2298           76.0          0.910828              0.000000   \n",
       "2299           78.0          0.551020              0.107143   \n",
       "2300           88.0          0.000000              1.000000   \n",
       "\n",
       "      hr_very_active_rate_30m  SDNN_10m  pHR2_10m  rMSSD_10m  low_hr_10m  \\\n",
       "2                    0.000000  0.001125  0.186441   1.978700        71.0   \n",
       "3                    0.075676  0.003763  0.188406   3.180557        50.0   \n",
       "4                    0.446352  0.001028  0.166667   2.455153        66.0   \n",
       "5                    0.000000  0.000624  0.027778   1.201850        65.0   \n",
       "6                    0.194595  0.000255  0.000000   0.820413        79.0   \n",
       "...                       ...       ...       ...        ...         ...   \n",
       "2296                 0.000000  0.000270  0.000000   0.510754        66.0   \n",
       "2297                 0.000000  0.000310  0.056604   1.197482        73.0   \n",
       "2298                 0.000000  0.000258  0.060000   1.174734        72.0   \n",
       "2299                 0.025510  0.000411  0.028571   1.207122        72.0   \n",
       "2300                 0.237805  0.000222  0.000000   0.612372        86.0   \n",
       "\n",
       "      high_hr_10m   l_h_10m    CR_10m  hr_mean_10m  hr_var_10m  hr_std_10m  \\\n",
       "2            99.0  0.717172  0.779528    81.916667   61.806497    7.861711   \n",
       "3           103.0  0.485437  0.811024    66.628571  325.019462   18.028296   \n",
       "4            91.0  0.725275  0.716535    77.589041   38.745434    6.224583   \n",
       "5            82.0  0.792683  0.625954    72.178082   10.870624    3.297063   \n",
       "6            85.0  0.929412  0.648855    81.320755    2.914369    1.707152   \n",
       "...           ...       ...       ...          ...         ...         ...   \n",
       "2296         72.0  0.916667  0.363636    69.808511    1.723404    1.312785   \n",
       "2297         81.0  0.901235  0.409091    76.907407    3.444095    1.855827   \n",
       "2298         79.0  0.911392  0.398990    74.843137    2.134902    1.461130   \n",
       "2299         84.0  0.857143  0.424242    79.394366    6.670825    2.582794   \n",
       "2300         92.0  0.934783  0.464646    88.061224    3.058673    1.748906   \n",
       "\n",
       "      hr_median_10m  hr_rest_rate_10m  hr_moderate_rate_10m  \\\n",
       "2              80.0          0.316667              0.233333   \n",
       "3              56.0          0.557143              0.342857   \n",
       "4              77.0          0.000000              0.849315   \n",
       "5              72.0          0.000000              0.931507   \n",
       "6              81.0          0.000000              1.000000   \n",
       "...             ...               ...                   ...   \n",
       "2296           70.0          1.000000              0.000000   \n",
       "2297           77.0          0.814815              0.000000   \n",
       "2298           75.0          0.980392              0.000000   \n",
       "2299           79.0          0.338028              0.112676   \n",
       "2300           88.0          0.000000              1.000000   \n",
       "\n",
       "      hr_very_active_rate_10m   SDNN_5m   pHR2_5m  rMSSD_5m  low_hr_5m  \\\n",
       "2                    0.000000  0.001094  0.125000  1.968502       76.0   \n",
       "3                    0.200000  0.000643  0.035714  1.224745       50.0   \n",
       "4                    0.054795  0.001182  0.181818  2.037527       66.0   \n",
       "5                    0.000000  0.000522  0.054054  1.414214       69.0   \n",
       "6                    0.000000  0.000252  0.000000  0.721110       79.0   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2296                 0.000000  0.000113  0.000000  0.417029       70.0   \n",
       "2297                 0.000000  0.000280  0.038462  1.143544       73.0   \n",
       "2298                 0.000000  0.000221  0.040000  1.000000       73.0   \n",
       "2299                 0.000000  0.000292  0.027027  1.196843       77.0   \n",
       "2300                 0.244898  0.000208  0.000000  0.807573       86.0   \n",
       "\n",
       "      high_hr_5m    l_h_5m     CR_5m  hr_mean_5m  hr_var_5m  hr_std_5m  \\\n",
       "2           99.0  0.767677  0.779528   85.757576  68.189394   8.257687   \n",
       "3           58.0  0.862069  0.456693   53.034483   3.463054   1.860928   \n",
       "4           91.0  0.725275  0.716535   76.852941  51.947415   7.207456   \n",
       "5           82.0  0.841463  0.625954   74.000000   8.648649   2.940858   \n",
       "6           84.0  0.940476  0.641221   81.846154   2.935385   1.713296   \n",
       "...          ...       ...       ...         ...        ...        ...   \n",
       "2296        72.0  0.972222  0.363636   70.625000   0.331522   0.575779   \n",
       "2297        79.0  0.924051  0.398990   76.037037   2.729345   1.652073   \n",
       "2298        77.0  0.948052  0.388889   74.269231   1.564615   1.250846   \n",
       "2299        84.0  0.916667  0.424242   80.842105   3.704125   1.924610   \n",
       "2300        92.0  0.934783  0.464646   89.166667   2.840580   1.685402   \n",
       "\n",
       "      hr_median_5m  hr_rest_rate_5m  hr_moderate_rate_5m  \\\n",
       "2             82.0         0.181818             0.424242   \n",
       "3             53.0         1.000000             0.000000   \n",
       "4             75.0         0.000000             0.764706   \n",
       "5             73.5         0.000000             1.000000   \n",
       "6             82.5         0.000000             1.000000   \n",
       "...            ...              ...                  ...   \n",
       "2296          71.0         1.000000             0.000000   \n",
       "2297          76.0         0.925926             0.000000   \n",
       "2298          74.0         1.000000             0.000000   \n",
       "2299          81.0         0.105263             0.210526   \n",
       "2300          89.5         0.000000             1.000000   \n",
       "\n",
       "      hr_very_active_rate_5m  hr_0  hr_0.3  hr_0.5  hr_0.8   hr_1  \n",
       "2                   0.000000  63.0    77.0    85.0    99.0  127.0  \n",
       "3                   0.000000  42.0    58.0    65.0    88.0  127.0  \n",
       "4                   0.117647  42.0    61.0    70.0    88.0  127.0  \n",
       "5                   0.000000  42.0    58.0    67.0    87.0  131.0  \n",
       "6                   0.000000  42.0    60.0    71.0    94.0  131.0  \n",
       "...                      ...   ...     ...     ...     ...    ...  \n",
       "2296                0.000000  49.0    79.0    82.0    89.0  198.0  \n",
       "2297                0.000000  49.0    78.0    82.0    89.0  198.0  \n",
       "2298                0.000000  49.0    78.0    82.0    89.0  198.0  \n",
       "2299                0.000000  49.0    78.0    82.0    89.0  198.0  \n",
       "2300                0.500000  49.0    78.0    82.0    89.0  198.0  \n",
       "\n",
       "[2017 rows x 205 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_complete_nona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the dataset\n",
    "#Columns to drop (the normal RF is not goign to include 'subject')\n",
    "cols_drop = ['la_p',\t'ha_p',\t'ha_n',\t'la_n',\t'la',\t'p',\t'n',\t'ha',\n",
    "              'start_survey','survey_no','experiment', 'VALENCE', 'Date_only_date', 'Subject', 'Date', \n",
    "             'start_survey_30m_ahead', 'start_survey_1h_ahead',\t'start_survey_3h_ahead', 'start_survey_5m_ahead', 'start_survey_10m_ahead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_repeated = DF_complete_nona.groupby('subject').aggregate('count')['experiment'].sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need 403 subjects for the test set\n"
     ]
    }
   ],
   "source": [
    "print(f'I need {round(20 * DF_complete_nona.shape[0] / 100)} subjects for the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200 unknown and 200 known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_repeated[:21].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1051', 'DND083', '1030', '1087', 'DND091', 'DND030', 'DND115', '1029',\n",
       "       '1041', 'DND007', '1018', 'DND013', '1037', '1032', '1045', '1014',\n",
       "       'DND046', '1060', 'DND006', 'DND070', 'DND100'],\n",
       "      dtype='object', name='subject')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_repeated[:21].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unknown_test = DF_complete_nona.loc[DF_complete_nona['subject'].isin(list_of_repeated[:21].index)].copy()\n",
    "X_unknown_test = X_unknown_test.drop(columns = cols_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Using the subjects that are NOT in the unknow dataset\n",
    "X_train, X_known_test = train_test_split(DF_complete_nona.loc[~DF_complete_nona['subject'].isin(list_of_repeated[:21].index)], test_size = .11, random_state = 7)\n",
    "#The random state is to be sure that I am using the same test set for MERF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = cols_drop)\n",
    "X_known_test = X_known_test.drop(columns= cols_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will store original dataset with the `_subj` ending to store the DF that I will use in the MERF model \n",
    "X_train_subj = X_train.copy()\n",
    "X_known_test_subj = X_known_test.copy()\n",
    "X_unknown_test_subj = X_unknown_test.copy()\n",
    "X_unified_test_subj = pd.concat([X_known_test_subj,X_unknown_test_subj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have my datasets, lets generate the `y` datasets. \n",
    "There would  be 3 dataset: \n",
    "- y_train\n",
    "- y_test_unknow\n",
    "- y_test_know\n",
    "- y_test_unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['VALENCE_mean'].copy()\n",
    "y_test_unknow = X_unknown_test['VALENCE_mean'].copy()\n",
    "y_test_know = X_known_test['VALENCE_mean'].copy()\n",
    "X_unified_test = pd.concat([X_known_test,X_unknown_test])\n",
    "y_test_unified = X_unified_test['VALENCE_mean'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Valence from all the train data\n",
    "for df in [X_known_test,X_train,X_unified_test, X_unknown_test]:\n",
    "    df.drop(columns = 'VALENCE_mean',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of the `Unknown subjects` vs `Known subjects`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bac566ac88>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(y_test_know)\n",
    "sns.distplot(y_test_unknow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### They look very similar. \n",
    "We do not have evidence to say that the distribution is different between groups. We are going to proceed with this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We should remove the subject label for the Lasso and RF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#drop subject\n",
    "X_train = X_train.drop(columns = 'subject')\n",
    "X_unified_test = X_unified_test.drop(columns='subject')\n",
    "X_unknown_test = X_unknown_test.drop(columns='subject')\n",
    "X_known_test = X_known_test.drop(columns='subject')\n",
    "#Use the train dataset to fit my scaler\n",
    "SCALER = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cols name (useuful for lasso regression and feature importance)\n",
    "cols_coef = X_unified_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply scaler to the DF \n",
    "X_train_scaled = SCALER.transform(X_train)\n",
    "X_unified_test_scaled = SCALER.transform(X_unified_test )\n",
    "X_unknown_test_scaled = SCALER.transform(X_unknown_test)\n",
    "X_known_test_scaled = SCALER.transform(X_known_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean [Mean Square Error] : -3.2391907449684904e+23, [Mean Square Error] STD : 4.580907482647849e+23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# evaluate an LDA model on the dataset using k-fold cross validation\n",
    "model = LinearRegression()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring ='neg_mean_squared_error')\n",
    "print(f'Mean [Mean Square Error] : {result.mean()}, [Mean Square Error] STD : {result.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not seem that a linear regression is going to be useful to predict the valence. Terrible Mean Square Error during the CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,\n",
    "             test_set_name = ['Unknown','Known', 'Unified'],\n",
    "             x_test = [X_unknown_test_scaled, X_known_test_scaled, X_unified_test_scaled] ,\n",
    "             y_test = [y_test_unknow, y_test_know, y_test_unified] ):\n",
    "    '''\n",
    "    Evaluate MAE, MSE,  RMSE of a model for all the test sets\n",
    "    '''\n",
    "    #initialize columns\n",
    "    df = pd.DataFrame(columns = ['Test set', 'MAE', 'MSE', 'RMSE'])\n",
    "    \n",
    "    for ts , x , y in zip(test_set_name, x_test, y_test):\n",
    "        predicted = model.predict(x)\n",
    "        rmse  = np.sqrt(mean_squared_error(y, predicted))\n",
    "        mae =  mean_absolute_error(y,predicted)\n",
    "        mse = mean_squared_error(y, predicted)\n",
    "        df = df.append({'Test set' : ts,\n",
    "                        'MAE' : mae,\n",
    "                        'MSE' : mse,\n",
    "                        'RMSE' : rmse}, ignore_index= True )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8.167547e+11</td>\n",
       "      <td>1.437946e+25</td>\n",
       "      <td>3.792026e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>9.733381e-01</td>\n",
       "      <td>1.608314e+00</td>\n",
       "      <td>1.268193e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>4.011403e+11</td>\n",
       "      <td>7.062316e+24</td>\n",
       "      <td>2.657502e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set           MAE           MSE          RMSE\n",
       "0  Unknown  8.167547e+11  1.437946e+25  3.792026e+12\n",
       "1    Known  9.733381e-01  1.608314e+00  1.268193e+00\n",
       "2  Unified  4.011403e+11  7.062316e+24  2.657502e+12"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model and check the values\n",
    "linear_reg = model.fit(X_train_scaled,y_train)\n",
    "evaluate(linear_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights of Simple Linear Regression\n",
    "If we only analize the predictions for the Unified dataset we can observe the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The simple linear regression is a very bad model.\n",
    "\n",
    "- It seems that the model is not able to correctly predict `Unknow` data. This could be because there are a lot of values that are repeated among subjects (all the demographic and personality data) and they are novel for new subjects. \n",
    "\n",
    "- The model is constantly over predicting (that why we have positive residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3518194696712271, tolerance: 0.18741089694166024\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=10000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=0,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'alpha': [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1,\n",
       "                                    0.2]}],\n",
       "             pre_dispatch='2*n_jobs', refit=False, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set lasso as the moedl\n",
    "model = Lasso(random_state=0, max_iter=10000)\n",
    "kfold = KFold(n_splits=5, random_state=7)\n",
    "\n",
    "#Params for GridSearch \n",
    "alphas = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "param_grid = [{'alpha': alphas}]\n",
    "clf = GridSearchCV(model, param_grid, cv=kfold, refit=False, scoring= 'neg_mean_squared_error')\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Negative Mean Square Error [Average]')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = clf.cv_results_['mean_test_score']\n",
    "scores_std = clf.cv_results_['std_test_score']\n",
    "std_error = scores_std / np.sqrt(5)\n",
    "plt.scatter(alphas, scores - std_error)\n",
    "plt.scatter(alphas, scores + std_error)\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Negative Mean Square Error [Average]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the Lasso regression with the best alpha value\n",
    "lasso_fit = Lasso(alpha= 0.01).fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso offers a useful feature selection given the importance of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 coefficients are > than 0. The original number of variables were 183\n"
     ]
    }
   ],
   "source": [
    "print(f'{(lasso_fit.coef_ > 0).sum()} coefficients are > than 0. The original number of variables were {len(lasso_fit.coef_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>hr_min</td>\n",
       "      <td>0.226690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LAP_actual</td>\n",
       "      <td>0.204600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HAP_actual</td>\n",
       "      <td>0.135467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HA_actual</td>\n",
       "      <td>0.120387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>LA_actual</td>\n",
       "      <td>0.106568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>BIS.5</td>\n",
       "      <td>0.083840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HA_ideal</td>\n",
       "      <td>0.073872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>BAS_FS</td>\n",
       "      <td>0.069436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Household_income</td>\n",
       "      <td>0.066268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>hr_rest_rate_1h</td>\n",
       "      <td>0.042158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>steps_var_1h</td>\n",
       "      <td>0.040358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Ethnicity_Black</td>\n",
       "      <td>0.039070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LAN_ideal</td>\n",
       "      <td>0.037835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Ethnicity_White</td>\n",
       "      <td>0.037353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>l_h_3h</td>\n",
       "      <td>0.034681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Marital_Status_Engaged</td>\n",
       "      <td>0.034256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>running_rate_3h</td>\n",
       "      <td>0.027314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>steps_max_3h</td>\n",
       "      <td>0.026052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>steps_var_10m</td>\n",
       "      <td>0.025345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>move_rate_10m</td>\n",
       "      <td>0.024468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>hr_var_10m</td>\n",
       "      <td>0.023328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>pHR2_3h</td>\n",
       "      <td>0.022765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>steps_median_10m</td>\n",
       "      <td>0.019595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>steps_median_3h</td>\n",
       "      <td>0.018372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>steps_min_1h</td>\n",
       "      <td>0.010854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>steps_min_10m</td>\n",
       "      <td>0.010451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Number of Awakenings</td>\n",
       "      <td>0.008793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>P_actual</td>\n",
       "      <td>0.007541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>hr_moderate_rate_5m</td>\n",
       "      <td>0.006753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>steps_var_30m</td>\n",
       "      <td>0.006128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>hr_var_1h</td>\n",
       "      <td>0.005482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>steps_median_30m</td>\n",
       "      <td>0.005313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Period_of_day_Morning</td>\n",
       "      <td>0.004734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NS_total</td>\n",
       "      <td>0.003652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>hr_0</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Coefficients\n",
       "27                  hr_min      0.226690\n",
       "4               LAP_actual      0.204600\n",
       "0               HAP_actual      0.135467\n",
       "1                HA_actual      0.120387\n",
       "5                LA_actual      0.106568\n",
       "9                    BIS.5      0.083840\n",
       "2                 HA_ideal      0.073872\n",
       "8                   BAS_FS      0.069436\n",
       "7         Household_income      0.066268\n",
       "31         hr_rest_rate_1h      0.042158\n",
       "20            steps_var_1h      0.040358\n",
       "12         Ethnicity_Black      0.039070\n",
       "3                LAN_ideal      0.037835\n",
       "13         Ethnicity_White      0.037353\n",
       "29                  l_h_3h      0.034681\n",
       "14  Marital_Status_Engaged      0.034256\n",
       "18         running_rate_3h      0.027314\n",
       "16            steps_max_3h      0.026052\n",
       "24           steps_var_10m      0.025345\n",
       "26           move_rate_10m      0.024468\n",
       "32              hr_var_10m      0.023328\n",
       "28                 pHR2_3h      0.022765\n",
       "25        steps_median_10m      0.019595\n",
       "17         steps_median_3h      0.018372\n",
       "19            steps_min_1h      0.010854\n",
       "23           steps_min_10m      0.010451\n",
       "11    Number of Awakenings      0.008793\n",
       "6                 P_actual      0.007541\n",
       "33     hr_moderate_rate_5m      0.006753\n",
       "21           steps_var_30m      0.006128\n",
       "30               hr_var_1h      0.005482\n",
       "22        steps_median_30m      0.005313\n",
       "15   Period_of_day_Morning      0.004734\n",
       "10                NS_total      0.003652\n",
       "34                    hr_0      0.000088"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's make a table with the different coefficients and residuals\n",
    "lasso_coef_df = pd.DataFrame(data = {'Feature' : cols_coef[lasso_fit.coef_ > 0],\n",
    "                                     'Coefficients' : lasso_fit.coef_[lasso_fit.coef_ > 0]})\n",
    "lasso_coef_df = lasso_coef_df.sort_values(by= 'Coefficients', ascending = False)\n",
    "lasso_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.992435</td>\n",
       "      <td>1.545168</td>\n",
       "      <td>1.243048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.858198</td>\n",
       "      <td>1.254919</td>\n",
       "      <td>1.120232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.924127</td>\n",
       "      <td>1.397471</td>\n",
       "      <td>1.182147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.992435  1.545168  1.243048\n",
       "1    Known  0.858198  1.254919  1.120232\n",
       "2  Unified  0.924127  1.397471  1.182147"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lasso_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights of Lasso regression\n",
    "We can observe that Lasso regression is orders of magnitude more accurate than a the simple linear regression. \n",
    "\n",
    "We should compare the performance against other models. We are going to explore different non-linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest `without` Subject as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=7, n_jobs = -1) #this could take time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 40.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_sta...\n",
       "                   iid='warn', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=7, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "rf_random.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open ('./rf.pickle','wb') as file:\n",
    "#    pickle.dump(rf_random,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0021337717060685"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how good is the RF to predict the Unified test set with the best params for the Random Search\n",
    "np.sqrt(mean_squared_error(rf_random.best_estimator_.predict(X_unified_test_scaled), y_test_unified))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [1500,1600,1700],\n",
    "             'min_samples_split': [4,5,6],\n",
    "             'min_samples_leaf': [3,4,5],\n",
    "             'max_features': ['sqrt'],\n",
    "             'max_depth': [100, 110, 120 ,130,140],\n",
    "             'bootstrap': [False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use k-fold \n",
    "kfold = KFold(n_splits=5, random_state=7)\n",
    "#Apply Grid Search to fine tune the parameters\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = kfold, n_jobs = -1, verbose = 2, scoring= 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done 675 out of 675 | elapsed: 31.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn'...\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False],\n",
       "                         'max_depth': [100, 110, 120, 130, 140],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [3, 4, 5],\n",
       "                         'min_samples_split': [4, 5, 6],\n",
       "                         'n_estimators': [1500, 1600, 1700]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=140,\n",
       "                      max_features='sqrt', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=4, min_samples_split=4,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for best estim\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=140,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=4, min_samples_split=4,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Let's assign the best estimator to my model\n",
    "rf_optimized = grid_search.best_estimator_\n",
    "print(rf_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open ('./rf_optimized.pickle','rb') as file:\n",
    "#      model_rf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.778032</td>\n",
       "      <td>0.930356</td>\n",
       "      <td>0.964550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.795444</td>\n",
       "      <td>1.083959</td>\n",
       "      <td>1.041134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.786892</td>\n",
       "      <td>1.008519</td>\n",
       "      <td>1.004250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.778032  0.930356  0.964550\n",
       "1    Known  0.795444  1.083959  1.041134\n",
       "2  Unified  0.786892  1.008519  1.004250"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(rf_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>LAP_actual</td>\n",
       "      <td>0.036694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Neuroticism_scaled</td>\n",
       "      <td>0.032171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HAP_actual</td>\n",
       "      <td>0.022911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>P_actual</td>\n",
       "      <td>0.020183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.017804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>LAN_actual</td>\n",
       "      <td>0.017248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Extraversion_scaled</td>\n",
       "      <td>0.017181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>hr_1</td>\n",
       "      <td>0.013784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>hr_max</td>\n",
       "      <td>0.012846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>BMI</td>\n",
       "      <td>0.012665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Importance\n",
       "8             LAP_actual    0.036694\n",
       "28    Neuroticism_scaled    0.032171\n",
       "2             HAP_actual    0.022911\n",
       "14              P_actual    0.020183\n",
       "16                   Age    0.017804\n",
       "6             LAN_actual    0.017248\n",
       "27   Extraversion_scaled    0.017181\n",
       "182                 hr_1    0.013784\n",
       "105               hr_max    0.012846\n",
       "19                   BMI    0.012665"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance for RF\n",
    "features_df = pd.DataFrame(data = {'Feature' : cols_coef,\n",
    "                                   'Importance' : rf_optimized.feature_importances_})\n",
    "features_df = features_df.sort_values(by= 'Importance', ascending = False)\n",
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights of RF\n",
    "RF shas better scores than Lasso. \n",
    "\n",
    "Also, it has a complete list of feature importance. This could be even more useful than only using 38 coeficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Mixed Effect Random Forest (MERF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install the MERF package\n",
    "conda install -c leylabmpi merf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting merf\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/67/857915b2fecbe73b6ef6c6c05fb532967af1c9ec4bedb9ca3eb648f71a1f/merf-0.3-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (from merf) (1.16.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (from merf) (0.21.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (from merf) (0.25.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (from scikit-learn->merf) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (from scikit-learn->merf) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (from pandas->merf) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (from pandas->merf) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->merf) (1.12.0)\n",
      "Installing collected packages: merf\n",
      "Successfully installed merf-0.3\n"
     ]
    }
   ],
   "source": [
    "#The anaconda promt trwed a weird message. Installing merf via pip instead.\n",
    "!pip install merf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merf.merf import MERF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I need to use the `subject` feature to train this model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Valence from all the train data\n",
    "for df in [X_known_test_subj, X_train_subj, X_unified_test_subj, X_unknown_test_subj]:\n",
    "    df.drop(columns = 'VALENCE_mean',inplace = True)\n",
    "\n",
    "#X_train_subj \n",
    "#X_known_test_subj \n",
    "#X_unknown_test_subj "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing all the parameters for MERF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z is and all ones parameter. Because we have only one randome effect in this case : `subject`\n",
    "\n",
    "# Z\n",
    "X_train_subj['Z'] = 1 \n",
    "Z_train = X_train_subj[['Z']] #they use  `DataFrame` instead of `Series` format. At least for Z.\n",
    "# Train - data\n",
    "X_train_subj.drop(columns = 'Z', inplace = True)\n",
    "X_train_vector = X_train_subj.drop(columns = 'subject')\n",
    "#Clusters - Subject\n",
    "clusters_train = X_train_subj['subject']\n",
    "# y - labels\n",
    "y_train_vector = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Creating test datasets `with` subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is not scaled. Should check if this matters, i don not think that it matters for RF models.\n",
    "## [https://stackoverflow.com/questions/8961586/do-i-need-to-normalize-or-scale-data-for-randomforest-r-package]\n",
    "\n",
    "#Known values\n",
    "X_known = X_known_test_subj.drop(columns = 'subject')\n",
    "Z_known = pd.DataFrame(data = np.repeat(1,X_known.shape[0])) #it's always a column of ones in a `Dataframe` format\n",
    "clusters_known = X_known_test_subj['subject']\n",
    "y_known = y_test_know\n",
    "\n",
    "# Unknown values (new)\n",
    "X_new = X_unknown_test_subj.drop(columns = 'subject')\n",
    "Z_new = pd.DataFrame(data = np.repeat(1,X_new.shape[0]))\n",
    "clusters_new = X_unknown_test_subj['subject']\n",
    "y_new = y_test_unknow\n",
    "\n",
    "# Unified values\n",
    "X_unified = X_unified_test_subj.drop(columns = 'subject')\n",
    "Z_unified = pd.DataFrame(data = np.repeat(1,X_unified.shape[0]))\n",
    "clusters_unified = X_unified_test_subj['subject']\n",
    "y_unified  = y_test_unified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mapper to recode the subjects into integers\n",
    "mapper = {k:v for k,v in zip(DF_complete_nona.subject.unique(),range(len(DF_complete_nona.subject.unique()))) }\n",
    "clusters_train = clusters_train.replace(mapper)\n",
    "clusters_known = clusters_known.replace(mapper)\n",
    "clusters_new = clusters_new.replace(mapper)\n",
    "clusters_unified = clusters_unified.replace(mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train MERF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [merf.py:250] GLL is 1361.6089703623347 at iteration 1.\n",
      "INFO     [merf.py:250] GLL is 1368.097541647414 at iteration 2.\n",
      "INFO     [merf.py:250] GLL is 1355.4717772926763 at iteration 3.\n",
      "INFO     [merf.py:250] GLL is 1340.1875827699398 at iteration 4.\n",
      "INFO     [merf.py:250] GLL is 1338.0426747085826 at iteration 5.\n",
      "INFO     [merf.py:250] GLL is 1325.757372191239 at iteration 6.\n",
      "INFO     [merf.py:250] GLL is 1321.9960370016404 at iteration 7.\n",
      "INFO     [merf.py:250] GLL is 1307.0620392866417 at iteration 8.\n",
      "INFO     [merf.py:250] GLL is 1280.4392652358201 at iteration 9.\n",
      "INFO     [merf.py:250] GLL is 1275.6561666236532 at iteration 10.\n",
      "INFO     [merf.py:250] GLL is 1256.6298965710992 at iteration 11.\n",
      "INFO     [merf.py:250] GLL is 1236.4585177289077 at iteration 12.\n",
      "INFO     [merf.py:250] GLL is 1239.9758201704897 at iteration 13.\n",
      "INFO     [merf.py:250] GLL is 1231.9704651175562 at iteration 14.\n",
      "INFO     [merf.py:250] GLL is 1219.4381613627618 at iteration 15.\n",
      "INFO     [merf.py:250] GLL is 1218.1262294545816 at iteration 16.\n",
      "INFO     [merf.py:250] GLL is 1221.687582059506 at iteration 17.\n",
      "INFO     [merf.py:250] GLL is 1200.8875721540207 at iteration 18.\n",
      "INFO     [merf.py:250] GLL is 1200.5301621570313 at iteration 19.\n",
      "INFO     [merf.py:250] GLL is 1204.8298469778226 at iteration 20.\n",
      "INFO     [merf.py:250] GLL is 1194.0838397985422 at iteration 21.\n",
      "INFO     [merf.py:250] GLL is 1180.6604591986502 at iteration 22.\n",
      "INFO     [merf.py:250] GLL is 1174.7732566674124 at iteration 23.\n",
      "INFO     [merf.py:250] GLL is 1168.512453065341 at iteration 24.\n",
      "INFO     [merf.py:250] GLL is 1182.1895582766938 at iteration 25.\n",
      "INFO     [merf.py:250] GLL is 1166.378219963413 at iteration 26.\n",
      "INFO     [merf.py:250] GLL is 1151.3240491810466 at iteration 27.\n",
      "INFO     [merf.py:250] GLL is 1162.2020623416252 at iteration 28.\n",
      "INFO     [merf.py:250] GLL is 1142.895640553718 at iteration 29.\n",
      "INFO     [merf.py:250] GLL is 1134.651998650297 at iteration 30.\n",
      "INFO     [merf.py:250] GLL is 1141.6926876335638 at iteration 31.\n",
      "INFO     [merf.py:250] GLL is 1131.880496821864 at iteration 32.\n",
      "INFO     [merf.py:250] GLL is 1136.41352451101 at iteration 33.\n",
      "INFO     [merf.py:250] GLL is 1155.504527714932 at iteration 34.\n",
      "INFO     [merf.py:250] GLL is 1131.3733525754367 at iteration 35.\n",
      "INFO     [merf.py:250] GLL is 1130.7694663725574 at iteration 36.\n",
      "INFO     [merf.py:250] GLL is 1133.373870284313 at iteration 37.\n",
      "INFO     [merf.py:250] GLL is 1125.1210520475279 at iteration 38.\n",
      "INFO     [merf.py:250] GLL is 1132.8147373889294 at iteration 39.\n",
      "INFO     [merf.py:250] GLL is 1117.463012855167 at iteration 40.\n",
      "INFO     [merf.py:250] GLL is 1131.4657439466268 at iteration 41.\n",
      "INFO     [merf.py:250] GLL is 1123.0477915969052 at iteration 42.\n",
      "INFO     [merf.py:250] GLL is 1111.3718891103267 at iteration 43.\n",
      "INFO     [merf.py:250] GLL is 1115.6322857720222 at iteration 44.\n",
      "INFO     [merf.py:250] GLL is 1107.0270154313705 at iteration 45.\n",
      "INFO     [merf.py:250] GLL is 1111.400418754881 at iteration 46.\n",
      "INFO     [merf.py:250] GLL is 1107.4160618250007 at iteration 47.\n",
      "INFO     [merf.py:250] GLL is 1084.8328896015673 at iteration 48.\n",
      "INFO     [merf.py:250] GLL is 1110.7093585396367 at iteration 49.\n",
      "INFO     [merf.py:250] GLL is 1095.8607209413638 at iteration 50.\n",
      "INFO     [merf.py:250] GLL is 1101.947878366236 at iteration 51.\n",
      "INFO     [merf.py:250] GLL is 1100.3984238665316 at iteration 52.\n",
      "INFO     [merf.py:250] GLL is 1102.1051640814642 at iteration 53.\n",
      "INFO     [merf.py:250] GLL is 1111.1740565903913 at iteration 54.\n",
      "INFO     [merf.py:250] GLL is 1095.019024330389 at iteration 55.\n",
      "INFO     [merf.py:250] GLL is 1095.0555817454256 at iteration 56.\n",
      "INFO     [merf.py:250] GLL is 1083.534580019932 at iteration 57.\n",
      "INFO     [merf.py:250] GLL is 1080.5770009820958 at iteration 58.\n",
      "INFO     [merf.py:250] GLL is 1074.7329167966968 at iteration 59.\n",
      "INFO     [merf.py:250] GLL is 1085.0136827765034 at iteration 60.\n",
      "INFO     [merf.py:250] GLL is 1068.3193735564132 at iteration 61.\n",
      "INFO     [merf.py:250] GLL is 1073.4524463518844 at iteration 62.\n",
      "INFO     [merf.py:250] GLL is 1078.5264640567993 at iteration 63.\n",
      "INFO     [merf.py:250] GLL is 1087.9185970951842 at iteration 64.\n",
      "INFO     [merf.py:250] GLL is 1072.5824041632015 at iteration 65.\n",
      "INFO     [merf.py:250] GLL is 1066.8321397719485 at iteration 66.\n",
      "INFO     [merf.py:250] GLL is 1069.2141566011417 at iteration 67.\n",
      "INFO     [merf.py:250] GLL is 1074.4379187570044 at iteration 68.\n",
      "INFO     [merf.py:250] GLL is 1070.5464522912841 at iteration 69.\n",
      "INFO     [merf.py:250] GLL is 1067.3311183640567 at iteration 70.\n",
      "INFO     [merf.py:250] GLL is 1079.7980599830057 at iteration 71.\n",
      "INFO     [merf.py:250] GLL is 1078.1063756145593 at iteration 72.\n",
      "INFO     [merf.py:250] GLL is 1071.1757431783008 at iteration 73.\n",
      "INFO     [merf.py:250] GLL is 1081.5608265658495 at iteration 74.\n",
      "INFO     [merf.py:250] GLL is 1071.7382478039658 at iteration 75.\n",
      "INFO     [merf.py:250] GLL is 1079.2781560822566 at iteration 76.\n",
      "INFO     [merf.py:250] GLL is 1055.2755802677452 at iteration 77.\n",
      "INFO     [merf.py:250] GLL is 1061.008693136318 at iteration 78.\n",
      "INFO     [merf.py:250] GLL is 1063.0075663749099 at iteration 79.\n",
      "INFO     [merf.py:250] GLL is 1068.8297931628551 at iteration 80.\n",
      "INFO     [merf.py:250] GLL is 1055.9624422695715 at iteration 81.\n",
      "INFO     [merf.py:250] GLL is 1041.0192328008495 at iteration 82.\n",
      "INFO     [merf.py:250] GLL is 1050.7197273201584 at iteration 83.\n",
      "INFO     [merf.py:250] GLL is 1064.125131471939 at iteration 84.\n",
      "INFO     [merf.py:250] GLL is 1055.5488825006332 at iteration 85.\n",
      "INFO     [merf.py:250] GLL is 1063.430320783428 at iteration 86.\n",
      "INFO     [merf.py:250] GLL is 1049.856732176983 at iteration 87.\n",
      "INFO     [merf.py:250] GLL is 1057.2914895012184 at iteration 88.\n",
      "INFO     [merf.py:250] GLL is 1043.8855577147879 at iteration 89.\n",
      "INFO     [merf.py:250] GLL is 1049.9370194831613 at iteration 90.\n",
      "INFO     [merf.py:250] GLL is 1060.8525053881017 at iteration 91.\n",
      "INFO     [merf.py:250] GLL is 1061.4728492380657 at iteration 92.\n",
      "INFO     [merf.py:250] GLL is 1054.4086320588028 at iteration 93.\n",
      "INFO     [merf.py:250] GLL is 1060.5348764731568 at iteration 94.\n",
      "INFO     [merf.py:250] GLL is 1044.2484349134245 at iteration 95.\n",
      "INFO     [merf.py:250] GLL is 1034.8044242607446 at iteration 96.\n",
      "INFO     [merf.py:250] GLL is 1040.8702216954555 at iteration 97.\n",
      "INFO     [merf.py:250] GLL is 1053.4146749988372 at iteration 98.\n",
      "INFO     [merf.py:250] GLL is 1041.1711828516138 at iteration 99.\n",
      "INFO     [merf.py:250] GLL is 1037.8125455904617 at iteration 100.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<merf.merf.MERF at 0x2bae3199888>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrf = MERF(n_estimators=300, max_iterations=100)\n",
    "mrf.fit(X_train_vector, Z_train, clusters_train, y_train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "with open('./mrf.pickle','wb') as file:\n",
    "    pickle.dump(mrf,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to evaluate different metrics for the model MERF\n",
    "def evaluate_MERF(model,\n",
    "             test_set_name = ['Unknown','Known', 'Unified' ],\n",
    "             x_test = [X_new, X_known, X_unified],\n",
    "             y_test = [y_new, y_known, y_unified],\n",
    "             Z = [Z_known],\n",
    "             clusters = [clusters_new, clusters_known, clusters_unified]):\n",
    "    '''\n",
    "    Evaluate MAE, MSE,  RMSE of a model for all the test sets\n",
    "    '''\n",
    "    #initialize columns\n",
    "    df = pd.DataFrame(columns = ['Test set', 'MAE', 'MSE', 'RMSE'])\n",
    "    \n",
    "    for ts , x , y, z, cluster in zip(test_set_name, x_test, y_test, Z, clusters):\n",
    "        predicted = model.predict(x, z, cluster)\n",
    "        rmse  = np.sqrt(mean_squared_error(y, predicted))\n",
    "        mae =  mean_absolute_error(y,predicted)\n",
    "        mse = mean_squared_error(y, predicted)\n",
    "        df = df.append({'Test set' : ts,\n",
    "                        'MAE' : mae,\n",
    "                        'MSE' : mse,\n",
    "                        'RMSE' : rmse}, ignore_index= True )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.806480</td>\n",
       "      <td>1.045034</td>\n",
       "      <td>1.022269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.807230</td>\n",
       "      <td>1.109694</td>\n",
       "      <td>1.053420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.806862</td>\n",
       "      <td>1.077937</td>\n",
       "      <td>1.038237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.806480  1.045034  1.022269\n",
       "1    Known  0.807230  1.109694  1.053420\n",
       "2  Unified  0.806862  1.077937  1.038237"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_MERF(mrf, \n",
    "              test_set_name = ['Unknown','Known', 'Unified'],\n",
    "              x_test = [X_new, X_known, X_unified],\n",
    "              y_test = [y_new, y_known, y_unified],\n",
    "              Z = [Z_new, Z_known, Z_unified],\n",
    "              clusters = [clusters_new, clusters_known, clusters_unified]              \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [merf.py:250] GLL is 1352.4844102148115 at iteration 1.\n",
      "INFO     [merf.py:250] GLL is 1346.9491315384612 at iteration 2.\n",
      "INFO     [merf.py:250] GLL is 1342.6623963839018 at iteration 3.\n",
      "INFO     [merf.py:250] GLL is 1332.6117662420447 at iteration 4.\n",
      "INFO     [merf.py:250] GLL is 1326.4270026941886 at iteration 5.\n",
      "INFO     [merf.py:250] GLL is 1307.7090352158298 at iteration 6.\n",
      "INFO     [merf.py:250] GLL is 1292.528100006028 at iteration 7.\n",
      "INFO     [merf.py:250] GLL is 1280.259551998944 at iteration 8.\n",
      "INFO     [merf.py:250] GLL is 1273.4706123528708 at iteration 9.\n",
      "INFO     [merf.py:250] GLL is 1265.6656059972386 at iteration 10.\n",
      "INFO     [merf.py:250] GLL is 1251.0841686827657 at iteration 11.\n",
      "INFO     [merf.py:250] GLL is 1232.0824647281077 at iteration 12.\n",
      "INFO     [merf.py:250] GLL is 1227.8803857119472 at iteration 13.\n",
      "INFO     [merf.py:250] GLL is 1219.4579114722644 at iteration 14.\n",
      "INFO     [merf.py:250] GLL is 1209.2942108658413 at iteration 15.\n",
      "INFO     [merf.py:250] GLL is 1205.3972827102502 at iteration 16.\n",
      "INFO     [merf.py:250] GLL is 1191.6031881051526 at iteration 17.\n",
      "INFO     [merf.py:250] GLL is 1191.7271205881673 at iteration 18.\n",
      "INFO     [merf.py:250] GLL is 1192.825591504881 at iteration 19.\n",
      "INFO     [merf.py:250] GLL is 1179.657572715538 at iteration 20.\n",
      "INFO     [merf.py:250] GLL is 1178.8932825582156 at iteration 21.\n",
      "INFO     [merf.py:250] GLL is 1161.018826496594 at iteration 22.\n",
      "INFO     [merf.py:250] GLL is 1162.3165714496135 at iteration 23.\n",
      "INFO     [merf.py:250] GLL is 1160.586727402563 at iteration 24.\n",
      "INFO     [merf.py:250] GLL is 1153.181977962855 at iteration 25.\n",
      "INFO     [merf.py:250] GLL is 1144.0315636738567 at iteration 26.\n",
      "INFO     [merf.py:250] GLL is 1143.6388267912087 at iteration 27.\n",
      "INFO     [merf.py:250] GLL is 1147.0812348864079 at iteration 28.\n",
      "INFO     [merf.py:250] GLL is 1145.049839238837 at iteration 29.\n",
      "INFO     [merf.py:250] GLL is 1134.2688639485414 at iteration 30.\n",
      "INFO     [merf.py:250] GLL is 1136.0068503174507 at iteration 31.\n",
      "INFO     [merf.py:250] GLL is 1126.0937806641402 at iteration 32.\n",
      "INFO     [merf.py:250] GLL is 1127.3992600757983 at iteration 33.\n",
      "INFO     [merf.py:250] GLL is 1117.622789838164 at iteration 34.\n",
      "INFO     [merf.py:250] GLL is 1119.7057193384858 at iteration 35.\n",
      "INFO     [merf.py:250] GLL is 1121.9050426626982 at iteration 36.\n",
      "INFO     [merf.py:250] GLL is 1109.369562210524 at iteration 37.\n",
      "INFO     [merf.py:250] GLL is 1111.7095703726866 at iteration 38.\n",
      "INFO     [merf.py:250] GLL is 1108.0279951493042 at iteration 39.\n",
      "INFO     [merf.py:250] GLL is 1111.1674624746333 at iteration 40.\n",
      "INFO     [merf.py:250] GLL is 1109.110461942989 at iteration 41.\n",
      "INFO     [merf.py:250] GLL is 1102.2008423287423 at iteration 42.\n",
      "INFO     [merf.py:250] GLL is 1096.5439403706255 at iteration 43.\n",
      "INFO     [merf.py:250] GLL is 1101.8794780978037 at iteration 44.\n",
      "INFO     [merf.py:250] GLL is 1097.0017384662297 at iteration 45.\n",
      "INFO     [merf.py:250] GLL is 1095.309535380916 at iteration 46.\n",
      "INFO     [merf.py:250] GLL is 1092.6167812474403 at iteration 47.\n",
      "INFO     [merf.py:250] GLL is 1085.8071579991638 at iteration 48.\n",
      "INFO     [merf.py:250] GLL is 1090.4645533140244 at iteration 49.\n",
      "INFO     [merf.py:250] GLL is 1090.447476793299 at iteration 50.\n",
      "INFO     [merf.py:250] GLL is 1084.4313668885784 at iteration 51.\n",
      "INFO     [merf.py:250] GLL is 1086.041619615059 at iteration 52.\n",
      "INFO     [merf.py:250] GLL is 1081.6926106083015 at iteration 53.\n",
      "INFO     [merf.py:250] GLL is 1075.484332707682 at iteration 54.\n",
      "INFO     [merf.py:250] GLL is 1082.8708670905899 at iteration 55.\n",
      "INFO     [merf.py:250] GLL is 1074.1062903362028 at iteration 56.\n",
      "INFO     [merf.py:250] GLL is 1075.4247394089957 at iteration 57.\n",
      "INFO     [merf.py:250] GLL is 1071.7166513255504 at iteration 58.\n",
      "INFO     [merf.py:250] GLL is 1073.302666852647 at iteration 59.\n",
      "INFO     [merf.py:250] GLL is 1071.7828310142963 at iteration 60.\n",
      "INFO     [merf.py:250] GLL is 1070.732723801961 at iteration 61.\n",
      "INFO     [merf.py:250] GLL is 1067.2681767880426 at iteration 62.\n",
      "INFO     [merf.py:250] GLL is 1061.5257296831444 at iteration 63.\n",
      "INFO     [merf.py:250] GLL is 1065.714932232535 at iteration 64.\n",
      "INFO     [merf.py:250] GLL is 1067.632860864531 at iteration 65.\n",
      "INFO     [merf.py:250] GLL is 1062.1151641061729 at iteration 66.\n",
      "INFO     [merf.py:250] GLL is 1057.6398666220791 at iteration 67.\n",
      "INFO     [merf.py:250] GLL is 1061.4295856085166 at iteration 68.\n",
      "INFO     [merf.py:250] GLL is 1061.7466158397597 at iteration 69.\n",
      "INFO     [merf.py:250] GLL is 1055.9220566750835 at iteration 70.\n",
      "INFO     [merf.py:250] GLL is 1053.3412235685498 at iteration 71.\n",
      "INFO     [merf.py:250] GLL is 1051.2198173553231 at iteration 72.\n",
      "INFO     [merf.py:250] GLL is 1051.161243754932 at iteration 73.\n",
      "INFO     [merf.py:250] GLL is 1053.5739078500483 at iteration 74.\n",
      "INFO     [merf.py:250] GLL is 1049.9836787343863 at iteration 75.\n",
      "INFO     [merf.py:250] GLL is 1042.6606115106863 at iteration 76.\n",
      "INFO     [merf.py:250] GLL is 1051.9721148124938 at iteration 77.\n",
      "INFO     [merf.py:250] GLL is 1049.396549249031 at iteration 78.\n",
      "INFO     [merf.py:250] GLL is 1037.0165777078673 at iteration 79.\n",
      "INFO     [merf.py:250] GLL is 1040.477642722034 at iteration 80.\n",
      "INFO     [merf.py:250] GLL is 1044.6933040196768 at iteration 81.\n",
      "INFO     [merf.py:250] GLL is 1037.1392138504832 at iteration 82.\n",
      "INFO     [merf.py:250] GLL is 1045.868365739231 at iteration 83.\n",
      "INFO     [merf.py:250] GLL is 1038.599526996494 at iteration 84.\n",
      "INFO     [merf.py:250] GLL is 1039.1323866657262 at iteration 85.\n",
      "INFO     [merf.py:250] GLL is 1043.1868083018842 at iteration 86.\n",
      "INFO     [merf.py:250] GLL is 1039.3311192453643 at iteration 87.\n",
      "INFO     [merf.py:250] GLL is 1044.2485068892222 at iteration 88.\n",
      "INFO     [merf.py:250] GLL is 1030.12508579114 at iteration 89.\n",
      "INFO     [merf.py:250] GLL is 1033.6172506839998 at iteration 90.\n",
      "INFO     [merf.py:250] GLL is 1039.0334201335238 at iteration 91.\n",
      "INFO     [merf.py:250] GLL is 1032.4849278405059 at iteration 92.\n",
      "INFO     [merf.py:250] GLL is 1031.328987275727 at iteration 93.\n",
      "INFO     [merf.py:250] GLL is 1034.277432752684 at iteration 94.\n",
      "INFO     [merf.py:250] GLL is 1031.220144667401 at iteration 95.\n",
      "INFO     [merf.py:250] GLL is 1028.7405284494369 at iteration 96.\n",
      "INFO     [merf.py:250] GLL is 1031.9180903011452 at iteration 97.\n",
      "INFO     [merf.py:250] GLL is 1028.5719819663123 at iteration 98.\n",
      "INFO     [merf.py:250] GLL is 1030.351532052036 at iteration 99.\n",
      "INFO     [merf.py:250] GLL is 1030.291379046105 at iteration 100.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<merf.merf.MERF at 0x2bb009ff1c8>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changed the number of estimators (CV is costly, should prepare a script and run it in Colab)\n",
    "\n",
    "mrf_recode = MERF(n_estimators=1500, max_iterations=100)\n",
    "mrf_recode.fit(X_train_vector, Z_train, clusters_train, y_train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "with open('./mrf_recode.pickle','wb') as file:\n",
    "    pickle.dump(mrf_recode,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.816421</td>\n",
       "      <td>1.072586</td>\n",
       "      <td>1.035657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.801740</td>\n",
       "      <td>1.091521</td>\n",
       "      <td>1.044759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.808950</td>\n",
       "      <td>1.082221</td>\n",
       "      <td>1.040299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.816421  1.072586  1.035657\n",
       "1    Known  0.801740  1.091521  1.044759\n",
       "2  Unified  0.808950  1.082221  1.040299"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_MERF(mrf_recode,\n",
    "              test_set_name = ['Unknown','Known', 'Unified'],\n",
    "              x_test = [X_new, X_known, X_unified],\n",
    "              y_test = [y_new, y_known, y_unified],\n",
    "              Z = [Z_new, Z_known, Z_unified],\n",
    "              clusters = [clusters_new, clusters_known, clusters_unified]              \n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.992435</td>\n",
       "      <td>1.545168</td>\n",
       "      <td>1.243048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.858198</td>\n",
       "      <td>1.254919</td>\n",
       "      <td>1.120232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.924127</td>\n",
       "      <td>1.397471</td>\n",
       "      <td>1.182147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.992435  1.545168  1.243048\n",
       "1    Known  0.858198  1.254919  1.120232\n",
       "2  Unified  0.924127  1.397471  1.182147"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lasso_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.778032</td>\n",
       "      <td>0.930356</td>\n",
       "      <td>0.964550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.795444</td>\n",
       "      <td>1.083959</td>\n",
       "      <td>1.041134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.786892</td>\n",
       "      <td>1.008519</td>\n",
       "      <td>1.004250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.778032  0.930356  0.964550\n",
       "1    Known  0.795444  1.083959  1.041134\n",
       "2  Unified  0.786892  1.008519  1.004250"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(rf_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.806480</td>\n",
       "      <td>1.045034</td>\n",
       "      <td>1.022269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.807230</td>\n",
       "      <td>1.109694</td>\n",
       "      <td>1.053420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.806862</td>\n",
       "      <td>1.077937</td>\n",
       "      <td>1.038237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.806480  1.045034  1.022269\n",
       "1    Known  0.807230  1.109694  1.053420\n",
       "2  Unified  0.806862  1.077937  1.038237"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_MERF(mrf, \n",
    "              test_set_name = ['Unknown','Known', 'Unified'],\n",
    "              x_test = [X_new, X_known, X_unified],\n",
    "              y_test = [y_new, y_known, y_unified],\n",
    "              Z = [Z_new, Z_known, Z_unified],\n",
    "              clusters = [clusters_new, clusters_known, clusters_unified]              \n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions (so far)\n",
    "\n",
    "- MERF is better than RF to predict known subjects. This result is coherent with how MERF works  and with the assumption that subjects behave in a cluster-like way.\n",
    "- Depending on the need of our client we should choose one model over the other. If we want to predict knew subjects a RF will be better, if we want to predict the emotion for known subjects then MERF is a possible option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Next steps:\n",
    "\n",
    "- Make a K-fold CV to compare RF and MERF before testing (Now is late for that, but would be good idea in the future).\n",
    "- Run a GridsearchCV tunning some hyperparameters (this is going to be costly, shoul run it in a CoLab notebook).\n",
    "- Create a new `y` variable. We could use negative mean and/or positive mean for the regression problem (maybe focus on negative)\n",
    "- We should re-check the answers for the survey (correlation between answers for the survey). We could use a PCA analysis in order to see how many 'groups' we have.\n",
    "- Plot the predictions against the real values to see if the model is losing the fit in one part of the continous data.\n",
    "- Talk to the Fitbit people about how to tackle a specific question (what is interesting to measure?).\n",
    "- Add the correlation data Mikella uploaded to BOX (maybe this is not correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> $\\frac{\\text{High Arousal Positive}_{s,i} + \\text{Low Arousal Positive}_{s,i} + \\text{Positive}_{s,i}}{3} - \\frac{\\text{High Arousal Negative}_{s,i} + \\text{Low Arousal Negative}_{s,i} + \\text{Negative}_{s,i}}{3}$ </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Valence_{s,i} - Median(Valence_s) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# More Analysis\n",
    "\n",
    "- SVM\n",
    "- Ridge Regression\n",
    "- Elastic Net\n",
    "- XG Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving my pcikles object to migrate to colab\n",
    "obj = ['X_train_scaled','y_train',\n",
    "       'X_known_test_scaled','y_test_know',\n",
    "       'X_unknown_test_scaled','y_test_unknow']\n",
    "for i in obj:\n",
    "    with open(f'./{i}.pickle','wb') as file:\n",
    "        pickle.dump(eval(i),file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def function for plotting\n",
    "def plot_res_vs_real(model):\n",
    "    '''\n",
    "    Func plot two graphs (one for every test DF).\n",
    "    Plots real values from target vs predicted values\n",
    "    '''\n",
    "    dfs = [(X_train_scaled,y_train,'Training set'),\n",
    "           (X_known_test_scaled,y_test_know,'Known subjects'),\n",
    "           (X_unknown_test_scaled, y_test_unknow, 'Unknown (new) subjects')]\n",
    "    fig, ax = plt.subplots(1, len(dfs), figsize=(10,5))\n",
    "\n",
    "    for n,df in enumerate(dfs):\n",
    "        p = model.predict(df[0])\n",
    "        ax[n].scatter(x = p, y = df[1])\n",
    "        ax[n].plot([0, 1], [0, 1], transform=ax[n].transAxes, color = 'k', linestyle = '--')\n",
    "        ax[n].set_xlim((-3,4.1))\n",
    "        ax[n].set_ylim((-3,4.1))\n",
    "        ax[n].set_xlabel('Predicted Values')\n",
    "        ax[n].set_ylabel('Real Values')\n",
    "        ax[n].set_title(df[2])\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use the `X_train_scaled` and `y_train` DF to train this and the next models. <br>\n",
    "Why? Because one-hot encoding this data do not have sense if we are going to focus our prediction on new subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_svm = svm.SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.812354</td>\n",
       "      <td>0.991679</td>\n",
       "      <td>0.995831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.857049</td>\n",
       "      <td>1.245982</td>\n",
       "      <td>1.116236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.835098</td>\n",
       "      <td>1.121084</td>\n",
       "      <td>1.058813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.812354  0.991679  0.995831\n",
       "1    Known  0.857049  1.245982  1.116236\n",
       "2  Unified  0.835098  1.121084  1.058813"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model_svm.fit(X_train_scaled,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   31.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 2, 5, 10],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets tune up the hyperparameters\n",
    "param_grid = {'C': [0.1, 1, 2,5, 10], 'gamma': [1,0.1,0.01, 0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(model_svm,param_grid, cv = kfold, verbose = True, n_jobs = -1, iid= False)\n",
    "grid.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.001,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.941617</td>\n",
       "      <td>1.363441</td>\n",
       "      <td>1.167665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.825473</td>\n",
       "      <td>1.177665</td>\n",
       "      <td>1.085203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.882516</td>\n",
       "      <td>1.268907</td>\n",
       "      <td>1.126458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.941617  1.363441  1.167665\n",
       "1    Known  0.825473  1.177665  1.085203\n",
       "2  Unified  0.882516  1.268907  1.126458"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm_optimized = grid.best_estimator_\n",
    "evaluate(model_svm_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Minutes Asleep</td>\n",
       "      <td>0.873915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>CR_10m</td>\n",
       "      <td>0.593989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>hr_std_3h</td>\n",
       "      <td>0.479114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>high_hr_5m</td>\n",
       "      <td>0.381849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>high_hr_30m</td>\n",
       "      <td>0.328033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>hr_0.5</td>\n",
       "      <td>0.308014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>hr_med</td>\n",
       "      <td>0.308014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>very_active_rate_30m</td>\n",
       "      <td>0.295548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>steps_median_10m</td>\n",
       "      <td>0.288973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>running_rate_3h</td>\n",
       "      <td>0.268736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature  Coefficients\n",
       "32         Minutes Asleep      0.873915\n",
       "156                CR_10m      0.593989\n",
       "117             hr_std_3h      0.479114\n",
       "168            high_hr_5m      0.381849\n",
       "140           high_hr_30m      0.328033\n",
       "180                hr_0.5      0.308014\n",
       "107                hr_med      0.308014\n",
       "85   very_active_rate_30m      0.295548\n",
       "91       steps_median_10m      0.288973\n",
       "68        running_rate_3h      0.268736"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "model_ridge = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv = kfold).fit(X_train_scaled,y_train)\n",
    "\n",
    "#Let's make a table with the different coefficients and residuals\n",
    "ridge_coef_df = pd.DataFrame(data = {'Feature' : cols_coef,\n",
    "                                     'Coefficients' : model_ridge.coef_})\n",
    "ridge_coef_df = ridge_coef_df.sort_values(by= 'Coefficients', ascending = False)\n",
    "ridge_coef_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Children</td>\n",
       "      <td>-0.292572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>low_hr_10m</td>\n",
       "      <td>-0.313782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>CR_30m</td>\n",
       "      <td>-0.320150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>steps_mean_10m</td>\n",
       "      <td>-0.327213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Neuroticism_scaled</td>\n",
       "      <td>-0.330698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>high_hr_10m</td>\n",
       "      <td>-0.337242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HAN_ideal</td>\n",
       "      <td>-0.380549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>CR_5m</td>\n",
       "      <td>-0.394162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>hr_0.3</td>\n",
       "      <td>-0.901161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Time in Bed</td>\n",
       "      <td>-0.917521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Coefficients\n",
       "17             Children     -0.292572\n",
       "153          low_hr_10m     -0.313782\n",
       "142              CR_30m     -0.320150\n",
       "89       steps_mean_10m     -0.327213\n",
       "28   Neuroticism_scaled     -0.330698\n",
       "154         high_hr_10m     -0.337242\n",
       "1             HAN_ideal     -0.380549\n",
       "170               CR_5m     -0.394162\n",
       "179              hr_0.3     -0.901161\n",
       "35          Time in Bed     -0.917521"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_coef_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.306370</td>\n",
       "      <td>2.759469</td>\n",
       "      <td>1.661165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.876757</td>\n",
       "      <td>1.288227</td>\n",
       "      <td>1.135001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>1.087757</td>\n",
       "      <td>2.010812</td>\n",
       "      <td>1.418031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  1.306370  2.759469  1.661165\n",
       "1    Known  0.876757  1.288227  1.135001\n",
       "2  Unified  1.087757  2.010812  1.418031"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayrsina Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10000 candidates, totalling 50000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1688 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3088 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4888 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 7088 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9688 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 12688 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 16088 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 19888 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 24088 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 28688 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 33688 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 39088 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 44888 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 50000 out of 50000 | elapsed: 10.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=BayesianRidge(alpha_1=1e-06, alpha_2=1e-06,\n",
       "                                     compute_score=False, copy_X=True,\n",
       "                                     fit_intercept=True, lambda_1=1e-06,\n",
       "                                     lambda_2=1e-06, n_iter=300,\n",
       "                                     normalize=False, tol=0.001,\n",
       "                                     verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'alpha_1': array([1.00000000e-13, 7.7426...\n",
       "                         'lambda_1': array([1.00000000e-10, 3.59381366e-10, 1.29154967e-09, 4.64158883e-09,\n",
       "       1.66810054e-08, 5.99484250e-08, 2.15443469e-07, 7.74263683e-07,\n",
       "       2.78255940e-06, 1.00000000e-05]),\n",
       "                         'lambda_2': array([1.00000000e-11, 5.99484250e-11, 3.59381366e-10, 2.15443469e-09,\n",
       "       1.29154967e-08, 7.74263683e-08, 4.64158883e-07, 2.78255940e-06,\n",
       "       1.66810054e-05, 1.00000000e-04])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "model_bayesian_ridge = BayesianRidge()\n",
    "param_grid = {\"alpha_1\": np.logspace(-13,-5,10),\"alpha_2\": np.logspace(-9,-3,10), \"lambda_1\": np.logspace(-10,-5,10),\"lambda_2\": np.logspace(-11,-4,10)}\n",
    "grid = GridSearchCV(model_bayesian_ridge, param_grid, cv = kfold, verbose = True, n_jobs = -1, iid=False)\n",
    "grid.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianRidge(alpha_1=1e-05, alpha_2=1e-09, compute_score=False, copy_X=True,\n",
      "              fit_intercept=True, lambda_1=1e-10, lambda_2=0.0001, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bayesian_ridge = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.890513</td>\n",
       "      <td>1.203007</td>\n",
       "      <td>1.096817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.877696</td>\n",
       "      <td>1.285765</td>\n",
       "      <td>1.133916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.883991</td>\n",
       "      <td>1.245119</td>\n",
       "      <td>1.115849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.890513  1.203007  1.096817\n",
       "1    Known  0.877696  1.285765  1.133916\n",
       "2  Unified  0.883991  1.245119  1.115849"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model_bayesian_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>LAP_actual</td>\n",
       "      <td>0.141626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HAP_actual</td>\n",
       "      <td>0.113888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>HA_ideal</td>\n",
       "      <td>0.086076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>hr_min</td>\n",
       "      <td>0.076782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>hr_0</td>\n",
       "      <td>0.076782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>LA_actual</td>\n",
       "      <td>0.072915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HA_actual</td>\n",
       "      <td>0.072411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Ethnicity_Black</td>\n",
       "      <td>0.069081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>P_actual</td>\n",
       "      <td>0.063073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Ethnicity_White</td>\n",
       "      <td>0.056180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Coefficients\n",
       "8         LAP_actual      0.141626\n",
       "2         HAP_actual      0.113888\n",
       "5           HA_ideal      0.086076\n",
       "106           hr_min      0.076782\n",
       "178             hr_0      0.076782\n",
       "10         LA_actual      0.072915\n",
       "4          HA_actual      0.072411\n",
       "40   Ethnicity_Black      0.069081\n",
       "14          P_actual      0.063073\n",
       "46   Ethnicity_White      0.056180"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge_coef_df = pd.DataFrame(data = {'Feature' : cols_coef,\n",
    "                                     'Coefficients' : model_bayesian_ridge.coef_})\n",
    "bayesian_ridge_coef_df = bayesian_ridge_coef_df.sort_values(by= 'Coefficients', ascending = False)\n",
    "bayesian_ridge_coef_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>pHR2_30m</td>\n",
       "      <td>-0.049250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Ethnicity_Hispanic</td>\n",
       "      <td>-0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Ethnicity_Asian</td>\n",
       "      <td>-0.066073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>hr_0.3</td>\n",
       "      <td>-0.085796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Conscientiousness_scaled</td>\n",
       "      <td>-0.091955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Children</td>\n",
       "      <td>-0.099598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HAN_ideal</td>\n",
       "      <td>-0.104492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>LAN_actual</td>\n",
       "      <td>-0.114409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Ethnicity_Hispanic/Other</td>\n",
       "      <td>-0.124660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Neuroticism_scaled</td>\n",
       "      <td>-0.125358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  Coefficients\n",
       "137                  pHR2_30m     -0.049250\n",
       "41         Ethnicity_Hispanic     -0.053700\n",
       "38            Ethnicity_Asian     -0.066073\n",
       "179                    hr_0.3     -0.085796\n",
       "26   Conscientiousness_scaled     -0.091955\n",
       "17                   Children     -0.099598\n",
       "1                   HAN_ideal     -0.104492\n",
       "6                  LAN_actual     -0.114409\n",
       "43   Ethnicity_Hispanic/Other     -0.124660\n",
       "28         Neuroticism_scaled     -0.125358"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_ridge_coef_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    8.1s finished\n",
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6761525856925346, tolerance: 0.22903742978490205\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=None, selection='cyclic',\n",
       "                                  tol=0.0001, warm_start=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9],\n",
       "                         'max_iter': [50, 100, 300, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model_elastic = ElasticNet()\n",
    "param_grid = {'l1_ratio':[.1, .5, .7, .9],\n",
    "              \"max_iter\": [1, 5, 10],\n",
    "              \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "             'max_iter' : [50,100,300,1000]}\n",
    "grid = GridSearchCV(model_elastic,param_grid, cv = kfold, verbose = True, n_jobs = -1, iid= False)\n",
    "grid.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True, l1_ratio=0.9,\n",
      "           max_iter=50, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elastic = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make a table with the different coefficients and residuals\n",
    "elastic_coef_df = pd.DataFrame(data = {'Feature' : cols_coef,\n",
    "                                     'Coefficients' : model_elastic.coef_})\n",
    "elastic_coef_df = elastic_coef_df.sort_values(by= 'Coefficients', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>hr_min</td>\n",
       "      <td>0.231010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>LAP_actual</td>\n",
       "      <td>0.204616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HAP_actual</td>\n",
       "      <td>0.130259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HA_actual</td>\n",
       "      <td>0.125937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>LA_actual</td>\n",
       "      <td>0.108951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>BIS.5</td>\n",
       "      <td>0.084705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>HA_ideal</td>\n",
       "      <td>0.078213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>BAS_FS</td>\n",
       "      <td>0.077430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Household_income</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>hr_rest_rate_1h</td>\n",
       "      <td>0.044051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Coefficients\n",
       "106            hr_min      0.231010\n",
       "8          LAP_actual      0.204616\n",
       "2          HAP_actual      0.130259\n",
       "4           HA_actual      0.125937\n",
       "10          LA_actual      0.108951\n",
       "23              BIS.5      0.084705\n",
       "5            HA_ideal      0.078213\n",
       "21             BAS_FS      0.077430\n",
       "18   Household_income      0.065563\n",
       "133   hr_rest_rate_1h      0.044051"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_coef_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Minutes Awake</td>\n",
       "      <td>-0.063529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HAP_ideal</td>\n",
       "      <td>-0.070529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>Marital_Status_Single</td>\n",
       "      <td>-0.095723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>LAN_actual</td>\n",
       "      <td>-0.122435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Conscientiousness_scaled</td>\n",
       "      <td>-0.137671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Ethnicity_Hispanic/Other</td>\n",
       "      <td>-0.151984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Children</td>\n",
       "      <td>-0.172326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>hr_0.3</td>\n",
       "      <td>-0.199967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Neuroticism_scaled</td>\n",
       "      <td>-0.203762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HAN_ideal</td>\n",
       "      <td>-0.228725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  Coefficients\n",
       "33              Minutes Awake     -0.063529\n",
       "3                   HAP_ideal     -0.070529\n",
       "52      Marital_Status_Single     -0.095723\n",
       "6                  LAN_actual     -0.122435\n",
       "26   Conscientiousness_scaled     -0.137671\n",
       "43   Ethnicity_Hispanic/Other     -0.151984\n",
       "17                   Children     -0.172326\n",
       "179                    hr_0.3     -0.199967\n",
       "28         Neuroticism_scaled     -0.203762\n",
       "1                   HAN_ideal     -0.228725"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_coef_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.003461</td>\n",
       "      <td>1.584334</td>\n",
       "      <td>1.258703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.858143</td>\n",
       "      <td>1.252715</td>\n",
       "      <td>1.119248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.929514</td>\n",
       "      <td>1.415586</td>\n",
       "      <td>1.189784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  1.003461  1.584334  1.258703\n",
       "1    Known  0.858143  1.252715  1.119248\n",
       "2  Unified  0.929514  1.415586  1.189784"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model_elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XG Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model_xgb = XGBRegressor()\n",
    "parameters = {\n",
    "    'max_depth': [2,3,5,10],\n",
    "    'n_estimators' : [25, 50,100,200],\n",
    "    'learning_rate' : [0.01,0.1,0.3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=7, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bytree=1,\n",
       "                                    gamma=0, learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=3,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:linear', random_state=0,\n",
       "                                    reg_alpha=0, reg_lambda=1,\n",
       "                                    scale_pos_weight=1, seed=None, silent=True,\n",
       "                                    subsample=1),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.3],\n",
       "                         'max_depth': [2, 3, 5, 10],\n",
       "                         'n_estimators': [25, 50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(model_xgb, parameters, cv = kfold, verbose = True, n_jobs = -1, iid= False)\n",
    "grid.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=5, min_child_weight=1, missing=None, n_estimators=50,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=True, subsample=1)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb_optimized = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.760535</td>\n",
       "      <td>0.925508</td>\n",
       "      <td>0.962034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.845198</td>\n",
       "      <td>1.189837</td>\n",
       "      <td>1.090797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.803616</td>\n",
       "      <td>1.060015</td>\n",
       "      <td>1.029570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.760535  0.925508  0.962034\n",
       "1    Known  0.845198  1.189837  1.090797\n",
       "2  Unified  0.803616  1.060015  1.029570"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classic XGB model\n",
    "evaluate(model_xgb.fit(X_train_scaled,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.856406</td>\n",
       "      <td>1.232564</td>\n",
       "      <td>1.110209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>0.828246</td>\n",
       "      <td>1.137742</td>\n",
       "      <td>1.066650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Unified</td>\n",
       "      <td>0.842077</td>\n",
       "      <td>1.184313</td>\n",
       "      <td>1.088261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test set       MAE       MSE      RMSE\n",
       "0  Unknown  0.856406  1.232564  1.110209\n",
       "1    Known  0.828246  1.137742  1.066650\n",
       "2  Unified  0.842077  1.184313  1.088261"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimized\n",
    "evaluate(model_xgb_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_res_vs_real(model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_res_vs_real(model_svm_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_res_vs_real(rf_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_res_vs_real(model_bayesian_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "XG Boosting, Random Forest, MERF, SVM and Bayes Ridge seems to be the best to predict `Unknown` data. \n",
    "\n",
    "Nevertheless, the performance is not good.\n",
    "We should train with a fully Nested CV on the new data (adding features and comapring with the average response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Converting predicted values into binary states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,confusion_matrix,\\\n",
    "                            roc_auc_score, roc_curve,precision_recall_curve,precision_score,\\\n",
    "                            recall_score, accuracy_score, f1_score\n",
    "\n",
    "def to_category (series_original):\n",
    "    '''\n",
    "    Transform the predicted value into a binary class\n",
    "    1 = sad\n",
    "    0 = happy\n",
    "    '''\n",
    "    series = series_original.copy()\n",
    "    series[series_original >= 0] = 0 #happy is  0\n",
    "    series[series_original < 0] = 1  #sad is 1\n",
    "    return series\n",
    "\n",
    "def conf_mat_rate(predict, real):\n",
    "    '''\n",
    "    Nice conf matrix\n",
    "    '''\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(predict, real).ravel()\n",
    "    conf = pd.DataFrame(index= ['+','-', 'Total real'], columns= ['POS' , 'NEG'] , data = np.array([[tp,fn],[fp,tn],[1,1]]))\n",
    "    conf.insert(2, 'Total predicted', np.array([tp+fn,fp+tn,0]))\n",
    "    conf.iloc[0,0:2] = conf.iloc[0,0:2]/conf.iloc[0,2] # I calculate the rates\n",
    "    conf.iloc[1,0:2] = conf.iloc[1,0:2]/conf.iloc[1,2]\n",
    "    conf.iloc[2,:] = np.array([tp+fp,fn+tn,tp+fn+fp+tn]).astype(str) # I calculate the total real observations\n",
    "    conf.iloc[2,:] = conf.iloc[2,:].astype(int) #formatting to integer\n",
    "    return conf\n",
    "\n",
    "def binary_class(model, dfs = None):\n",
    "    '''\n",
    "    Generate several metrics\n",
    "    dfs : list of tuples. (X,y,name of DF)\n",
    "    '''\n",
    "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve,precision_recall_curve,precision_score, recall_score, accuracy_score, f1_score\n",
    "    \n",
    "    #in this case I am testing with several DF only to check. In the final stage I would like to do a NestedCV\n",
    "    if dfs is None:\n",
    "        dfs = [(X_train_scaled,y_train,'Training set'),\n",
    "           (X_known_test_scaled,y_test_know,'Known subjects'),\n",
    "           (X_unknown_test_scaled, y_test_unknow, 'Unknown (new) subjects')]\n",
    "    all_values = {}\n",
    "    for df in dfs:\n",
    "        #df[0] -> X\n",
    "        #df[1] -> y\n",
    "        pred = to_category(model.predict(df[0]))\n",
    "        real = to_category(df[1])\n",
    "        cf = confusion_matrix(pred,real)\n",
    "        cf_rate = conf_mat_rate(pred,real)\n",
    "        \n",
    "        metrics = {} #metric dictionary\n",
    "        metrics_names = ['recall','precision','accuracy','f1']\n",
    "        recall = recall_score(pred,real) #sensitivity\n",
    "        precision = precision_score(pred,real)\n",
    "        accuracy = accuracy_score(pred,real)\n",
    "        f1 = f1_score(pred,real)\n",
    "        for m in metrics_names:\n",
    "            metrics[m] = eval(m)\n",
    "        #append all\n",
    "        all_values[df[2]] = [cf , cf_rate, metrics]\n",
    "    return all_values\n",
    "\n",
    "def metric_table (all_values, name_df, model_name):\n",
    "    metric_df = pd.DataFrame(all_values[name_df][2], index=[model_name])\n",
    "    return metric_df\n",
    "\n",
    "def all_models_scores (models , models_names, name_df):\n",
    "    '''\n",
    "    one table per test df\n",
    "    models : list\n",
    "    models_name : list\n",
    "    name_df : string\n",
    "    '''\n",
    "    metrics_names = ['recall','precision','accuracy','f1']\n",
    "    df = pd.DataFrame(index = models_names, columns= metrics_names)\n",
    "    \n",
    "    for mod,name in zip(models, models_names):\n",
    "        all_vals = binary_class(mod)\n",
    "        df.loc[name,:] = metric_table(all_vals, name_df, model_name=name).values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown (new) subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>model_svm_optimized</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0909091</td>\n",
       "      <td>0.912371</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>model_xgb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_optimized</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>model_bayesian_ridge</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     recall  precision  accuracy        f1\n",
       "model_svm_optimized   0.125  0.0909091  0.912371  0.105263\n",
       "model_xgb                 0          0  0.943299         0\n",
       "rf_optimized              0          0  0.943299         0\n",
       "model_bayesian_ridge      0          0   0.93299         0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_scores(models=[model_svm_optimized, model_xgb, rf_optimized, model_bayesian_ridge],\n",
    "                  models_names=['model_svm_optimized','model_xgb','rf_optimized','model_bayesian_ridge'],\n",
    "                  name_df= 'Unknown (new) subjects'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Known subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\joaqu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>model_svm_optimized</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>model_xgb</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_optimized</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>model_bayesian_ridge</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        recall precision  accuracy        f1\n",
       "model_svm_optimized          1       0.1  0.865672  0.181818\n",
       "model_xgb                  0.8  0.133333  0.865672  0.228571\n",
       "rf_optimized          0.857143       0.2  0.875622  0.324324\n",
       "model_bayesian_ridge         1       0.1  0.865672  0.181818"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_scores(models=[model_svm_optimized, model_xgb, rf_optimized, model_bayesian_ridge],\n",
    "                  models_names=['model_svm_optimized','model_xgb','rf_optimized','model_bayesian_ridge'],\n",
    "                  name_df= 'Known subjects'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we can see that the `Unknown` test DF is not very good. It has only 11 negative cases over 194 (a ratio of 0.056) so, only 5.6 % of cases are sad. \n",
    "\n",
    "We should move to a CV by subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to rebuild my DF in order to cross validate leaving subjects out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DF_complete_nona.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['la_p',\t'ha_p',\t'ha_n',\t'la_n',\t'la',\t'p',\t'n',\t'ha',\n",
    "              'start_survey','survey_no','experiment', 'VALENCE', 'Date_only_date', 'Subject', 'Date', \n",
    "             'start_survey_30m_ahead', 'start_survey_1h_ahead',\t'start_survey_3h_ahead', 'start_survey_5m_ahead', 'start_survey_10m_ahead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns =cols_drop, inplace= True)\n",
    "X.reset_index(inplace= True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>VALENCE_mean</th>\n",
       "      <th>HAN_actual</th>\n",
       "      <th>HAN_ideal</th>\n",
       "      <th>HAP_actual</th>\n",
       "      <th>HAP_ideal</th>\n",
       "      <th>HA_actual</th>\n",
       "      <th>HA_ideal</th>\n",
       "      <th>LAN_actual</th>\n",
       "      <th>LAN_ideal</th>\n",
       "      <th>LAP_actual</th>\n",
       "      <th>LAP_ideal</th>\n",
       "      <th>LA_actual</th>\n",
       "      <th>LA_ideal</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>N_ideal</th>\n",
       "      <th>P_actual</th>\n",
       "      <th>P_ideal</th>\n",
       "      <th>Age</th>\n",
       "      <th>Children</th>\n",
       "      <th>Household_income</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BAS_D</th>\n",
       "      <th>BAS_FS</th>\n",
       "      <th>BAS_RR</th>\n",
       "      <th>BIS.5</th>\n",
       "      <th>BIS_total</th>\n",
       "      <th>NS_total</th>\n",
       "      <th>Conscientiousness_scaled</th>\n",
       "      <th>Extraversion_scaled</th>\n",
       "      <th>Neuroticism_scaled</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>FTP</th>\n",
       "      <th>SBQ</th>\n",
       "      <th>Minutes Asleep</th>\n",
       "      <th>Minutes Awake</th>\n",
       "      <th>Number of Awakenings</th>\n",
       "      <th>Time in Bed</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Biracial</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Hispanic</th>\n",
       "      <th>Ethnicity_Hispanic/Caucasian</th>\n",
       "      <th>Ethnicity_Hispanic/Other</th>\n",
       "      <th>Ethnicity_More than 1 race</th>\n",
       "      <th>Ethnicity_Native Hawaiian/Pacific Islander</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "      <th>Ethnicity_White/Pacific Islander</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Engaged</th>\n",
       "      <th>Marital_Status_Living with partner</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Widowed</th>\n",
       "      <th>Period_of_day_Evening</th>\n",
       "      <th>Period_of_day_Morning</th>\n",
       "      <th>Period_of_day_Night</th>\n",
       "      <th>step_max</th>\n",
       "      <th>step_min</th>\n",
       "      <th>step_median</th>\n",
       "      <th>steps_max_3h</th>\n",
       "      <th>steps_min_3h</th>\n",
       "      <th>steps_mean_3h</th>\n",
       "      <th>steps_var_3h</th>\n",
       "      <th>steps_median_3h</th>\n",
       "      <th>move_rate_3h</th>\n",
       "      <th>active_rate_3h</th>\n",
       "      <th>very_active_rate_3h</th>\n",
       "      <th>running_rate_3h</th>\n",
       "      <th>steps_max_1h</th>\n",
       "      <th>steps_min_1h</th>\n",
       "      <th>steps_mean_1h</th>\n",
       "      <th>steps_var_1h</th>\n",
       "      <th>steps_median_1h</th>\n",
       "      <th>move_rate_1h</th>\n",
       "      <th>active_rate_1h</th>\n",
       "      <th>very_active_rate_1h</th>\n",
       "      <th>running_rate_1h</th>\n",
       "      <th>steps_max_30m</th>\n",
       "      <th>steps_min_30m</th>\n",
       "      <th>steps_mean_30m</th>\n",
       "      <th>steps_var_30m</th>\n",
       "      <th>steps_median_30m</th>\n",
       "      <th>move_rate_30m</th>\n",
       "      <th>active_rate_30m</th>\n",
       "      <th>very_active_rate_30m</th>\n",
       "      <th>running_rate_30m</th>\n",
       "      <th>steps_max_10m</th>\n",
       "      <th>steps_min_10m</th>\n",
       "      <th>steps_mean_10m</th>\n",
       "      <th>steps_var_10m</th>\n",
       "      <th>steps_median_10m</th>\n",
       "      <th>move_rate_10m</th>\n",
       "      <th>active_rate_10m</th>\n",
       "      <th>very_active_rate_10m</th>\n",
       "      <th>running_rate_10m</th>\n",
       "      <th>steps_max_5m</th>\n",
       "      <th>steps_min_5m</th>\n",
       "      <th>steps_mean_5m</th>\n",
       "      <th>steps_var_5m</th>\n",
       "      <th>steps_median_5m</th>\n",
       "      <th>move_rate_5m</th>\n",
       "      <th>active_rate_5m</th>\n",
       "      <th>very_active_rate_5m</th>\n",
       "      <th>running_rate_5m</th>\n",
       "      <th>hr_max</th>\n",
       "      <th>hr_min</th>\n",
       "      <th>hr_med</th>\n",
       "      <th>SDNN_3h</th>\n",
       "      <th>pHR2_3h</th>\n",
       "      <th>rMSSD_3h</th>\n",
       "      <th>low_hr_3h</th>\n",
       "      <th>high_hr_3h</th>\n",
       "      <th>l_h_3h</th>\n",
       "      <th>CR_3h</th>\n",
       "      <th>hr_mean_3h</th>\n",
       "      <th>hr_var_3h</th>\n",
       "      <th>hr_std_3h</th>\n",
       "      <th>hr_median_3h</th>\n",
       "      <th>hr_rest_rate_3h</th>\n",
       "      <th>hr_moderate_rate_3h</th>\n",
       "      <th>hr_very_active_rate_3h</th>\n",
       "      <th>SDNN_1h</th>\n",
       "      <th>pHR2_1h</th>\n",
       "      <th>rMSSD_1h</th>\n",
       "      <th>low_hr_1h</th>\n",
       "      <th>high_hr_1h</th>\n",
       "      <th>l_h_1h</th>\n",
       "      <th>CR_1h</th>\n",
       "      <th>hr_mean_1h</th>\n",
       "      <th>hr_var_1h</th>\n",
       "      <th>hr_std_1h</th>\n",
       "      <th>hr_median_1h</th>\n",
       "      <th>hr_rest_rate_1h</th>\n",
       "      <th>hr_moderate_rate_1h</th>\n",
       "      <th>hr_very_active_rate_1h</th>\n",
       "      <th>SDNN_30m</th>\n",
       "      <th>pHR2_30m</th>\n",
       "      <th>rMSSD_30m</th>\n",
       "      <th>low_hr_30m</th>\n",
       "      <th>high_hr_30m</th>\n",
       "      <th>l_h_30m</th>\n",
       "      <th>CR_30m</th>\n",
       "      <th>hr_mean_30m</th>\n",
       "      <th>hr_var_30m</th>\n",
       "      <th>hr_std_30m</th>\n",
       "      <th>hr_median_30m</th>\n",
       "      <th>hr_rest_rate_30m</th>\n",
       "      <th>hr_moderate_rate_30m</th>\n",
       "      <th>hr_very_active_rate_30m</th>\n",
       "      <th>SDNN_10m</th>\n",
       "      <th>pHR2_10m</th>\n",
       "      <th>rMSSD_10m</th>\n",
       "      <th>low_hr_10m</th>\n",
       "      <th>high_hr_10m</th>\n",
       "      <th>l_h_10m</th>\n",
       "      <th>CR_10m</th>\n",
       "      <th>hr_mean_10m</th>\n",
       "      <th>hr_var_10m</th>\n",
       "      <th>hr_std_10m</th>\n",
       "      <th>hr_median_10m</th>\n",
       "      <th>hr_rest_rate_10m</th>\n",
       "      <th>hr_moderate_rate_10m</th>\n",
       "      <th>hr_very_active_rate_10m</th>\n",
       "      <th>SDNN_5m</th>\n",
       "      <th>pHR2_5m</th>\n",
       "      <th>rMSSD_5m</th>\n",
       "      <th>low_hr_5m</th>\n",
       "      <th>high_hr_5m</th>\n",
       "      <th>l_h_5m</th>\n",
       "      <th>CR_5m</th>\n",
       "      <th>hr_mean_5m</th>\n",
       "      <th>hr_var_5m</th>\n",
       "      <th>hr_std_5m</th>\n",
       "      <th>hr_median_5m</th>\n",
       "      <th>hr_rest_rate_5m</th>\n",
       "      <th>hr_moderate_rate_5m</th>\n",
       "      <th>hr_very_active_rate_5m</th>\n",
       "      <th>hr_0</th>\n",
       "      <th>hr_0.3</th>\n",
       "      <th>hr_0.5</th>\n",
       "      <th>hr_0.8</th>\n",
       "      <th>hr_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.311111</td>\n",
       "      <td>209.813284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.216667</td>\n",
       "      <td>133.325141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>260.947126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>726.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1251.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>127.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.151828</td>\n",
       "      <td>2.057286</td>\n",
       "      <td>63.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>79.605805</td>\n",
       "      <td>107.223097</td>\n",
       "      <td>10.354859</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.555243</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>1.950937</td>\n",
       "      <td>64.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>76.411043</td>\n",
       "      <td>31.498216</td>\n",
       "      <td>5.612327</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.690184</td>\n",
       "      <td>0.070552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.140244</td>\n",
       "      <td>1.844570</td>\n",
       "      <td>69.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>78.654545</td>\n",
       "      <td>37.800665</td>\n",
       "      <td>6.148225</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.539394</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>1.978700</td>\n",
       "      <td>71.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>81.916667</td>\n",
       "      <td>61.806497</td>\n",
       "      <td>7.861711</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.968502</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>85.757576</td>\n",
       "      <td>68.189394</td>\n",
       "      <td>8.257687</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.205556</td>\n",
       "      <td>60.074829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>17.922034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>30.648276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>77.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.164480</td>\n",
       "      <td>3.189919</td>\n",
       "      <td>42.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>58.940524</td>\n",
       "      <td>93.349638</td>\n",
       "      <td>9.661762</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.553427</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>2.899143</td>\n",
       "      <td>44.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>59.724234</td>\n",
       "      <td>113.496366</td>\n",
       "      <td>10.653467</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.604457</td>\n",
       "      <td>0.200557</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.251811</td>\n",
       "      <td>50.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>60.913514</td>\n",
       "      <td>150.818566</td>\n",
       "      <td>12.280821</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>3.180557</td>\n",
       "      <td>50.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>66.628571</td>\n",
       "      <td>325.019462</td>\n",
       "      <td>18.028296</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.456693</td>\n",
       "      <td>53.034483</td>\n",
       "      <td>3.463054</td>\n",
       "      <td>1.860928</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.950000</td>\n",
       "      <td>417.265642</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.566667</td>\n",
       "      <td>434.148023</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>484.533333</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>742.622222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1029.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>127.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.168531</td>\n",
       "      <td>2.259787</td>\n",
       "      <td>58.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>84.674367</td>\n",
       "      <td>148.673153</td>\n",
       "      <td>12.193160</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.346498</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>2.271544</td>\n",
       "      <td>58.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.487395</td>\n",
       "      <td>0.937008</td>\n",
       "      <td>89.058427</td>\n",
       "      <td>183.032615</td>\n",
       "      <td>13.528955</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.925843</td>\n",
       "      <td>0.476404</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>2.237032</td>\n",
       "      <td>66.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>88.798283</td>\n",
       "      <td>154.722066</td>\n",
       "      <td>12.438732</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.446352</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.455153</td>\n",
       "      <td>66.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>77.589041</td>\n",
       "      <td>38.745434</td>\n",
       "      <td>6.224583</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>2.037527</td>\n",
       "      <td>66.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>76.852941</td>\n",
       "      <td>51.947415</td>\n",
       "      <td>7.207456</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>42.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>124.613128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>193.648305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.125108</td>\n",
       "      <td>2.243964</td>\n",
       "      <td>43.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.387387</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>73.071552</td>\n",
       "      <td>166.872357</td>\n",
       "      <td>12.917908</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.709483</td>\n",
       "      <td>0.141379</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.077694</td>\n",
       "      <td>1.869824</td>\n",
       "      <td>57.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>72.535000</td>\n",
       "      <td>40.655414</td>\n",
       "      <td>6.376160</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.046422</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>71.228856</td>\n",
       "      <td>10.887363</td>\n",
       "      <td>3.299600</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1.201850</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>72.178082</td>\n",
       "      <td>10.870624</td>\n",
       "      <td>3.297063</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>69.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>8.648649</td>\n",
       "      <td>2.940858</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.328927</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.577778</td>\n",
       "      <td>496.803973</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>535.345763</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>61.610345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.170872</td>\n",
       "      <td>2.072757</td>\n",
       "      <td>65.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>98.662824</td>\n",
       "      <td>119.034032</td>\n",
       "      <td>10.910272</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.115566</td>\n",
       "      <td>1.631789</td>\n",
       "      <td>77.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.877863</td>\n",
       "      <td>95.423529</td>\n",
       "      <td>119.768313</td>\n",
       "      <td>10.943871</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628235</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>1.242368</td>\n",
       "      <td>77.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>85.583784</td>\n",
       "      <td>77.168214</td>\n",
       "      <td>8.784544</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194595</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820413</td>\n",
       "      <td>79.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.648855</td>\n",
       "      <td>81.320755</td>\n",
       "      <td>2.914369</td>\n",
       "      <td>1.707152</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721110</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.641221</td>\n",
       "      <td>81.846154</td>\n",
       "      <td>2.935385</td>\n",
       "      <td>1.713296</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012</td>\n",
       "      <td>DND119</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.073858</td>\n",
       "      <td>1.467497</td>\n",
       "      <td>57.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>64.677670</td>\n",
       "      <td>16.741483</td>\n",
       "      <td>4.091636</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.988350</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>1.298748</td>\n",
       "      <td>59.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>66.972973</td>\n",
       "      <td>8.863725</td>\n",
       "      <td>2.977201</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731768</td>\n",
       "      <td>65.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>68.923077</td>\n",
       "      <td>2.794045</td>\n",
       "      <td>1.671540</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>69.808511</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>1.312785</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417029</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>70.625000</td>\n",
       "      <td>0.331522</td>\n",
       "      <td>0.575779</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013</td>\n",
       "      <td>DND119</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>71.199876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.103670</td>\n",
       "      <td>1.745243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>83.830431</td>\n",
       "      <td>65.251036</td>\n",
       "      <td>8.077811</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.199817</td>\n",
       "      <td>0.435380</td>\n",
       "      <td>0.209899</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.087209</td>\n",
       "      <td>1.422412</td>\n",
       "      <td>73.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>78.936232</td>\n",
       "      <td>4.623829</td>\n",
       "      <td>2.150309</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.414493</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.092486</td>\n",
       "      <td>1.476208</td>\n",
       "      <td>73.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>77.632184</td>\n",
       "      <td>3.043120</td>\n",
       "      <td>1.744454</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>1.197482</td>\n",
       "      <td>73.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>76.907407</td>\n",
       "      <td>3.444095</td>\n",
       "      <td>1.855827</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1.143544</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>76.037037</td>\n",
       "      <td>2.729345</td>\n",
       "      <td>1.652073</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014</td>\n",
       "      <td>DND119</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>27.786592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.092144</td>\n",
       "      <td>1.545934</td>\n",
       "      <td>69.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>78.250969</td>\n",
       "      <td>16.554800</td>\n",
       "      <td>4.068759</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.123062</td>\n",
       "      <td>0.037791</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.104615</td>\n",
       "      <td>1.705196</td>\n",
       "      <td>72.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>76.671779</td>\n",
       "      <td>4.350401</td>\n",
       "      <td>2.085762</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>1.365791</td>\n",
       "      <td>72.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>75.764331</td>\n",
       "      <td>3.540258</td>\n",
       "      <td>1.881557</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1.174734</td>\n",
       "      <td>72.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>74.843137</td>\n",
       "      <td>2.134902</td>\n",
       "      <td>1.461130</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>74.269231</td>\n",
       "      <td>1.564615</td>\n",
       "      <td>1.250846</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>DND119</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.490909</td>\n",
       "      <td>29.739246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>71.399718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>78.350575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>33.955556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.122177</td>\n",
       "      <td>1.808604</td>\n",
       "      <td>63.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>75.685128</td>\n",
       "      <td>55.708762</td>\n",
       "      <td>7.463830</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.749744</td>\n",
       "      <td>0.130256</td>\n",
       "      <td>0.069744</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.108808</td>\n",
       "      <td>1.821006</td>\n",
       "      <td>67.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>79.976744</td>\n",
       "      <td>78.255934</td>\n",
       "      <td>8.846238</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.563307</td>\n",
       "      <td>0.260982</td>\n",
       "      <td>0.175711</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>1.647064</td>\n",
       "      <td>67.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>78.326531</td>\n",
       "      <td>15.533857</td>\n",
       "      <td>3.941301</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1.207122</td>\n",
       "      <td>72.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>79.394366</td>\n",
       "      <td>6.670825</td>\n",
       "      <td>2.582794</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1.196843</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>80.842105</td>\n",
       "      <td>3.704125</td>\n",
       "      <td>1.924610</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>DND119</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.377778</td>\n",
       "      <td>251.621850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.128472</td>\n",
       "      <td>2.270738</td>\n",
       "      <td>62.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>90.870772</td>\n",
       "      <td>176.829640</td>\n",
       "      <td>13.297731</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.205551</td>\n",
       "      <td>0.761492</td>\n",
       "      <td>0.504770</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.067055</td>\n",
       "      <td>2.100257</td>\n",
       "      <td>62.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.613861</td>\n",
       "      <td>0.510101</td>\n",
       "      <td>88.598837</td>\n",
       "      <td>21.961048</td>\n",
       "      <td>4.686262</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.956395</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>1.030218</td>\n",
       "      <td>84.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>88.384146</td>\n",
       "      <td>5.587723</td>\n",
       "      <td>2.363836</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>86.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>88.061224</td>\n",
       "      <td>3.058673</td>\n",
       "      <td>1.748906</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807573</td>\n",
       "      <td>86.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>2.840580</td>\n",
       "      <td>1.685402</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  VALENCE_mean  HAN_actual  HAN_ideal  HAP_actual  HAP_ideal  \\\n",
       "0       1047      2.666667    1.333333        1.0         2.6        2.8   \n",
       "1       1047      1.000000    1.333333        1.0         2.6        2.8   \n",
       "2       1047      1.666667    1.333333        1.0         2.6        2.8   \n",
       "3       1047      1.000000    1.333333        1.0         2.6        2.8   \n",
       "4       1047      2.333333    1.333333        1.0         2.6        2.8   \n",
       "...      ...           ...         ...        ...         ...        ...   \n",
       "2012  DND119      1.666667    1.000000        1.0         2.4        3.0   \n",
       "2013  DND119      2.666667    1.000000        1.0         2.4        3.0   \n",
       "2014  DND119      2.333333    1.000000        1.0         2.4        3.0   \n",
       "2015  DND119      2.333333    1.000000        1.0         2.4        3.0   \n",
       "2016  DND119      1.666667    1.000000        1.0         2.4        3.0   \n",
       "\n",
       "      HA_actual  HA_ideal  LAN_actual  LAN_ideal  LAP_actual  LAP_ideal  \\\n",
       "0      2.000000  2.333333    1.666667   1.000000         3.6        4.2   \n",
       "1      2.000000  2.333333    1.666667   1.000000         3.6        4.2   \n",
       "2      2.000000  2.333333    1.666667   1.000000         3.6        4.2   \n",
       "3      2.000000  2.333333    1.666667   1.000000         3.6        4.2   \n",
       "4      2.000000  2.333333    1.666667   1.000000         3.6        4.2   \n",
       "...         ...       ...         ...        ...         ...        ...   \n",
       "2012   2.666667  3.333333    2.000000   1.666667         3.6        3.6   \n",
       "2013   2.666667  3.333333    2.000000   1.666667         3.6        3.6   \n",
       "2014   2.666667  3.333333    2.000000   1.666667         3.6        3.6   \n",
       "2015   2.666667  3.333333    2.000000   1.666667         3.6        3.6   \n",
       "2016   2.666667  3.333333    2.000000   1.666667         3.6        3.6   \n",
       "\n",
       "      LA_actual  LA_ideal  N_actual   N_ideal  P_actual   P_ideal   Age  \\\n",
       "0           2.0       1.8       1.0  1.000000  4.333333  4.333333  43.0   \n",
       "1           2.0       1.8       1.0  1.000000  4.333333  4.333333  43.0   \n",
       "2           2.0       1.8       1.0  1.000000  4.333333  4.333333  43.0   \n",
       "3           2.0       1.8       1.0  1.000000  4.333333  4.333333  43.0   \n",
       "4           2.0       1.8       1.0  1.000000  4.333333  4.333333  43.0   \n",
       "...         ...       ...       ...       ...       ...       ...   ...   \n",
       "2012        1.6       1.4       1.0  1.333333  4.000000  4.000000  57.0   \n",
       "2013        1.6       1.4       1.0  1.333333  4.000000  4.000000  57.0   \n",
       "2014        1.6       1.4       1.0  1.333333  4.000000  4.000000  57.0   \n",
       "2015        1.6       1.4       1.0  1.333333  4.000000  4.000000  57.0   \n",
       "2016        1.6       1.4       1.0  1.333333  4.000000  4.000000  57.0   \n",
       "\n",
       "      Children  Household_income        BMI  BAS_D  BAS_FS  BAS_RR  BIS.5  \\\n",
       "0          3.0               9.0  27.328927   14.0    16.0    23.0   24.0   \n",
       "1          3.0               9.0  27.328927   14.0    16.0    23.0   24.0   \n",
       "2          3.0               9.0  27.328927   14.0    16.0    23.0   24.0   \n",
       "3          3.0               9.0  27.328927   14.0    16.0    23.0   24.0   \n",
       "4          3.0               9.0  27.328927   14.0    16.0    23.0   24.0   \n",
       "...        ...               ...        ...    ...     ...     ...    ...   \n",
       "2012       1.0               9.0  31.800000    7.0     9.0    10.0   17.0   \n",
       "2013       1.0               9.0  31.800000    7.0     9.0    10.0   17.0   \n",
       "2014       1.0               9.0  31.800000    7.0     9.0    10.0   17.0   \n",
       "2015       1.0               9.0  31.800000    7.0     9.0    10.0   17.0   \n",
       "2016       1.0               9.0  31.800000    7.0     9.0    10.0   17.0   \n",
       "\n",
       "      BIS_total  NS_total  Conscientiousness_scaled  Extraversion_scaled  \\\n",
       "0          51.0      11.0                     0.875             0.583333   \n",
       "1          51.0      11.0                     0.875             0.583333   \n",
       "2          51.0      11.0                     0.875             0.583333   \n",
       "3          51.0      11.0                     0.875             0.583333   \n",
       "4          51.0      11.0                     0.875             0.583333   \n",
       "...         ...       ...                       ...                  ...   \n",
       "2012       61.0      18.0                     0.625             0.520833   \n",
       "2013       61.0      18.0                     0.625             0.520833   \n",
       "2014       61.0      18.0                     0.625             0.520833   \n",
       "2015       61.0      18.0                     0.625             0.520833   \n",
       "2016       61.0      18.0                     0.625             0.520833   \n",
       "\n",
       "      Neuroticism_scaled  SWLS   FTP   SBQ  Minutes Asleep  Minutes Awake  \\\n",
       "0               0.208333  25.0   5.5  60.0           147.0           10.0   \n",
       "1               0.208333  25.0   5.5  60.0           317.0           40.0   \n",
       "2               0.208333  25.0   5.5  60.0           317.0           40.0   \n",
       "3               0.208333  25.0   5.5  60.0           419.0           34.0   \n",
       "4               0.208333  25.0   5.5  60.0           419.0           34.0   \n",
       "...                  ...   ...   ...   ...             ...            ...   \n",
       "2012            0.197917  23.0  54.0  52.0           739.0           14.0   \n",
       "2013            0.197917  23.0  54.0  52.0           739.0           14.0   \n",
       "2014            0.197917  23.0  54.0  52.0           372.0           16.0   \n",
       "2015            0.197917  23.0  54.0  52.0           372.0           16.0   \n",
       "2016            0.197917  23.0  54.0  52.0           372.0           16.0   \n",
       "\n",
       "      Number of Awakenings  Time in Bed  Sex_Female  Sex_Male  \\\n",
       "0                      6.0        157.0           1         0   \n",
       "1                     17.0        357.0           1         0   \n",
       "2                     17.0        357.0           1         0   \n",
       "3                     17.0        453.0           1         0   \n",
       "4                     17.0        453.0           1         0   \n",
       "...                    ...          ...         ...       ...   \n",
       "2012                   1.0        753.0           0         1   \n",
       "2013                   1.0        753.0           0         1   \n",
       "2014                   1.0        388.0           0         1   \n",
       "2015                   1.0        388.0           0         1   \n",
       "2016                   1.0        388.0           0         1   \n",
       "\n",
       "      Ethnicity_Asian  Ethnicity_Biracial  Ethnicity_Black  \\\n",
       "0                   0                   0                0   \n",
       "1                   0                   0                0   \n",
       "2                   0                   0                0   \n",
       "3                   0                   0                0   \n",
       "4                   0                   0                0   \n",
       "...               ...                 ...              ...   \n",
       "2012                0                   0                1   \n",
       "2013                0                   0                1   \n",
       "2014                0                   0                1   \n",
       "2015                0                   0                1   \n",
       "2016                0                   0                1   \n",
       "\n",
       "      Ethnicity_Hispanic  Ethnicity_Hispanic/Caucasian  \\\n",
       "0                      0                             0   \n",
       "1                      0                             0   \n",
       "2                      0                             0   \n",
       "3                      0                             0   \n",
       "4                      0                             0   \n",
       "...                  ...                           ...   \n",
       "2012                   0                             0   \n",
       "2013                   0                             0   \n",
       "2014                   0                             0   \n",
       "2015                   0                             0   \n",
       "2016                   0                             0   \n",
       "\n",
       "      Ethnicity_Hispanic/Other  Ethnicity_More than 1 race  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "...                        ...                         ...   \n",
       "2012                         0                           0   \n",
       "2013                         0                           0   \n",
       "2014                         0                           0   \n",
       "2015                         0                           0   \n",
       "2016                         0                           0   \n",
       "\n",
       "      Ethnicity_Native Hawaiian/Pacific Islander  Ethnicity_White  \\\n",
       "0                                              0                1   \n",
       "1                                              0                1   \n",
       "2                                              0                1   \n",
       "3                                              0                1   \n",
       "4                                              0                1   \n",
       "...                                          ...              ...   \n",
       "2012                                           0                0   \n",
       "2013                                           0                0   \n",
       "2014                                           0                0   \n",
       "2015                                           0                0   \n",
       "2016                                           0                0   \n",
       "\n",
       "      Ethnicity_White/Pacific Islander  Marital_Status_Divorced  \\\n",
       "0                                    0                        0   \n",
       "1                                    0                        0   \n",
       "2                                    0                        0   \n",
       "3                                    0                        0   \n",
       "4                                    0                        0   \n",
       "...                                ...                      ...   \n",
       "2012                                 0                        1   \n",
       "2013                                 0                        1   \n",
       "2014                                 0                        1   \n",
       "2015                                 0                        1   \n",
       "2016                                 0                        1   \n",
       "\n",
       "      Marital_Status_Engaged  Marital_Status_Living with partner  \\\n",
       "0                          0                                   0   \n",
       "1                          0                                   0   \n",
       "2                          0                                   0   \n",
       "3                          0                                   0   \n",
       "4                          0                                   0   \n",
       "...                      ...                                 ...   \n",
       "2012                       0                                   0   \n",
       "2013                       0                                   0   \n",
       "2014                       0                                   0   \n",
       "2015                       0                                   0   \n",
       "2016                       0                                   0   \n",
       "\n",
       "      Marital_Status_Married  Marital_Status_Single  Marital_Status_Widowed  \\\n",
       "0                          1                      0                       0   \n",
       "1                          1                      0                       0   \n",
       "2                          1                      0                       0   \n",
       "3                          1                      0                       0   \n",
       "4                          1                      0                       0   \n",
       "...                      ...                    ...                     ...   \n",
       "2012                       0                      0                       0   \n",
       "2013                       0                      0                       0   \n",
       "2014                       0                      0                       0   \n",
       "2015                       0                      0                       0   \n",
       "2016                       0                      0                       0   \n",
       "\n",
       "      Period_of_day_Evening  Period_of_day_Morning  Period_of_day_Night  \\\n",
       "0                         0                      0                    1   \n",
       "1                         0                      1                    0   \n",
       "2                         1                      0                    0   \n",
       "3                         0                      1                    0   \n",
       "4                         1                      0                    0   \n",
       "...                     ...                    ...                  ...   \n",
       "2012                      1                      0                    0   \n",
       "2013                      0                      0                    1   \n",
       "2014                      0                      1                    0   \n",
       "2015                      1                      0                    0   \n",
       "2016                      0                      0                    1   \n",
       "\n",
       "      step_max  step_min  step_median  steps_max_3h  steps_min_3h  \\\n",
       "0        110.0       0.0          0.0         110.0           0.0   \n",
       "1        111.0       0.0          0.0          70.0           0.0   \n",
       "2        111.0       0.0          0.0         102.0           0.0   \n",
       "3        111.0       0.0          0.0          72.0           0.0   \n",
       "4        111.0       0.0          0.0          87.0           0.0   \n",
       "...        ...       ...          ...           ...           ...   \n",
       "2012     112.0       0.0          0.0           6.0           0.0   \n",
       "2013     112.0       0.0          0.0          57.0           0.0   \n",
       "2014     112.0       0.0          0.0          62.0           0.0   \n",
       "2015     112.0       0.0          0.0          41.0           0.0   \n",
       "2016     112.0       0.0          0.0          73.0           0.0   \n",
       "\n",
       "      steps_mean_3h  steps_var_3h  steps_median_3h  move_rate_3h  \\\n",
       "0          4.311111    209.813284              0.0      0.155556   \n",
       "1          1.205556     60.074829              0.0      0.044444   \n",
       "2         18.950000    417.265642             14.5      0.672222   \n",
       "3          3.750000    124.613128              0.0      0.166667   \n",
       "4         26.577778    496.803973             22.5      0.766667   \n",
       "...             ...           ...              ...           ...   \n",
       "2012       0.033333      0.200000              0.0      0.005556   \n",
       "2013       2.611111     71.199876              0.0      0.138889   \n",
       "2014       0.700000     27.786592              0.0      0.027778   \n",
       "2015       1.490909     29.739246              0.0      0.096970   \n",
       "2016       7.377778    251.621850              0.0      0.283333   \n",
       "\n",
       "      active_rate_3h  very_active_rate_3h  running_rate_3h  steps_max_1h  \\\n",
       "0           0.100000             0.066667         0.044444          76.0   \n",
       "1           0.033333             0.016667         0.011111          21.0   \n",
       "2           0.577778             0.377778         0.238889          86.0   \n",
       "3           0.105556             0.061111         0.038889          72.0   \n",
       "4           0.727778             0.550000         0.383333          87.0   \n",
       "...              ...                  ...              ...           ...   \n",
       "2012        0.000000             0.000000         0.000000           0.0   \n",
       "2013        0.094444             0.038889         0.016667           0.0   \n",
       "2014        0.022222             0.011111         0.005556           0.0   \n",
       "2015        0.054545             0.024242         0.006061          41.0   \n",
       "2016        0.205556             0.127778         0.105556          43.0   \n",
       "\n",
       "      steps_min_1h  steps_mean_1h  steps_var_1h  steps_median_1h  \\\n",
       "0              0.0       2.216667    133.325141              0.0   \n",
       "1              0.0       1.100000     17.922034              0.0   \n",
       "2              0.0      19.566667    434.148023             14.5   \n",
       "3              0.0       3.250000    193.648305              0.0   \n",
       "4              0.0      19.100000    535.345763             14.0   \n",
       "...            ...            ...           ...              ...   \n",
       "2012           0.0       0.000000      0.000000              0.0   \n",
       "2013           0.0       0.000000      0.000000              0.0   \n",
       "2014           0.0       0.000000      0.000000              0.0   \n",
       "2015           0.0       3.583333     71.399718              0.0   \n",
       "2016           0.0       1.450000     46.150000              0.0   \n",
       "\n",
       "      move_rate_1h  active_rate_1h  very_active_rate_1h  running_rate_1h  \\\n",
       "0         0.050000        0.033333             0.033333         0.033333   \n",
       "1         0.066667        0.066667             0.016667         0.000000   \n",
       "2         0.683333        0.583333             0.400000         0.233333   \n",
       "3         0.066667        0.050000             0.050000         0.050000   \n",
       "4         0.550000        0.516667             0.366667         0.266667   \n",
       "...            ...             ...                  ...              ...   \n",
       "2012      0.000000        0.000000             0.000000         0.000000   \n",
       "2013      0.000000        0.000000             0.000000         0.000000   \n",
       "2014      0.000000        0.000000             0.000000         0.000000   \n",
       "2015      0.200000        0.150000             0.066667         0.016667   \n",
       "2016      0.066667        0.033333             0.033333         0.016667   \n",
       "\n",
       "      steps_max_30m  steps_min_30m  steps_mean_30m  steps_var_30m  \\\n",
       "0              76.0            0.0        4.133333     260.947126   \n",
       "1              21.0            0.0        1.800000      30.648276   \n",
       "2              74.0            0.0       24.466667     484.533333   \n",
       "3               0.0            0.0        0.000000       0.000000   \n",
       "4              31.0            0.0        2.900000      61.610345   \n",
       "...             ...            ...             ...            ...   \n",
       "2012            0.0            0.0        0.000000       0.000000   \n",
       "2013            0.0            0.0        0.000000       0.000000   \n",
       "2014            0.0            0.0        0.000000       0.000000   \n",
       "2015           41.0            0.0        3.166667      78.350575   \n",
       "2016            0.0            0.0        0.000000       0.000000   \n",
       "\n",
       "      steps_median_30m  move_rate_30m  active_rate_30m  very_active_rate_30m  \\\n",
       "0                  0.0       0.066667         0.066667              0.066667   \n",
       "1                  0.0       0.100000         0.100000              0.033333   \n",
       "2                 23.0       0.733333         0.666667              0.533333   \n",
       "3                  0.0       0.000000         0.000000              0.000000   \n",
       "4                  0.0       0.133333         0.133333              0.066667   \n",
       "...                ...            ...              ...                   ...   \n",
       "2012               0.0       0.000000         0.000000              0.000000   \n",
       "2013               0.0       0.000000         0.000000              0.000000   \n",
       "2014               0.0       0.000000         0.000000              0.000000   \n",
       "2015               0.0       0.166667         0.133333              0.066667   \n",
       "2016               0.0       0.000000         0.000000              0.000000   \n",
       "\n",
       "      running_rate_30m  steps_max_10m  steps_min_10m  steps_mean_10m  \\\n",
       "0             0.066667           76.0            0.0            12.4   \n",
       "1             0.000000           21.0            0.0             5.4   \n",
       "2             0.333333           74.0            0.0            21.8   \n",
       "3             0.000000            0.0            0.0             0.0   \n",
       "4             0.033333            0.0            0.0             0.0   \n",
       "...                ...            ...            ...             ...   \n",
       "2012          0.000000            0.0            0.0             0.0   \n",
       "2013          0.000000            0.0            0.0             0.0   \n",
       "2014          0.000000            0.0            0.0             0.0   \n",
       "2015          0.033333           14.0            0.0             3.2   \n",
       "2016          0.000000            0.0            0.0             0.0   \n",
       "\n",
       "      steps_var_10m  steps_median_10m  move_rate_10m  active_rate_10m  \\\n",
       "0        726.933333               0.0            0.2              0.2   \n",
       "1         77.155556               0.0            0.3              0.3   \n",
       "2        742.622222              16.0            0.6              0.6   \n",
       "3          0.000000               0.0            0.0              0.0   \n",
       "4          0.000000               0.0            0.0              0.0   \n",
       "...             ...               ...            ...              ...   \n",
       "2012       0.000000               0.0            0.0              0.0   \n",
       "2013       0.000000               0.0            0.0              0.0   \n",
       "2014       0.000000               0.0            0.0              0.0   \n",
       "2015      33.955556               0.0            0.3              0.2   \n",
       "2016       0.000000               0.0            0.0              0.0   \n",
       "\n",
       "      very_active_rate_10m  running_rate_10m  steps_max_5m  steps_min_5m  \\\n",
       "0                      0.2               0.2          76.0           0.0   \n",
       "1                      0.1               0.0           0.0           0.0   \n",
       "2                      0.4               0.2          74.0           0.0   \n",
       "3                      0.0               0.0           0.0           0.0   \n",
       "4                      0.0               0.0           0.0           0.0   \n",
       "...                    ...               ...           ...           ...   \n",
       "2012                   0.0               0.0           0.0           0.0   \n",
       "2013                   0.0               0.0           0.0           0.0   \n",
       "2014                   0.0               0.0           0.0           0.0   \n",
       "2015                   0.0               0.0          14.0           0.0   \n",
       "2016                   0.0               0.0           0.0           0.0   \n",
       "\n",
       "      steps_mean_5m  steps_var_5m  steps_median_5m  move_rate_5m  \\\n",
       "0              24.8        1251.2              0.0           0.4   \n",
       "1               0.0           0.0              0.0           0.0   \n",
       "2              19.2        1029.2              0.0           0.4   \n",
       "3               0.0           0.0              0.0           0.0   \n",
       "4               0.0           0.0              0.0           0.0   \n",
       "...             ...           ...              ...           ...   \n",
       "2012            0.0           0.0              0.0           0.0   \n",
       "2013            0.0           0.0              0.0           0.0   \n",
       "2014            0.0           0.0              0.0           0.0   \n",
       "2015            3.6          36.8              0.0           0.4   \n",
       "2016            0.0           0.0              0.0           0.0   \n",
       "\n",
       "      active_rate_5m  very_active_rate_5m  running_rate_5m  hr_max  hr_min  \\\n",
       "0                0.4                  0.4              0.4   127.0    63.0   \n",
       "1                0.0                  0.0              0.0   127.0    42.0   \n",
       "2                0.4                  0.4              0.2   127.0    42.0   \n",
       "3                0.0                  0.0              0.0   131.0    42.0   \n",
       "4                0.0                  0.0              0.0   131.0    42.0   \n",
       "...              ...                  ...              ...     ...     ...   \n",
       "2012             0.0                  0.0              0.0   198.0    49.0   \n",
       "2013             0.0                  0.0              0.0   198.0    49.0   \n",
       "2014             0.0                  0.0              0.0   198.0    49.0   \n",
       "2015             0.2                  0.0              0.0   198.0    49.0   \n",
       "2016             0.0                  0.0              0.0   198.0    49.0   \n",
       "\n",
       "      hr_med   SDNN_3h   pHR2_3h  rMSSD_3h  low_hr_3h  high_hr_3h    l_h_3h  \\\n",
       "0       85.0  0.001523  0.151828  2.057286       63.0       114.0  0.552632   \n",
       "1       65.0  0.002603  0.164480  3.189919       42.0       103.0  0.407767   \n",
       "2       70.0  0.001690  0.168531  2.259787       58.0       124.0  0.467742   \n",
       "3       67.0  0.002445  0.125108  2.243964       43.0       111.0  0.387387   \n",
       "4       71.0  0.001169  0.170872  2.072757       65.0       128.0  0.507812   \n",
       "...      ...       ...       ...       ...        ...         ...       ...   \n",
       "2012    82.0  0.000940  0.073858  1.467497       57.0        86.0  0.662791   \n",
       "2013    82.0  0.001111  0.103670  1.745243       64.0       117.0  0.547009   \n",
       "2014    82.0  0.000635  0.092144  1.545934       69.0        99.0  0.696970   \n",
       "2015    82.0  0.001218  0.122177  1.808604       63.0       107.0  0.588785   \n",
       "2016    82.0  0.001625  0.128472  2.270738       62.0       122.0  0.508197   \n",
       "\n",
       "         CR_3h  hr_mean_3h   hr_var_3h  hr_std_3h  hr_median_3h  \\\n",
       "0     0.897638   79.605805  107.223097  10.354859          77.0   \n",
       "1     0.811024   58.940524   93.349638   9.661762          58.0   \n",
       "2     0.976378   84.674367  148.673153  12.193160          83.0   \n",
       "3     0.847328   73.071552  166.872357  12.917908          72.0   \n",
       "4     0.977099   98.662824  119.034032  10.910272         100.0   \n",
       "...        ...         ...         ...        ...           ...   \n",
       "2012  0.434343   64.677670   16.741483   4.091636          64.0   \n",
       "2013  0.590909   83.830431   65.251036   8.077811          82.0   \n",
       "2014  0.500000   78.250969   16.554800   4.068759          77.0   \n",
       "2015  0.540404   75.685128   55.708762   7.463830          73.0   \n",
       "2016  0.616162   90.870772  176.829640  13.297731          90.0   \n",
       "\n",
       "      hr_rest_rate_3h  hr_moderate_rate_3h  hr_very_active_rate_3h   SDNN_1h  \\\n",
       "0            0.555243             0.179775                0.081461  0.000918   \n",
       "1            0.553427             0.185484                0.023185  0.002703   \n",
       "2            0.011177             0.885246                0.346498  0.001724   \n",
       "3            0.117241             0.709483                0.141379  0.001187   \n",
       "4            0.000000             0.988473                0.697406  0.001238   \n",
       "...               ...                  ...                     ...       ...   \n",
       "2012         0.988350             0.005825                0.000000  0.000665   \n",
       "2013         0.199817             0.435380                0.209899  0.000345   \n",
       "2014         0.708333             0.123062                0.037791  0.000350   \n",
       "2015         0.749744             0.130256                0.069744  0.001308   \n",
       "2016         0.205551             0.761492                0.504770  0.000643   \n",
       "\n",
       "       pHR2_1h  rMSSD_1h  low_hr_1h  high_hr_1h    l_h_1h     CR_1h  \\\n",
       "0     0.123077  1.950937       64.0        99.0  0.646465  0.779528   \n",
       "1     0.178771  2.899143       44.0       103.0  0.427184  0.811024   \n",
       "2     0.180180  2.271544       58.0       119.0  0.487395  0.937008   \n",
       "3     0.077694  1.869824       57.0       101.0  0.564356  0.770992   \n",
       "4     0.115566  1.631789       77.0       115.0  0.669565  0.877863   \n",
       "...        ...       ...        ...         ...       ...       ...   \n",
       "2012  0.042169  1.298748       59.0        76.0  0.776316  0.383838   \n",
       "2013  0.087209  1.422412       73.0        85.0  0.858824  0.429293   \n",
       "2014  0.104615  1.705196       72.0        87.0  0.827586  0.439394   \n",
       "2015  0.108808  1.821006       67.0       107.0  0.626168  0.540404   \n",
       "2016  0.067055  2.100257       62.0       101.0  0.613861  0.510101   \n",
       "\n",
       "      hr_mean_1h   hr_var_1h  hr_std_1h  hr_median_1h  hr_rest_rate_1h  \\\n",
       "0      76.411043   31.498216   5.612327          76.0         0.690184   \n",
       "1      59.724234  113.496366  10.653467          57.0         0.604457   \n",
       "2      89.058427  183.032615  13.528955          88.0         0.013483   \n",
       "3      72.535000   40.655414   6.376160          72.0         0.012500   \n",
       "4      95.423529  119.768313  10.943871         100.0         0.000000   \n",
       "...          ...         ...        ...           ...              ...   \n",
       "2012   66.972973    8.863725   2.977201          67.0         1.000000   \n",
       "2013   78.936232    4.623829   2.150309          79.0         0.414493   \n",
       "2014   76.671779    4.350401   2.085762          76.0         0.858896   \n",
       "2015   79.976744   78.255934   8.846238          78.0         0.563307   \n",
       "2016   88.598837   21.961048   4.686262          89.0         0.023256   \n",
       "\n",
       "      hr_moderate_rate_1h  hr_very_active_rate_1h  SDNN_30m  pHR2_30m  \\\n",
       "0                0.070552                0.000000  0.000943  0.140244   \n",
       "1                0.200557                0.038997  0.002822  0.125000   \n",
       "2                0.925843                0.476404  0.001571  0.172414   \n",
       "3                0.835000                0.020000  0.000638  0.010000   \n",
       "4                1.000000                0.628235  0.001121  0.048913   \n",
       "...                   ...                     ...       ...       ...   \n",
       "2012             0.000000                0.000000  0.000352  0.000000   \n",
       "2013             0.052174                0.000000  0.000289  0.092486   \n",
       "2014             0.012270                0.000000  0.000323  0.057692   \n",
       "2015             0.260982                0.175711  0.000631  0.102564   \n",
       "2016             0.956395                0.351744  0.000298  0.012270   \n",
       "\n",
       "      rMSSD_30m  low_hr_30m  high_hr_30m   l_h_30m    CR_30m  hr_mean_30m  \\\n",
       "0      1.844570        69.0         99.0  0.696970  0.779528    78.654545   \n",
       "1      2.251811        50.0        103.0  0.485437  0.811024    60.913514   \n",
       "2      2.237032        66.0        117.0  0.564103  0.921260    88.798283   \n",
       "3      1.046422        65.0         82.0  0.792683  0.625954    71.228856   \n",
       "4      1.242368        77.0        111.0  0.693694  0.847328    85.583784   \n",
       "...         ...         ...          ...       ...       ...          ...   \n",
       "2012   0.731768        65.0         72.0  0.902778  0.363636    68.923077   \n",
       "2013   1.476208        73.0         84.0  0.869048  0.424242    77.632184   \n",
       "2014   1.365791        72.0         82.0  0.878049  0.414141    75.764331   \n",
       "2015   1.647064        67.0         94.0  0.712766  0.474747    78.326531   \n",
       "2016   1.030218        84.0         96.0  0.875000  0.484848    88.384146   \n",
       "\n",
       "      hr_var_30m  hr_std_30m  hr_median_30m  hr_rest_rate_30m  \\\n",
       "0      37.800665    6.148225           77.0          0.539394   \n",
       "1     150.818566   12.280821           57.0          0.675676   \n",
       "2     154.722066   12.438732           86.0          0.000000   \n",
       "3      10.887363    3.299600           71.0          0.000000   \n",
       "4      77.168214    8.784544           82.0          0.000000   \n",
       "...          ...         ...            ...               ...   \n",
       "2012    2.794045    1.671540           69.0          1.000000   \n",
       "2013    3.043120    1.744454           78.0          0.706897   \n",
       "2014    3.540258    1.881557           76.0          0.910828   \n",
       "2015   15.533857    3.941301           78.0          0.551020   \n",
       "2016    5.587723    2.363836           88.0          0.000000   \n",
       "\n",
       "      hr_moderate_rate_30m  hr_very_active_rate_30m  SDNN_10m  pHR2_10m  \\\n",
       "0                 0.121212                 0.000000  0.001125  0.186441   \n",
       "1                 0.151351                 0.075676  0.003763  0.188406   \n",
       "2                 0.952790                 0.446352  0.001028  0.166667   \n",
       "3                 0.885572                 0.000000  0.000624  0.027778   \n",
       "4                 1.000000                 0.194595  0.000255  0.000000   \n",
       "...                    ...                      ...       ...       ...   \n",
       "2012              0.000000                 0.000000  0.000270  0.000000   \n",
       "2013              0.005747                 0.000000  0.000310  0.056604   \n",
       "2014              0.000000                 0.000000  0.000258  0.060000   \n",
       "2015              0.107143                 0.025510  0.000411  0.028571   \n",
       "2016              1.000000                 0.237805  0.000222  0.000000   \n",
       "\n",
       "      rMSSD_10m  low_hr_10m  high_hr_10m   l_h_10m    CR_10m  hr_mean_10m  \\\n",
       "0      1.978700        71.0         99.0  0.717172  0.779528    81.916667   \n",
       "1      3.180557        50.0        103.0  0.485437  0.811024    66.628571   \n",
       "2      2.455153        66.0         91.0  0.725275  0.716535    77.589041   \n",
       "3      1.201850        65.0         82.0  0.792683  0.625954    72.178082   \n",
       "4      0.820413        79.0         85.0  0.929412  0.648855    81.320755   \n",
       "...         ...         ...          ...       ...       ...          ...   \n",
       "2012   0.510754        66.0         72.0  0.916667  0.363636    69.808511   \n",
       "2013   1.197482        73.0         81.0  0.901235  0.409091    76.907407   \n",
       "2014   1.174734        72.0         79.0  0.911392  0.398990    74.843137   \n",
       "2015   1.207122        72.0         84.0  0.857143  0.424242    79.394366   \n",
       "2016   0.612372        86.0         92.0  0.934783  0.464646    88.061224   \n",
       "\n",
       "      hr_var_10m  hr_std_10m  hr_median_10m  hr_rest_rate_10m  \\\n",
       "0      61.806497    7.861711           80.0          0.316667   \n",
       "1     325.019462   18.028296           56.0          0.557143   \n",
       "2      38.745434    6.224583           77.0          0.000000   \n",
       "3      10.870624    3.297063           72.0          0.000000   \n",
       "4       2.914369    1.707152           81.0          0.000000   \n",
       "...          ...         ...            ...               ...   \n",
       "2012    1.723404    1.312785           70.0          1.000000   \n",
       "2013    3.444095    1.855827           77.0          0.814815   \n",
       "2014    2.134902    1.461130           75.0          0.980392   \n",
       "2015    6.670825    2.582794           79.0          0.338028   \n",
       "2016    3.058673    1.748906           88.0          0.000000   \n",
       "\n",
       "      hr_moderate_rate_10m  hr_very_active_rate_10m   SDNN_5m   pHR2_5m  \\\n",
       "0                 0.233333                 0.000000  0.001094  0.125000   \n",
       "1                 0.342857                 0.200000  0.000643  0.035714   \n",
       "2                 0.849315                 0.054795  0.001182  0.181818   \n",
       "3                 0.931507                 0.000000  0.000522  0.054054   \n",
       "4                 1.000000                 0.000000  0.000252  0.000000   \n",
       "...                    ...                      ...       ...       ...   \n",
       "2012              0.000000                 0.000000  0.000113  0.000000   \n",
       "2013              0.000000                 0.000000  0.000280  0.038462   \n",
       "2014              0.000000                 0.000000  0.000221  0.040000   \n",
       "2015              0.112676                 0.000000  0.000292  0.027027   \n",
       "2016              1.000000                 0.244898  0.000208  0.000000   \n",
       "\n",
       "      rMSSD_5m  low_hr_5m  high_hr_5m    l_h_5m     CR_5m  hr_mean_5m  \\\n",
       "0     1.968502       76.0        99.0  0.767677  0.779528   85.757576   \n",
       "1     1.224745       50.0        58.0  0.862069  0.456693   53.034483   \n",
       "2     2.037527       66.0        91.0  0.725275  0.716535   76.852941   \n",
       "3     1.414214       69.0        82.0  0.841463  0.625954   74.000000   \n",
       "4     0.721110       79.0        84.0  0.940476  0.641221   81.846154   \n",
       "...        ...        ...         ...       ...       ...         ...   \n",
       "2012  0.417029       70.0        72.0  0.972222  0.363636   70.625000   \n",
       "2013  1.143544       73.0        79.0  0.924051  0.398990   76.037037   \n",
       "2014  1.000000       73.0        77.0  0.948052  0.388889   74.269231   \n",
       "2015  1.196843       77.0        84.0  0.916667  0.424242   80.842105   \n",
       "2016  0.807573       86.0        92.0  0.934783  0.464646   89.166667   \n",
       "\n",
       "      hr_var_5m  hr_std_5m  hr_median_5m  hr_rest_rate_5m  \\\n",
       "0     68.189394   8.257687          82.0         0.181818   \n",
       "1      3.463054   1.860928          53.0         1.000000   \n",
       "2     51.947415   7.207456          75.0         0.000000   \n",
       "3      8.648649   2.940858          73.5         0.000000   \n",
       "4      2.935385   1.713296          82.5         0.000000   \n",
       "...         ...        ...           ...              ...   \n",
       "2012   0.331522   0.575779          71.0         1.000000   \n",
       "2013   2.729345   1.652073          76.0         0.925926   \n",
       "2014   1.564615   1.250846          74.0         1.000000   \n",
       "2015   3.704125   1.924610          81.0         0.105263   \n",
       "2016   2.840580   1.685402          89.5         0.000000   \n",
       "\n",
       "      hr_moderate_rate_5m  hr_very_active_rate_5m  hr_0  hr_0.3  hr_0.5  \\\n",
       "0                0.424242                0.000000  63.0    77.0    85.0   \n",
       "1                0.000000                0.000000  42.0    58.0    65.0   \n",
       "2                0.764706                0.117647  42.0    61.0    70.0   \n",
       "3                1.000000                0.000000  42.0    58.0    67.0   \n",
       "4                1.000000                0.000000  42.0    60.0    71.0   \n",
       "...                   ...                     ...   ...     ...     ...   \n",
       "2012             0.000000                0.000000  49.0    79.0    82.0   \n",
       "2013             0.000000                0.000000  49.0    78.0    82.0   \n",
       "2014             0.000000                0.000000  49.0    78.0    82.0   \n",
       "2015             0.210526                0.000000  49.0    78.0    82.0   \n",
       "2016             1.000000                0.500000  49.0    78.0    82.0   \n",
       "\n",
       "      hr_0.8   hr_1  \n",
       "0       99.0  127.0  \n",
       "1       88.0  127.0  \n",
       "2       88.0  127.0  \n",
       "3       87.0  131.0  \n",
       "4       94.0  131.0  \n",
       "...      ...    ...  \n",
       "2012    89.0  198.0  \n",
       "2013    89.0  198.0  \n",
       "2014    89.0  198.0  \n",
       "2015    89.0  198.0  \n",
       "2016    89.0  198.0  \n",
       "\n",
       "[2017 rows x 185 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['VALENCE_mean'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject\n",
       "1002      3.000000\n",
       "1004      0.500000\n",
       "1008      1.000000\n",
       "1009      2.333333\n",
       "1014      2.666667\n",
       "            ...   \n",
       "DND111    2.000000\n",
       "DND113    2.666667\n",
       "DND114    1.333333\n",
       "DND115    1.833333\n",
       "DND119    2.333333\n",
       "Name: VALENCE_mean, Length: 97, dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_median_subject = X.groupby(by='subject').median()['VALENCE_mean']\n",
    "y_median_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column with the valence reported - the median valence reported\n",
    "X['Median_subject_valence'] = X['VALENCE_mean'].copy()\n",
    "#substracting to each subject their own median\n",
    "for subj in y_median_subject.index:\n",
    "    X.loc[X.subject == subj,'Median_subject_valence'] = X.loc[X.subject == subj,'Median_subject_valence'].apply(lambda x: x - y_median_subject[subj])\n",
    "\n",
    "y_median = X['Median_subject_valence'].astype(float).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = X['subject'].copy() #let's store a copy of the subjects\n",
    "X.drop(columns= ['VALENCE_mean', 'Median_subject_valence','subject'], inplace= True)\n",
    "# I could drop this columns [hr_0\thr_0.3\thr_0.5\thr_0.8\thr_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['X','y','y_median','subjects','DF_complete_nona']:\n",
    "    with open(f'./{i}.pickle', 'wb') as file:\n",
    "        pickle.dump(eval(i),file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnig CV by Groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's split by group/subject in order to train with different subjects than test\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=10, train_size=.7, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_shuffle(model,X,y, gss):\n",
    "    '''\n",
    "    Function performs a group shuffle CV\n",
    "    '''\n",
    "    n = 0\n",
    "    df = pd.DataFrame(columns = ['Test set',\t'MAE',\t'MSE',\t'RMSE'])\n",
    "\n",
    "    #Loop to train all the different combinations\n",
    "    for train_idx, test_idx in gss.split(X, y, subjects):\n",
    "        n += 1\n",
    "        SCALER = preprocessing.StandardScaler().fit(X.iloc[train_idx,:]) # I would SCALE the data, but to dont contaminate the Fold I should scale using the training for every fold\n",
    "        train = pd.DataFrame(data = SCALER.transform(X.iloc[train_idx,:]), columns = X.columns) # Apply scaler to train data\n",
    "        test = pd.DataFrame(data = SCALER.transform(X.iloc[test_idx,:]), columns = X.columns) # Apply scaler to test data\n",
    "        model.fit(train, y.iloc[train_idx])\n",
    "        df= df.append( evaluate(model,\n",
    "                                 test_set_name=[f'Set {n}'],\n",
    "                                 x_test = [test],\n",
    "                                 y_test= [y.iloc[test_idx]]\n",
    "                               )\n",
    "                        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics = group_shuffle(rf_optimized,X,y, gss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE     0.859302\n",
       "MSE     1.216094\n",
       "RMSE    1.101915\n",
       "dtype: float64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_median_metrics = group_shuffle(rf_optimized,X,y_median, gss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE     0.715397\n",
       "MSE     0.892019\n",
       "RMSE    0.943668\n",
       "dtype: float64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_median_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bad92b8dc8>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparing both distributions\n",
    "sns.distplot(y)\n",
    "sns.distplot(y_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2017.000000\n",
       "mean        1.342588\n",
       "std         1.192099\n",
       "min        -3.333333\n",
       "25%         0.666667\n",
       "50%         1.333333\n",
       "75%         2.333333\n",
       "max         4.000000\n",
       "Name: VALENCE_mean, dtype: float64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2017.000000\n",
       "mean       -0.075040\n",
       "std         0.950234\n",
       "min        -4.833000\n",
       "25%        -0.667000\n",
       "50%         0.000000\n",
       "75%         0.500000\n",
       "max         3.333000\n",
       "Name: Median_subject_valence, dtype: float64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_median.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How we compare the RMSE between this two different distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe the best solution to this is binarize the target variable and compare using classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_metrics = group_shuffle(model_svm_optimized,X,y, gss)\n",
    "svm_median_metrics = group_shuffle(model_svm_optimized,X,y_median, gss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE     0.933741\n",
       "MSE     1.467727\n",
       "RMSE    1.209467\n",
       "dtype: float64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE     0.745145\n",
       "MSE     0.964165\n",
       "RMSE    0.981152\n",
       "dtype: float64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_median_metrics.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_metrics = group_shuffle(model_xgb,X,y, gss)\n",
    "xgb_median_metrics = group_shuffle(model_xgb,X,y_median, gss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE     0.884350\n",
       "MSE     1.282147\n",
       "RMSE    1.131525\n",
       "dtype: float64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE     0.737599\n",
       "MSE     0.941949\n",
       "RMSE    0.969884\n",
       "dtype: float64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_median_metrics.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_metrics = group_shuffle(model_bayesian_ridge,X,y, gss)\n",
    "bayesian_median_metrics = group_shuffle(model_bayesian_ridge,X,y_median, gss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE     0.943658\n",
       "MSE     1.504620\n",
       "RMSE    1.224004\n",
       "dtype: float64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE     0.701709\n",
       "MSE     0.864653\n",
       "RMSE    0.929102\n",
       "dtype: float64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_median_metrics.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest is the winner for `Valence`\n",
    "> RMSE = 1.101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Ridge Regression is the winner for `Median_subject_valence`\n",
    "\n",
    "> RMSE = 0.929"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
